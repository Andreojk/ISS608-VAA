[
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "title": "Take-Home_Ex03",
    "section": "",
    "text": "In this take-home exercise, I am required to select one of the modules of my proposed Shiny application and complete the following tasks:\n\nTo evaluate and determine the necessary R packages needed for your Shiny application are supported in R CRAN,\nTo prepare and test the specific R codes can be run and returned the correct output as expected,\nTo determine the parameters and outputs that will be exposed on the Shiny applications, and\nTo select the appropriate Shiny UI components for exposing the parameters determine above.\n\nThese components have been considered and reviewed individually using Take-Home Ex02 where this current exercise will be the continuation and preparation to build the plots into Shiny App.\n\n\nContinuing from Take-Home Exercise 2, my group members (Hendra and Jin Yao) and I have completed Mini-Challenge 1 and publish the relevant data and visualisation required.\nBased on Take Home 3, we have cross-examined the work done for each of MC1 sections and hand picked some useful charts that we feel is great for the Shiny app."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#data-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#data-preparation",
    "title": "Take-Home_Ex03",
    "section": "",
    "text": "Continuing from Take-Home Exercise 2, my group members (Hendra and Jin Yao) and I have completed Mini-Challenge 1 and publish the relevant data and visualisation required.\nBased on Take Home 3, we have cross-examined the work done for each of MC1 sections and hand picked some useful charts that we feel is great for the Shiny app."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#r-packages-required",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#r-packages-required",
    "title": "Take-Home_Ex03",
    "section": "R packages required",
    "text": "R packages required\n\n\nCode\npacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph,ggraph,dplyr,igraph, \n               visNetwork,RColorBrewer,htmltools,ggplot2,scales,plotly,tidytext\n               ,patchwork, lubridate)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#visualisation-charts",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#visualisation-charts",
    "title": "Take-Home_Ex03",
    "section": "Visualisation Charts",
    "text": "Visualisation Charts\nThe charts are linked to the below links.\nJin Yao\nHendra\nAndre/Myself"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-1",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-1",
    "title": "Take-Home_Ex03",
    "section": "Module 1",
    "text": "Module 1\nA navigation bar will be created at the top to click between section. Module 1 will be called (1) General Interaction.\nThe first section will consist of the (6) Overallnetwork graph where the user can select either (2) Music Artist and/or (3) Groups filter drop down list. This selection will show the network graph interaction with each individual nodes (Song, Album, MusicalGroup, Person and RecordLabel).\nThe filter number of (4) Hops can be selected to show a less clattered direct interaction. We wil also include a (5) timeline which we can choose the interaction period instead of visualising the whole career of the Artist/Group.\nThe final plot wil be (7) Betweenness Centrality to show which interaction is the most significant."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-2",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-2",
    "title": "Take-Home_Ex03",
    "section": "Module 2",
    "text": "Module 2\nThis module will be (1) Inward/Outward Influences based on the network graph. Similarly the visualisation section is similar to module 1. The only changes will be an added (6) Inward/Outward button selection that will toggle between the plots.\nAn example can be seen for the (7) charts where we can scroll to see the individual edge connection.\n\n2a2b\n\n\n\nInward/Outward button will toggle between 2a and 2b.\n\n\n\n\n\n\n\n\n\nInward/Outward button will toggle between 2a and 2b."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-3",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-3",
    "title": "Take-Home_Ex03",
    "section": "Module 3",
    "text": "Module 3\nThis module will be (1) Influence Through The Years with bar, line graphs and histograms being used.\nThe chart will show (4) Selected Genre where the bar graphs will show the accumulated influences across the years. The (2) Genre can be selected from the filter drop down list and (3) Timeline can be limited on the chart for better visibility."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-4",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-4",
    "title": "Take-Home_Ex03",
    "section": "Module 4",
    "text": "Module 4\nThis module will be (1) Top Genres and Artists where both line and bar graphs are used for the visuaisation.\nThe (2) Number of songs by Genre will be the overall analysis of the dataset. (3) Top Artists with the most number of notable songs in each genre is plotted on the right. The filter selection of (5) Genres and (6) Artists in Genre are in the side box where the user is able to key in the number he/she intends to see in the plot.\nLastly, (7) Timeline of Artist’s released songs will be plotted acrss the years using the select artist in the filters."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-5",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#module-5",
    "title": "Take-Home_Ex03",
    "section": "Module 5",
    "text": "Module 5\nFor the last module, we will take a look at (1) Artist and Song Popularity. This module will be based on the number of notable songs released by the artist.(2) Top Persons by Genre will be plotted as a reference where the genre can be selected by the (5) Genres filter list.\nThe 2nd chart of (3) Artist: Notable vs Chartered songs across the timeline will be plotted using the (6) Selected Artist. (7) Timeline limit filter is also added to limit the visualisation.\nLastly, a pie chart of (7) Notable vs non-notable songs will be plotted for the selected artist in the genre."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html",
    "title": "Take-Home_Ex01_Part2",
    "section": "",
    "text": "We are tasked with the below instructions for ‘Take-Home_Ex01_Part2’:\n\n\n\n\n\n\nPart 2 Instructions\n\n\n\nPart 2: Selecting one submission provided by your classmate, critic three good design principles and three areas for further improvement. With reference to the comment, prepare the makeover version of the data visualization.\n\n\n\n\n\nDuring lecture, an article published by Ben Jones was shared as a framework to judge data visualization plots. I will be using this as a baseline to praise or critic the plots in this exercise.\n\n\n\n\n\n\n\nThe Four Quadrants:\n\nQuadrant I is for the winning visualizations that are both clear AND beautiful.\nQuadrant II, where those unfortunate clear but ugly visualizations live.\nQuadrant III, the saddest plot of land reserved for those ugly AND confusing works that should never have been.\nQuadrant IV – the insidious land of the visualizations that stun you with their graphical beauty, but don’t impart a lick of understanding of the real world, at least not of the accurate sort. Even worse, they tend to mislead the reader, sometimes with malicious intent.\n\n\n\n\n\nI will be using the following classmate’s submission (Click the link below) for this activity. His data cleaning will be replicated in the initial steps to get the original plot.\nPlot 3"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#background",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#background",
    "title": "Take-Home_Ex01_Part2",
    "section": "",
    "text": "We are tasked with the below instructions for ‘Take-Home_Ex01_Part2’:\n\n\n\n\n\n\nPart 2 Instructions\n\n\n\nPart 2: Selecting one submission provided by your classmate, critic three good design principles and three areas for further improvement. With reference to the comment, prepare the makeover version of the data visualization."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#framework-to-critic-visualizations-classmates-links",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#framework-to-critic-visualizations-classmates-links",
    "title": "Take-Home_Ex01_Part2",
    "section": "",
    "text": "During lecture, an article published by Ben Jones was shared as a framework to judge data visualization plots. I will be using this as a baseline to praise or critic the plots in this exercise.\n\n\n\n\n\n\n\nThe Four Quadrants:\n\nQuadrant I is for the winning visualizations that are both clear AND beautiful.\nQuadrant II, where those unfortunate clear but ugly visualizations live.\nQuadrant III, the saddest plot of land reserved for those ugly AND confusing works that should never have been.\nQuadrant IV – the insidious land of the visualizations that stun you with their graphical beauty, but don’t impart a lick of understanding of the real world, at least not of the accurate sort. Even worse, they tend to mislead the reader, sometimes with malicious intent."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#classmate-links",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#classmate-links",
    "title": "Take-Home_Ex01_Part2",
    "section": "",
    "text": "I will be using the following classmate’s submission (Click the link below) for this activity. His data cleaning will be replicated in the initial steps to get the original plot.\nPlot 3"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#loading-of-libraries-and-dataset",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#loading-of-libraries-and-dataset",
    "title": "Take-Home_Ex01_Part2",
    "section": "2.1 Loading of libraries and dataset",
    "text": "2.1 Loading of libraries and dataset\nLibraries:\n\n\nCode\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, \n               patchwork, DT, dplyr, scales, forcats, dplyr, grid) \n\n\nDataset:\n\n\nCode\ndf &lt;- read_csv(\"data/respopagesex2024.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#loading-original-skeleton-and-codes",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#loading-original-skeleton-and-codes",
    "title": "Take-Home_Ex01_Part2",
    "section": "2.2 Loading original skeleton and codes",
    "text": "2.2 Loading original skeleton and codes\n\n\n\n\n\n\nOriginal Author’s Theme\n\n\n\nWe will keep to the original author’s code to replicate his/her plot.\n\n\nTheme:\nUsing the original author’s theme.\n\n\nCode\ncommon_theme &lt;- theme_minimal(base_size = 16) +\n  theme(\n    axis.text = element_text(size = 18),\n    axis.title = element_text(size = 20),\n    plot.title = element_text(size = 18, face = \"bold\"),\n    legend.text = element_text(size = 17),\n    legend.title = element_text(size = 16)\n  )\n\n\nCreating a Numeric Age Column & Age Grouping:\nColumn type created are integers to be used for plotting.\n\n\nCode\ndf &lt;- df %&gt;%\n  mutate(\n    AgeNum = suppressWarnings(\n      ifelse(Age == \"90_and_Over\", 90, as.numeric(Age))\n    )\n  )\n\ndf &lt;- df %&gt;%\n  mutate(\n    AgeGroup = case_when(\n      AgeNum &lt;= 12 ~ \"Child\",\n      AgeNum &lt;= 24 ~ \"Youth\",\n      AgeNum &lt;= 64 ~ \"Adult\",\n      TRUE ~ \"Senior\"\n    )\n  )"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#orginal-plot",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#orginal-plot",
    "title": "Take-Home_Ex01_Part2",
    "section": "3.1 Orginal Plot",
    "text": "3.1 Orginal Plot\n\n\n\n\n\n\nReplicating the Original Plot\n\n\n\nBelow is the original plot (Plot 3) from the chosen classmate’s link. It might look smaller from the original link but the overall aesthetic remains the same.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_pyramid &lt;- df %&gt;%\n  filter(AgeNum &lt;= 90) %&gt;%\n  mutate(Pop = ifelse(Sex == \"Males\", -Pop, Pop))\n\np6 &lt;- ggplot(df_pyramid, aes(x = AgeNum, y = Pop, fill = Sex)) +\n  geom_col(width = 1) +\n  coord_flip() +\n  labs(title = \"Population Pyramid\", x = \"Age\", y = \"Population\") +\n  scale_y_continuous(labels = label_comma()) +\n  common_theme\n\np7 &lt;- df %&gt;%\n  group_by(Sex, AgeGroup) %&gt;%\n  summarise(Pop = sum(Pop)) %&gt;%\n  ggplot(aes(x = AgeGroup, y = Pop, fill = Sex)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Age Group Distribution by Gender\", y = \"Population\") +\n  scale_y_continuous(labels = label_comma()) +\n  common_theme\n\n(p6 / p7) + plot_layout(heights = c(1.3, 1))\n\n\n\n\n\n3.1.1 Good Design Principles\n\nClean Plots with Gridlines\n\nThe gridlines for both the 1) Pyramid plot and 2) Bar charts help to guide the user on the axis references.\n\nColour Theme\n\nThe colour code of males and females were consistent and easily distinguishable for both plots. I am instantly able to identify the gender from the plots.\n\nClarity of Secondary Bar Chart Plot\n\nThe bar chart helps to provide a simple but direct comparison of the ranked categorical data. It describes the total population of each ‘Age groups’ where majority of the population are ‘Adults’.\n\n\n3.1.2 Areas of Improvements\n\nAxis Scale\n\nThe x-axis of the pyramid plot has a negative number for the population and the scaling is too large to identify the population number of each age.\nSuggestion: This requires changing the x-axis to only positive values and changing the scale into thousands.\n\nBinning of Age Groups\n\nThe bars in the pyramid plot is too clustered, where I am unable to distinguish the age groups clearly as all the ages are represented in the plot. Secondly, the Y-axis scale of only 4 digits does not clearly identify all the age groups for identification.\nSuggestion: This can tidied by grouping the ages into ranges for better representation and also reduce the amount of the bars on the pyramid plot\n\nEditing the Age Grouping & Sorting it via age\n\nFor the bar chart plot, the ‘Adult’ group might be too bias as majority of the population falls under the range between ‘25 - 65 years old’. It would be better to increases the amount of groups from the initial 4 for a more accurate representation of the population groups. Secondly, the groups are not sorted properly making it confusing to identify which has the least population.\nSuggestion: This can be adjusted by splitting the ‘Adult’ groups into ‘Young Adults’, ‘Middle-Aged Adults’ & ‘Older Adults’. Ensuring the groups are categorized as equal/fair as possible. The new groups are sorting according to increasing age groups for easier identification."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#additional-code-chunks-to-the-plot",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#additional-code-chunks-to-the-plot",
    "title": "Take-Home_Ex01_Part2",
    "section": "4.1 Additional Code Chunks to the plot",
    "text": "4.1 Additional Code Chunks to the plot\n\n4.1.1 Editing the Age column and Binning\nThe Age column is not entirely numeric due to character values “90_and_Over”. I will directly address this by creating a new column called ‘AgeNum2’ and re-code those character values to “90” using string replacement. This will make the binning of new age ranges for the edited pyramid plot easier.\nBinning into ranges:\nI will bin the ages into incremental ranges of 5 using AgeNum column into ‘AgeNum2’.\n\n\nCode\nage_breaks &lt;- seq(0, 90, by = 5)\nage_labels &lt;- c(paste(seq(0, 80, 5), seq(4, 84, 5), sep = \"-\"), \"85-89\", \"90+\")\n\ndf &lt;- df %&gt;%\n  mutate(\n    AgeNum = ifelse(AgeNum == \"90+\", 90, AgeNum),\n    AgeNum = as.numeric(AgeNum),\n    AgeNum2 = cut(\n      AgeNum,\n      breaks = c(seq(0, 90, 5), Inf),\n      labels = age_labels,\n      right = FALSE\n    )\n  )\n\n\nExpanding Age Groupings:\nAdding Another column ‘AgeGroup2’ by editing the Age ranges\n\n\nCode\ndf &lt;- df %&gt;%\n  mutate(\n    AgeGroup2 = case_when(\n      AgeNum &lt;= 12 ~ \"Children\",\n      AgeNum &lt;= 20 ~ \"Teenagers\",\n      AgeNum &lt;= 30 ~ \"Young Adults\",\n      AgeNum &lt;= 45 ~ \"Adults\",\n      AgeNum &lt;= 64 ~ \"Older Adults\",\n      TRUE ~ \"Elderly\"\n    )\n  )"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#reworking-the-actual-plot",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01_Part2.html#reworking-the-actual-plot",
    "title": "Take-Home_Ex01_Part2",
    "section": "4.2 Reworking the Actual Plot",
    "text": "4.2 Reworking the Actual Plot\nCombining the additional code blocks above together with optimizing the original code. The below plot is derived.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndf_pyramid &lt;- df %&gt;%\n  mutate(Pop = ifelse(Sex == \"Males\", -Pop, Pop))\n\np6 &lt;- ggplot(df_pyramid, aes(x = AgeNum2, y = Pop, fill = Sex)) +\n  geom_bar(stat = \"identity\", width = 0.8) +\n  coord_flip() +\n  scale_y_continuous(\n    breaks = seq(-150000, 150000, 50000),\n    labels = abs(seq(-150, 150, 50))\n  ) +\n  labs(\n    title = \"Singapore Residents Pyramid by Age Cohort, 2024\",\n    x = \"Age group\",\n    y = \"Population (in thousands)\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, face = \"bold\"),\n    axis.text.y = element_text(size = 10),\n    axis.title.x = element_text(margin = margin(t = 10))\n  )\n\np7 &lt;- df %&gt;%\n  group_by(Sex, AgeGroup2) %&gt;%\n  summarise(Pop = sum(Pop)) %&gt;%\n  ggplot(aes(x = AgeGroup2, y = Pop, fill = Sex)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.8) +\n  scale_x_discrete(limits = c(\n      \"Children\",\"Teenagers\",\"Young Adults\",\"Adults\",\"Older Adults\",\"Elderly\"\n    )) +\n  labs(title = \"Age Group Distribution by Gender\", y = \"Population\", x = \"Age Groups\") +\n  scale_y_continuous(labels = label_comma()) +\n  common_theme +\n  theme(\n    plot.title       = element_text(size = 14, hjust = 0.5, face = \"bold\"),\n    axis.title.x     = element_text(size = 10, margin = margin(t = 4)),\n    axis.title.y     = element_text(size = 10),\n    axis.text.y      = element_text(size = 8),\n    axis.text.x      = element_text(size = 8),\n    legend.title     = element_text(size = 10),\n    legend.text      = element_text(size = 8)\n    )\n\n(p6 / p7) + plot_layout(heights = c(1.3, 1))\n\n\n\n\n\n\n\n\n\n\nConclusion\n\n\n\nWith these changes to the original plots, we can visualize the Age and Population distribution much clearer."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISS608-VAA",
    "section": "",
    "text": "Welcome to Andre’s ISSS608 Visual Analytics and Applications coursework website. You will find the exercises, assignments and projects published during the course.\nDo feel free to connect with me to discuss questions and insights about analytics!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-on_Ex09",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, we will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.\n\n\n\n\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nThe code chunks below will accomplish the task.\n\n\nCode\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\n\n\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n\nCode\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n\nCode\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\n\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n\nCode\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nCode\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n\nCode\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview",
    "title": "Hands-on_Ex09",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, we will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages",
    "title": "Hands-on_Ex09",
    "section": "",
    "text": "For this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nThe code chunks below will accomplish the task.\n\n\nCode\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation",
    "title": "Hands-on_Ex09",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n\nCode\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n\nCode\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on_Ex09",
    "section": "",
    "text": "Use ggtern() function of ggtern package to create a simple ternary plot.\n\n\nCode\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nCode\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n\nCode\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-1",
    "title": "Hands-on_Ex09",
    "section": "6.1 Overview",
    "text": "6.1 Overview\nCorrelation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, we will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, I will create a correlation matrix using pairs() of R Graphics. Next, I will plot corrgram using corrplot package of R. Lastly, I will create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-1",
    "title": "Hands-on_Ex09",
    "section": "6.2 Installing and Launching R Packages",
    "text": "6.2 Installing and Launching R Packages\nBefore we get started, we are required to open a new Quarto document. Keep the default html authoring format.\nNext, we will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\n\nCode\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-and-preparing-the-data-set",
    "title": "Hands-on_Ex09",
    "section": "6.3 Importing and Preparing The Data Set",
    "text": "6.3 Importing and Preparing The Data Set\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n6.3.1 Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\n\nCode\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on_Ex09",
    "section": "6.4 Building Correlation Matrix: pairs() method",
    "text": "6.4 Building Correlation Matrix: pairs() method\nThere are more than one way to build scatterplot matrix with R. In this section, we will create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, we should read the syntax description of pairs function.\n\n6.4.1 Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\n\nCode\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\n\nCode\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n\n6.4.2 Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\n\nCode\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\n\nSimilarly, we can display the upper half of the correlation matrix by using the code chun below.\n\n\nCode\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\n6.4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into our R session or script. Let’s have more fun way to display the correlation matrix.\n\n\nCode\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on_Ex09",
    "section": "6.5 Visualising Correlation Matrix: ggcormat()",
    "text": "6.5 Visualising Correlation Matrix: ggcormat()\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n6.5.1 The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\n\nCode\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\n\n\nCode\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\n\nCode\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#building-multiple-plots",
    "title": "Hands-on_Ex09",
    "section": "6.6 Building multiple plots",
    "text": "6.6 Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\n\nCode\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on_Ex09",
    "section": "6.7 Visualising Correlation Matrix using corrplot Package",
    "text": "6.7 Visualising Correlation Matrix using corrplot Package\nIn this hands-on exercise, we will focus on corrplot. However, I will encouraged to explore the other two packages too.\nBefore getting started, we are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n6.7.1 Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\n\nCode\nwine.cor &lt;- cor(wine[, 1:11])\n\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\n\nCode\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n6.7.2 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\n\nCode\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\n6.7.3 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\n\nCode\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\n\nCode\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\n\n6.7.4 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\n\nCode\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\n\nCode\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n6.7.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\n\nCode\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\n\nCode\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\n6.7.6 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\n\nCode\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n6.7.7 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\n\nCode\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#reference",
    "title": "Hands-on_Ex09",
    "section": "7 Reference",
    "text": "7 Reference\nMichael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180.\n\n7.1 R packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/data/geospatial/MPSZ-2019.html",
    "title": "ISS608-VAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "In this hands-on exercise, I will attempt to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, I will be doing the following:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\n\n\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nPackages:\n\n\nCode\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)\n\n\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n\n\n\n\n\n\n\nCode\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\n\n\nCode\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\n\nCode\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nCode\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\n\nCode\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nCode\nglimpse(GAStech_edges_aggregated)\n\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…\n\n\n\n\n\n\nIn this section, I will create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nThe below 2 articles are helpful before starting the plots. - Introducing tidygraph - tidygraph 1.1 - A tidy hope\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\n\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give us the edge data and .G() will give us the tbl_graph object itself.\n\n\n\n\nIn this section, we will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, I will recommended to review to reference guide of tbl_graph().\n\n\nCode\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\n\nCode\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but we can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nCode\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function.\n\n\n\n\nggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes\nedges\nlayouts\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before getting started, it is advisable to read their respective reference guide at least once.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this sub-portion, I will be exploring alternate plots from the following references:\n\nLayouts\ntidygraph and ggraph\n\n\nTidygraph algorithms in ggraph codeGroup_info map from aboveGrid LayoutFocal Layout (Coord Diagram)Spring-based Layout\n\n\n\n\nCode\nggraph(GAStech_graph, \n            layout = 'fr') + \n  geom_edge_link() + \n  geom_node_point(aes(size = centrality_pagerank())) + \n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggraph(GAStech_graph, \n            layout = 'fr') + \n  geom_edge_link() + \n  geom_node_point() + \n  facet_nodes(~ group_infomap())\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggraph(GAStech_graph, \n            layout = \"grid\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes()) +\n  theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ng &lt;- ggraph(GAStech_graph, \n            'focus', focus = node_is_center()) + \n  ggforce::geom_circle(aes(x0 = 0, y0 = 0, r = r), data.frame(r = 1:3), colour = 'grey') + \n  geom_edge_link() + \n  geom_node_point() + \n  coord_fixed()\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggraph(GAStech_graph, \n            layout = \"kk\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes()) +\n  theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line.\n\n\n\n\n\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, I will use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable to read it’s reference guide at least once.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\nChanging the legend positions to the bottom:\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable to read it’s reference guide at least once.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()\n\n\n\n\n\n\n\n\n\nvisNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nI can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nI can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\n\n\nCode\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\n\nCode\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\n\nCode\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges. - The argument arrows is used to define where to place the arrow. - The smooth argument is used to plot the edges using a smooth curve.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#overview",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "In this hands-on exercise, I will attempt to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, I will be doing the following:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-lauching-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#installing-and-lauching-packages",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "In this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nPackages:\n\n\nCode\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts, \n               concaveman, ggforce)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#datasets",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#datasets",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\n\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\n\n\n\n\n\n\n\n\n\n\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\n\n\n\n\n\n\n\n\n\nCode\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\n\n\n\nCode\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\n\nThe code chunk below will be used to perform the changes.\n\n\nCode\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nCode\nglimpse(GAStech_edges)\n\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\n\n\nCode\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\n\n\nTable below shows the data structure of the reformatted GAStech_edges data frame\n\n\nCode\nglimpse(GAStech_edges_aggregated)\n\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-network-objects-using-tidygraph",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "In this section, I will create a graph data model by using tidygraph package. It provides a tidy API for graph/network manipulation. While network data itself is not tidy, it can be envisioned as two tidy tables, one for node data and one for edge data. tidygraph provides a way to switch between the two tables and provides dplyr verbs for manipulating them. Furthermore it provides access to a lot of graph algorithms with return values that facilitate their use in a tidy workflow.\nThe below 2 articles are helpful before starting the plots. - Introducing tidygraph - tidygraph 1.1 - A tidy hope\n\n\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor).\n\n\n\n\n\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\n\n\n\n\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give us the edge data and .G() will give us the tbl_graph object itself.\n\n\n\n\nIn this section, we will use tbl_graph() of tinygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, I will recommended to review to reference guide of tbl_graph().\n\n\nCode\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\n\n\n\n\n\nCode\nGAStech_graph\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time.\n\n\n\n\nThe nodes tibble data frame is activated by default, but we can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\n\nCode\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#plotting-static-network-graphs-with-ggraph-package",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "ggraph is an extension of ggplot2, making it easier to carry over basic ggplot skills to the design of network graphs.\nAs in all network graph, there are three main aspects to a ggraph’s network graph, they are:\n\nnodes\nedges\nlayouts\n\nFor a comprehensive discussion of each of this aspect of graph, please refer to their respective vignettes provided.\n\n\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before getting started, it is advisable to read their respective reference guide at least once.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object.\n\n\n\n\n\n\nIn this section, you will use theme_graph() to remove the x and y axes. Before your get started, it is advisable to read it’s reference guide at least once.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots.\n\n\n\n\n\n\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')\n\n\n\n\n\n\n\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph().\n\n\n\n\n\n\n\n\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used.\n\n\n\n\nIn this sub-portion, I will be exploring alternate plots from the following references:\n\nLayouts\ntidygraph and ggraph\n\n\nTidygraph algorithms in ggraph codeGroup_info map from aboveGrid LayoutFocal Layout (Coord Diagram)Spring-based Layout\n\n\n\n\nCode\nggraph(GAStech_graph, \n            layout = 'fr') + \n  geom_edge_link() + \n  geom_node_point(aes(size = centrality_pagerank())) + \n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggraph(GAStech_graph, \n            layout = 'fr') + \n  geom_edge_link() + \n  geom_node_point() + \n  facet_nodes(~ group_infomap())\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggraph(GAStech_graph, \n            layout = \"grid\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes()) +\n  theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ng &lt;- ggraph(GAStech_graph, \n            'focus', focus = node_is_center()) + \n  ggforce::geom_circle(aes(x0 = 0, y0 = 0, r = r), data.frame(r = 1:3), colour = 'grey') + \n  geom_edge_link() + \n  geom_node_point() + \n  coord_fixed()\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggraph(GAStech_graph, \n            layout = \"kk\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes()) +\n  theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section, you will colour each node by referring to their respective departments.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chnuks above colour and size are used.\n\n\n\n\nIn the code chunk below, the thickness of the edges will be mapped with the Weight variable.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-facet-graphs",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "Another very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, I will use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\n\nIn the code chunk below, facet_edges() is used. Before getting started, it is advisable to read it’s reference guide at least once.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\nChanging the legend positions to the bottom:\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)\n\n\n\n\n\n\n\nThe code chunk below adds frame to each graph.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')\n\n\n\n\n\n\n\nIn the code chunkc below, facet_nodes() is used. Before getting started, it is advisable to read it’s reference guide at least once.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#network-metrics-analysis",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "Centrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph.\n\n\n\n\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()\n\n\n\n\n\n\n\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(\n    group_edge_betweenness(\n      weights = Weight, \n      directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(\n    aes(\n      width=Weight), \n    alpha=0.2) +\n  scale_edge_width(\n    range = c(0.1, 5)) +\n  geom_node_point(\n    aes(colour = community))  \n\ng + theme_graph()\n\n\n\n\nIn order to support effective visual investigation, the community network above has been revised by using geom_mark_hull() of ggforce package.\n\n\n\n\n\n\nImportant\n\n\n\nPlease be reminded that to install and include ggforce and concaveman packages before running the code chunk below.\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ng &lt;- GAStech_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(community = as.factor(\n    group_optimal(weights = Weight)),\n         betweenness_measure = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_mark_hull(\n    aes(x, y, \n        group = community, \n        fill = community),  \n    alpha = 0.2,  \n    expand = unit(0.3, \"cm\"),  # Expand\n    radius = unit(0.3, \"cm\")  # Smoothness\n  ) + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(fill = Department,\n                      size = betweenness_measure),\n                      color = \"black\",\n                      shape = 21)\n  \ng + theme_graph()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#building-interactive-network-graph-with-visnetwork",
    "title": "Hands-on_Ex05",
    "section": "",
    "text": "visNetwork() is a R package for network visualization, using vis.js javascript library.\nvisNetwork() function uses a nodes list and edges list to create an interactive graph.\n\nThe nodes list must include an “id” column, and the edge list must have “from” and “to” columns.\nThe function also plots the labels for the nodes, using the names of the actors from the “label” column in the node list.\n\nThe resulting graph is fun to play around with.\n\nI can move the nodes and the graph will use an algorithm to keep the nodes properly spaced.\nI can also zoom in and out on the plot and move it around to re-center it.\n\n\n\n\n\n\nCode\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\nThe code chunk below will be used to plot an interactive network graph by using the data prepared.\n\n\nCode\nvisNetwork(GAStech_nodes, \n           GAStech_edges_aggregated)\n\n\n\n\n\n\n\n\n\nIn the code chunk below, Fruchterman and Reingold layout is used.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument.\n\n\n\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\n\nCode\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n\nIn the code run below visEdges() is used to symbolise the edges. - The argument arrows is used to define where to place the arrow. - The smooth argument is used to plot the edges using a smooth curve.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\nVisit Option to find out more about visEdges’s argument.\n\n\n\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\nVisit Option to find out more about visOption’s argument."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Code\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, \n               patchwork, DT) \n\n\n\n\n\n\n\nCode\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = ID),\n    stackgroups = TRUE,  binwidth = 1, method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\ngirafe(\n  ggobj = p, width_svg = 6,height_svg = 6*0.618\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nexam_data$tooltip &lt;- c(paste0( \"Name = \", exam_data$ID,\"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE, binwidth = 1, method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\ngirafe(\n  ggobj = p,width_svg = 8,height_svg = 8*0.618\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive( aes(tooltip = ID),  stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe( ggobj = p, width_svg = 6, height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\n\n\n\n\n\nCode\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, tooltip = after_stat(tooltip(y, ymax))),  \n    fun.data = \"mean_se\", geom = GeomInteractiveCol, fill = \"light blue\") +\n  \n  stat_summary(aes(y = MATHS), fun.data = mean_se, geom = \"errorbar\", width = 0.2, size = 0.2)\n\ngirafe(ggobj = gg_point, width_svg = 8, height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(  aes(data_id = CLASS),  stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL)\ngirafe(                                  \n  ggobj = p, width_svg = 6, height_svg = 6*0.618                      \n)\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(data_id = CLASS),stackgroups = TRUE,binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 6*0.618, options = list(        opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(  aes(data_id = CLASS),  stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(                                  \n  ggobj = p, width_svg = 6, height_svg = 6*0.618, options = list(                     \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)    \n\n\n\n\n\n\n\n\n\n\n\nCode\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) + geom_dotplot_interactive(              \n    aes(onclick = onclick), stackgroups = TRUE, binwidth = 1,method = \"histodot\") + scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(ggobj = p, width_svg = 6,height_svg = 6*0.618)\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) + geom_dotplot_interactive(aes(data_id = ID),              \n    stackgroups = TRUE,binwidth = 1, method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, aes(x = ENGLISH)) +\n  geom_dotplot_interactive(aes(data_id = ID),stackgroups = TRUE, binwidth = 1, method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(code = print(p1 + p2), width_svg = 6, height_svg = 3,\n       options = list( opts_hover(css = \"fill: #202020;\"),opts_hover_inv(css = \"opacity:0.2;\"))) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_ly(data = exam_data,  x = ~MATHS, y = ~ENGLISH)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_ly(data = exam_data, x = ~ENGLISH, y = ~MATHS, color = ~RACE)\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, aes(x = MATHS, y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nCode\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, aes(x = MATHS,y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, aes(x = MATHS, y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, aes(ENGLISH, MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p), \"plotly_selected\")  \n\ncrosstalk::bscols(gg, DT::datatable(d), widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#launching-r-packages",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Code\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, \n               patchwork, DT)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-the-data",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Code\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Code\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = ID),\n    stackgroups = TRUE,  binwidth = 1, method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\ngirafe(\n  ggobj = p, width_svg = 6,height_svg = 6*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Code\nexam_data$tooltip &lt;- c(paste0( \"Name = \", exam_data$ID,\"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE, binwidth = 1, method = \"histodot\") +\n  scale_y_continuous(NULL, breaks = NULL)\ngirafe(\n  ggobj = p,width_svg = 8,height_svg = 8*0.618\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Code\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive( aes(tooltip = ID),  stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe( ggobj = p, width_svg = 6, height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\n\n\n\n\n\n\n\n\n\n\nCode\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, tooltip = after_stat(tooltip(y, ymax))),  \n    fun.data = \"mean_se\", geom = GeomInteractiveCol, fill = \"light blue\") +\n  \n  stat_summary(aes(y = MATHS), fun.data = mean_se, geom = \"errorbar\", width = 0.2, size = 0.2)\n\ngirafe(ggobj = gg_point, width_svg = 8, height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(  aes(data_id = CLASS),  stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL)\ngirafe(                                  \n  ggobj = p, width_svg = 6, height_svg = 6*0.618                      \n)\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(data_id = CLASS),stackgroups = TRUE,binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 6, height_svg = 6*0.618, options = list(        opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(  aes(data_id = CLASS),  stackgroups = TRUE, binwidth = 1, method = \"histodot\") +               \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(                                  \n  ggobj = p, width_svg = 6, height_svg = 6*0.618, options = list(                     \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)    \n\n\n\n\n\n\n\n\n\n\n\nCode\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) + geom_dotplot_interactive(              \n    aes(onclick = onclick), stackgroups = TRUE, binwidth = 1,method = \"histodot\") + scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(ggobj = p, width_svg = 6,height_svg = 6*0.618)\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) + geom_dotplot_interactive(aes(data_id = ID),              \n    stackgroups = TRUE,binwidth = 1, method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, aes(x = ENGLISH)) +\n  geom_dotplot_interactive(aes(data_id = ID),stackgroups = TRUE, binwidth = 1, method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(code = print(p1 + p2), width_svg = 6, height_svg = 3,\n       options = list( opts_hover(css = \"fill: #202020;\"),opts_hover_inv(css = \"opacity:0.2;\")))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Code\nplot_ly(data = exam_data,  x = ~MATHS, y = ~ENGLISH)\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_ly(data = exam_data, x = ~ENGLISH, y = ~MATHS, color = ~RACE)\n\n\n\n\n\n\n\n\n\n\n\nCode\np &lt;- ggplot(data=exam_data, aes(x = MATHS, y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nCode\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, aes(x = MATHS,y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, aes(x = MATHS, y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\nsubplot(ggplotly(p1),\n        ggplotly(p2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on_Ex03",
    "section": "",
    "text": "Code\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\n\n\n\nCode\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, aes(ENGLISH, MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p), \"plotly_selected\")  \n\ncrosstalk::bscols(gg, DT::datatable(d), widths = 5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-the-plot-using-patchwork.",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-the-plot-using-patchwork.",
    "title": "Hands-on_Ex03",
    "section": "Creating the plot using patchwork.",
    "text": "Creating the plot using patchwork."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#scatterplot-density-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#scatterplot-density-plot",
    "title": "Hands-on_Ex03",
    "section": "Scatterplot + Density plot",
    "text": "Scatterplot + Density plot\n\n\nCode\n# Scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Marginal density plot for x-axis (MATHS)\ndensity_x &lt;- ggplot(data = exam_data, \n                    aes(x = MATHS)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n# Marginal density plot for y-axis (ENGLISH)\ndensity_y &lt;- ggplot(data = exam_data, \n                    aes(x = ENGLISH)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  coord_flip() +  # Flip to make it vertical\n  theme_minimal() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n\n# Combine plots using patchwork\ncombined_plot &lt;- density_x + \n  plot_spacer() +  # Empty space\n  scatter_plot + \n  density_y +\n  plot_layout(ncol = 2, widths = c(4, 1), heights = c(1, 4))\n\n# Display the combined plot\ncombined_plot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-the-plot-using-ggextra",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#creating-the-plot-using-ggextra",
    "title": "Hands-on_Ex03",
    "section": "Creating the plot using ggExtra",
    "text": "Creating the plot using ggExtra\n\npacman::p_load(ggExtra)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#scatterplot-density-plot-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#scatterplot-density-plot-1",
    "title": "Hands-on_Ex03",
    "section": "Scatterplot + Density plot",
    "text": "Scatterplot + Density plot\n\n\nCode\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal density plots\nggMarginal(scatter_plot,\n           type = \"density\",\n           fill = \"gray\",\n           alpha = 0.6,\n           color = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#scatterplot-boxplot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#scatterplot-boxplot",
    "title": "Hands-on_Ex03",
    "section": "Scatterplot + Boxplot",
    "text": "Scatterplot + Boxplot\n\n\nCode\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Boxplots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal boxplots\nggMarginal(scatter_plot, \n           type =\"boxplot\", \n           color = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#scatterplot-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#scatterplot-histogram",
    "title": "Hands-on_Ex03",
    "section": "Scatterplot + Histogram",
    "text": "Scatterplot + Histogram\n\n\nCode\n# Step 1: Create scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, y = ENGLISH)) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Histogram Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Step 2: Add marginal histogram plots\nggMarginal(scatter_plot, \n           type = \"histogram\",\n           color = \"black\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-scatterplot-marginal-density-plots-using-patchwork",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-scatterplot-marginal-density-plots-using-patchwork",
    "title": "Hands-on_Ex03",
    "section": "Interactive Scatterplot + Marginal Density Plots using patchwork",
    "text": "Interactive Scatterplot + Marginal Density Plots using patchwork\n\n\nCode\n# Scatter plot\nscatter_plot &lt;- ggplot(data = exam_data, \n                       aes(x = MATHS, \n                           y = ENGLISH,\n                           text = paste(\"Student\", ID,\n                                        \"&lt;br&gt;Maths: \", MATHS, \n                                        \"&lt;br&gt;English: \", ENGLISH))) +\n  geom_point(alpha = 0.8) +\n  theme_minimal() +\n  labs(title = \"Scatter Plot with Marginal Density Plots\",\n       x = \"Maths Score\",\n       y = \"English Score\")\n\n# Marginal density plot for x-axis (MATHS)\ndensity_x &lt;- ggplot(data = exam_data, \n                    aes(x = MATHS)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  theme_minimal() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank())\n\n# Marginal density plot for y-axis (ENGLISH)\ndensity_y &lt;- ggplot(data = exam_data, \n                    aes(x = ENGLISH)) +\n  geom_density(fill = \"gray\", alpha = 0.6) +\n  coord_flip() +  # Flip to make it vertical\n  theme_minimal() +\n  theme(axis.title.y = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n\ninteractive_scatter &lt;- ggplotly(scatter_plot, tooltip = \"text\")\n\n# Convert marginal plots to plotly\ninteractive_x_density &lt;- ggplotly(density_x) %&gt;% hide_legend() \ninteractive_y_density &lt;- ggplotly(density_y) %&gt;% hide_legend()\n\n# Step 3: Arrange all plots together using subplot\nfinal_plot &lt;- subplot(\n  interactive_x_density, \n  plot_spacer(),\n  interactive_scatter, \n  interactive_y_density,\n  nrows = 2, heights = c(0.2, 0.8), widths = c(0.8, 0.2),\n  shareX = TRUE, shareY = TRUE\n)\n\nfinal_plot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#launching-r-packages-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#launching-r-packages-1",
    "title": "Hands-on_Ex03",
    "section": "Launching R packages",
    "text": "Launching R packages\n\n\nCode\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on_Ex03",
    "section": "Importing Data",
    "text": "Importing Data\n\n\nCode\n# Step 1: \ncol &lt;- c(\"Country\", \"Continent\")\n\n#Step 2:\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on_Ex03",
    "section": "4.3 Animated Data Visualisation: gganimate methods",
    "text": "4.3 Animated Data Visualisation: gganimate methods\n\n4.3.1 Building a static population bubble plot\n\n\nCode\nggplot(globalPop, aes(x = Old, y = Young, size = Population,colour = Country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', x = '% Aged', y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\n4.3.2 Building the animated bubble plot\n\n\nCode\nggplot(globalPop, aes(x = Old, y = Young, size = Population, colour = Country)) +\n  geom_point(alpha = 0.7, show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', x = '% Aged', y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-plotly",
    "title": "Hands-on_Ex03",
    "section": "4.4 Animated Data Visualisation: plotly",
    "text": "4.4 Animated Data Visualisation: plotly\n\n4.4.1 Building an animated bubble plot: ggplotly() method\n\n\nCode\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n4.4.2 Building an animated bubble plot: plot_ly() method\n\n\nCode\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n\nCode\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, DT) \n\n\n\n\n\n\n\nCode\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n\n\nCode\nggplot(data = exam_data, aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\n\nCode\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, DT)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Code\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Code\nggplot(data = exam_data, aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#introducing-ggplot",
    "title": "Hands-on Exercise 1",
    "section": "1.3 Introducing ggplot",
    "text": "1.3 Introducing ggplot\n\n1.3.1 R Graphics VS ggplot\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, boundary = 100, color=\"black\", fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "1.4 Grammar of Graphics",
    "text": "1.4 Grammar of Graphics\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\n\n1.4.1 A Layered Grammaer of Graphics\n\nA short description of each building block are as follows:\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1",
    "section": "1.5 Essential Grammatical Elements in ggplot2: data",
    "text": "1.5 Essential Grammatical Elements in ggplot2: data\n\n\nCode\nggplot(data=exam_data)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data-1",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data-1",
    "title": "Hands-on Exercise 1",
    "section": "1.6 Essential Grammatical Elements in ggplot2: data",
    "text": "1.6 Essential Grammatical Elements in ggplot2: data\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1",
    "section": "1.7 Essential Grammatical Elements in ggplot2: Aesthetic mappings",
    "text": "1.7 Essential Grammatical Elements in ggplot2: Aesthetic mappings\n\n1.7.1 Geometric Objects: geom_bar\n\n\nCode\nggplot(data=exam_data, aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n1.7.2 Geometric Objects: geom_dotplot\n\n\nCode\nggplot(data=exam_data, aes(x=MATHS)) +\n  geom_dotplot(binwidth=2.5, dotsize = 0.5) +\n  scale_y_continuous(NULL, breaks = NULL)\n\n\n\n\n\n\n\n\n\n\n\n1.7.3 Geometric Objects: geom_histogram()\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\n1.7.4 Modifying a geometric object by changing geom()\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\n\n\n\n1.7.5 Modifying a geometric object by changing aes()\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS, fill = GENDER)) +\n  geom_histogram(bins=20, color=\"grey30\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-1-science-and-gender-histogram",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-1-science-and-gender-histogram",
    "title": "Hands-on Exercise 1",
    "section": "(Alternate 1) Science and Gender Histogram",
    "text": "(Alternate 1) Science and Gender Histogram\n\n\nCode\nggplot(data=exam_data, aes(x = SCIENCE, fill = GENDER)) +\n  geom_histogram(bins=15, color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n1.7.6 Geometric Objects: geom-density()\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS, colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\n1.7.7 Geometric Objects: geom_boxplot\n\n\nCode\nggplot(data=exam_data, aes(y = MATHS, x = GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n1.7.8 Geometric Objects: geom_violin\n\n\nCode\nggplot(data=exam_data, aes(y = MATHS, x = GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-2-science-and-gender-violin-plots",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-2-science-and-gender-violin-plots",
    "title": "Hands-on Exercise 1",
    "section": "(Alternate 2) Science and Gender Violin plots",
    "text": "(Alternate 2) Science and Gender Violin plots\n\n\nCode\nggplot(data=exam_data, aes(y = SCIENCE, x = GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n1.7.9 Geometric Objects: geom_point()\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS, y = ENGLISH)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n1.7.10 geom objects can be combined\n\n\nCode\nggplot(data=exam_data, aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", size = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-stat",
    "title": "Hands-on Exercise 1",
    "section": "1.8 Essential Grammatical Elements in ggplot2: stat",
    "text": "1.8 Essential Grammatical Elements in ggplot2: stat\n\n1.8.1 Working with stat()\n\n\nCode\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n1.8.2 Working with stat - the stat_summary() method\n\n\nCode\nggplot(data=exam_data, aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\", fun = \"mean\",colour =\"red\", size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-3-math-and-race-boxplots",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-3-math-and-race-boxplots",
    "title": "Hands-on Exercise 1",
    "section": "(Alternate 3) Math and Race Boxplots",
    "text": "(Alternate 3) Math and Race Boxplots\n\n\nCode\nggplot(data=exam_data, \n       aes(y = MATHS, x= RACE)) +\n  geom_boxplot() +\n  geom_point(stat = \"summary\", fun = \"mean\", colour =\"red\", size=3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-4-science-and-race-boxplots",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-4-science-and-race-boxplots",
    "title": "Hands-on Exercise 1",
    "section": "(Alternate 4) Science and Race Boxplots",
    "text": "(Alternate 4) Science and Race Boxplots\n\n\nCode\nggplot(data=exam_data, \n       aes(y = SCIENCE, x= RACE)) +\n  geom_boxplot() +\n  geom_point(stat = \"summary\", fun = \"mean\", colour =\"blue\", size=3)               \n\n\n\n\n\n\n\n\n\n\n1.8.3 Working with stat - the geom() method\n\n\nCode\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat = \"summary\", fun = \"mean\", colour =\"red\", size=4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-5-english-and-science-scatterplot-with-best-fit-curve",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-5-english-and-science-scatterplot-with-best-fit-curve",
    "title": "Hands-on Exercise 1",
    "section": "(Alternate 5) English and Science Scatterplot with Best Fit curve",
    "text": "(Alternate 5) English and Science Scatterplot with Best Fit curve\n\n\nCode\nggplot(data=exam_data, \n       aes(x= ENGLISH, y=SCIENCE)) +\n  geom_point() +\n  geom_smooth(method=lm, linewidth=1)         \n\n\n\n\n\n\n\n\n\n\n1.8.4 Adding a best fit curve on a scatterplot\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, linewidth=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-facets",
    "title": "Hands-on Exercise 1",
    "section": "1.9 Essential Grammatical Elements in ggplot2: Facets",
    "text": "1.9 Essential Grammatical Elements in ggplot2: Facets\n\n1.9.1 Working with facet_wrap()\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n1.9.2 facet_grid() function\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-coordinates",
    "title": "Hands-on Exercise 1",
    "section": "1.10 Essential Grammatical Elements in ggplot2: Coordinates",
    "text": "1.10 Essential Grammatical Elements in ggplot2: Coordinates\n\n1.10.1 Working with Coordinate\n\n\nCode\nggplot(data=exam_data, aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n1.10.2 Changing the y- and x-axis range\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, size=0.5) +\n  coord_cartesian(xlim=c(0,100), ylim=c(0,100))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-themes",
    "title": "Hands-on Exercise 1",
    "section": "1.11 Essential Grammatical Elements in ggplot2: themes",
    "text": "1.11 Essential Grammatical Elements in ggplot2: themes\n\n1.11.1 Working with theme\n\n\nCode\nggplot(data=exam_data, aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-6-density-plot-with-math",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-6-density-plot-with-math",
    "title": "Hands-on Exercise 1",
    "section": "(Alternate 6) Density plot with Math",
    "text": "(Alternate 6) Density plot with Math\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_density(fill=\"#69b3a2\", color=\"#e9ecef\", alpha=0.8)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-7-scatterplot-of-science-maths-with-geom_rug",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#alternate-7-scatterplot-of-science-maths-with-geom_rug",
    "title": "Hands-on Exercise 1",
    "section": "(Alternate 7) Scatterplot of Science & Maths with geom_rug()",
    "text": "(Alternate 7) Scatterplot of Science & Maths with geom_rug()\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS, y = SCIENCE)) +\n  geom_point() +\n  geom_rug(col=\"steelblue\",alpha=0.1, size=1.5)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "About this site\nHi there! I am Andre Ong, this site is created by me as a part-time Masters of IT in Business (Data Science and Analytics) student at SMU.\nI will be showcasing some hands-on exercises on this website to practice the visualisation codes and models."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\nCareer wise, I have worked across project & engineering roles in the private sector for both start-ups and MNCs.\nI enjoy working with data and solve business problems with it. Do feel free to connect with me as I would love to hear about your experiences!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\nlibrary(extrafont)\n\n\n\n\n\n\nCode\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, DT) \n\n\n\n\n\n\n\nCode\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\n###2.3.1 Working with ggrepel\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, \n       aes(x= SCIENCE, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100, color=\"grey25\", fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100, color=\"grey25\", fill=\"grey80\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, aes(x = SCIENCE)) +\n  geom_histogram(bins=20, boundary = 100, color=\"grey25\", fill=\"grey80\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100, color=\"grey25\", fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\nCode\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np4 &lt;- ggplot(data=exam_data, \n             aes(x = SCIENCE)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Science scores\")\n\np1 + p2 + p4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np5 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=SCIENCE)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=1.5) +  \n  coord_cartesian(xlim=c(5,105),\n                  ylim=c(5,105)) +\n  ggtitle(\"Science scores versus Maths scores for Primary 3\")\n\n(p1 / p4) | p5\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npatchwork &lt;- (p1 / p4) | p5\npatchwork & theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npatchwork &lt;- (p1 / p2) | p3   \npatchwork & theme_tufte()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np5 + inset_element(p4, \n                   left = 0.01, \n                   bottom = 0.65, \n                   right = 0.5, \n                   top = 1)  + theme_stata()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#install-and-launching-r-packages",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, DT)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-the-data",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "###2.3.1 Working with ggrepel\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, \n       aes(x= SCIENCE, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100, color=\"grey25\", fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100, color=\"grey25\", fill=\"grey80\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, aes(x = SCIENCE)) +\n  geom_histogram(bins=20, boundary = 100, color=\"grey25\", fill=\"grey80\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, boundary = 100, color=\"grey25\", fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\nCode\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np4 &lt;- ggplot(data=exam_data, \n             aes(x = SCIENCE)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Science scores\")\n\np1 + p2 + p4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n(p1 / p2) | p3"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#alternate-1-science-and-math-distribution-comparison-with-changes-to-size-and-cartesian-coords",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#alternate-1-science-and-math-distribution-comparison-with-changes-to-size-and-cartesian-coords",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\np5 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=SCIENCE)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=1.5) +  \n  coord_cartesian(xlim=c(5,105),\n                  ylim=c(5,105)) +\n  ggtitle(\"Science scores versus Maths scores for Primary 3\")\n\n(p1 / p4) | p5\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#alternate-2-creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#alternate-2-creating-a-composite-figure-by-using-patchwork-and-ggtheme",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\npatchwork &lt;- (p1 / p4) | p5\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#alternate-3-exploring-tufte-theme-with-patchwork",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#alternate-3-exploring-tufte-theme-with-patchwork",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\npatchwork &lt;- (p1 / p2) | p3   \npatchwork & theme_tufte()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#alternate-4-science-vs-math-scatter-figure-with-science-insert-changing-theme-and-coords",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#alternate-4-science-vs-math-scatter-figure-with-science-insert-changing-theme-and-coords",
    "title": "Hands-on_Ex02",
    "section": "",
    "text": "Code\np5 + inset_element(p4, \n                   left = 0.01, \n                   bottom = 0.65, \n                   right = 0.5, \n                   top = 1)  + theme_stata()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this chapter, I will be using two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.\nLoading Packages:\n\n\nCode\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, \n               patchwork, DT, dplyr, scales, forcats, dplyr, grid,\n               ggdist, ggridges, colorspace) \n\n\nLoading dataset\n\n\nCode\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n Note:\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If there is less than ~6 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, I will be plotting ridgeline plots by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient().\nBoth geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\nNote It is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()\n\n\n\n\n\n\n\n\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, I will be creating a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\nNote\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "In this chapter, I will be using two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.\nLoading Packages:\n\n\nCode\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, \n               patchwork, DT, dplyr, scales, forcats, dplyr, grid,\n               ggdist, ggridges, colorspace) \n\n\nLoading dataset\n\n\nCode\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "Ridgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n Note:\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If there is less than ~6 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, I will be plotting ridgeline plots by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient().\nBoth geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()\n\n\n\n\nNote It is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_viridis_d(name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")\n  ) +\n  theme_ridges()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on_Ex04",
    "section": "",
    "text": "Raincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, I will be creating a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\nNote\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA.\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(exam, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview",
    "title": "Hands-on_Ex04",
    "section": "11.1 Overview",
    "text": "11.1 Overview\nVisualising uncertainty is relatively new in statistical graphics. In this chapter, I will be creating statistical graphics for visualising uncertainty using the same exam.csv. Below is the overview of plots:\n\nplot statistics error bars by using ggplot2,\nplot interactive error bars by combining ggplot2, plotly and DT,\ncreate advanced by using ggdist, and\ncreate hypothetical outcome plots (HOPs) by using ungeviz package.\n\nLoading Packages:\n\n\nCode\npacman::p_load(crosstalk, gganimate)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on_Ex04",
    "section": "11.3 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "11.3 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\nIn this section, I will plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\n\nCode\nmy_sum &lt;- exam %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nTableCode\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\n11.3.1 Plotting standard error bars of point estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by rac\")\n\n\n\n\n\nThe error bars are computed by using the formula mean+/-se.\nFor geom_point(), it is important to indicate stat=“identity”.\n\n\n\n11.3.2 Plotting confidence interval of point estimates\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    linewidth=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n11.3.3 Visualizing the uncertainty of point estimates with interactive error bars\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on_Ex04",
    "section": "11.4 Visualising Uncertainty: ggdist package",
    "text": "11.4 Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nFor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nFor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\n\n\n\n11.4.1 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\nCode\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\nFor example, in the code chunk below the following arguments are used:\n.width = 0.95 .point = median .interval = qi\n\n\nCode\nexam %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n11.4.2 Visualizing the uncertainty of point estimates: ggdist methods\nI will attempt to makeover the plot from the previous slide by showing 95% and 99% confidence intervals.\n\n\nCode\nexam %&gt;%\nggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE,\n    .width = c(0.95, 0.99),\n    aes(interval_color = stat(level)),\n    point_fill = \"grey\",\n    point_colour = \"grey\",\n    point_size = 5\n  ) +\n  #Define colors of the intervals\n  scale_color_manual(\n    values = c(\"steelblue\", \"pink\"),\n    aesthetics = \"interval_color\"\n  ) +\n  labs(\n    title = \"Visualising Confidence Intervals of Mean Scores for MATHS by RACE\",\n    subtitle = \"Mean point + multiple-interval plot\"\n  ) +\n  theme(\n    panel.background = element_rect(fill = \"transparent\", color = NA),\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    legend.background = element_rect(fill = \"transparent\", color = NA)\n  )\n\n\n\n\n\n\n\n\n\n\n\n11.4.3 Visualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\n\nCode\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on_Ex04",
    "section": "11.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "11.5 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nI will using the following ungeviz packages for this\n\n\nCode\nlibrary(ungeviz)\n\n\n\n11.5.3 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nNext, the code chunk below will be used to build the HOPs.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview-1",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#overview-1",
    "title": "Hands-on_Ex04",
    "section": "8.1 Overview",
    "text": "8.1 Overview\nFunnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. I will be doing the following plots:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\nDownloading Packages:\n\n\nCode\npacman::p_load(FunnelPlotR, knitr)\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\nLoading New Dataset:\n\n\nCode\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnelplotr-methods",
    "title": "Hands-on_Ex04",
    "section": "8.4 FunnelPlotR methods",
    "text": "8.4 FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n8.4.1 FunnelPlotR methods: The basic plot\n\n\nCode\nfunnel_plot(\n  .data = covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n8.4.2 FunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",     #&lt;&lt;\n  xrange = c(0, 6500),  #&lt;&lt;\n  yrange = c(0, 0.05)   #&lt;&lt;\n)\n\n\n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n8.4.2 FunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\n\n\nfunnel_plot(\n  .data = covid19,\n  numerator = Death,\n  denominator = Positive,\n  group = `Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on_Ex04",
    "section": "8.5 Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "8.5 Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, I will be building funnel plots step-by-step by using ggplot2.\n\n8.5.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\n\nCode\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\n8.5.2 8.5.2 Calculate lower and upper limits for 95% and 99.9% CI\n\n\nCode\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\n\n\n\n8.5.3 Plotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\n8.5.4 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#references",
    "title": "Hands-on_Ex04",
    "section": "8.6 References",
    "text": "8.6 References\n\nfunnelPlotR package\nFunnel Plots for Indirectly-standardised ratios\nChanging funnel plot options\nggplot2 package"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "By the end of this hands-on exercise, I will be creating the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\nInstalling and launching the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\nPackages:\n\n\nCode\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\n\nIn this section, I will be practicing to plot a calender heatmap programmatically by using ggplot2 package.\n\n\n\n\n\nBy the end of this section, I will:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, I will use the code chunk below to import eventlog.csv file into R environment and called the data frame as “attacks”.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\n\nCode\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\n\nCode\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\nnew field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, I required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\n\nCode\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\n\nStep 2: Preparing the tidy data frame\nIn this step, I will extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\n\nCode\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\nIn this section, I will attempt to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\n\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data = Vietnam,\n            aes(x = year, \n                y = `Vietnam`, \n                group = month), \n            colour = \"black\") +\n  geom_hline(data = hline.data, \n             aes(yintercept = avgvalue), \n             linetype = \"dashed\", \n             colour = \"red\", \n             size = 0.5) + \n  facet_grid(~month) +\n  labs(title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\",\n       x = \"\", \n       y = \"No. of Visitors\") +   \n  theme_minimal(base_family = \"Helvetica\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8))\n\n\n\n\n\n\n\n\n\n\n\n\nIn this section I will plot a slopegraph by using R.\nBefore getting start, ensure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Andre Ong Jia Kang\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor.\n\n\n\n\n\n\nI will be exploring the below additional plots for the Rice dataset.\n\nHeatmaps, Cycleplots, Barcharts, Boxplots, Linegraphs.\n\nMain purpose will be to visualize the 1) Rice production & 2) Yield over the years or countries.\n\n\n\n\n\n\nSimple and Easy\n\n\n\nFor effective data visualization, simple graphs can tell a story instead of complicated ones.\n\n\n\n\n\n\nCode\npacman::p_load(ggplot2, readr, dplyr, scales) \n\n\n\n\n\n\n\n\nLet’s plot out a heatmap to show the Rice Production values across the countries.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(rice, aes(x = Year, y = Country, fill = Production)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis(option = \"C\", labels = comma) +\n  labs(\n    title = \"Heatmap of Rice Production\",\n    x = \"Year\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 7),\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\nPlot 1 Note\n\n\n\nBased on the colour, this shows that China has the highest amount of rice production\n\n\n\n\n\n\nIf china has the highest rice production, let’s see how much China actually produces yearly against the other countries.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(rice, aes(x = Year, y = Production, color = Country, group = Country)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Rice Production Over Time\",\n    x = \"Year\",\n    y = \"Production (tonnes)\"\n  ) +\n  scale_x_continuous(breaks = pretty_breaks()) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nPlot 2 Note\n\n\n\nThe bottom few countries in the plot are hard to deduce the order. Let’s try to use bargraph to understand it further.\n\n\n\n\n\n\nUsing bargraphs with the axis, we can visualise clearly on the order of countries for total rice production and their respective values.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice %&gt;%\n  group_by(Country) %&gt;%\n  summarize(TotalProd = sum(Production, na.rm = TRUE)) %&gt;%\n  arrange(desc(TotalProd)) %&gt;%\n  ggplot(aes(x = reorder(Country, TotalProd), y = TotalProd, fill = Country)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Total Rice Production by Country\",\n    x = \"\",\n    y = \"Total Production (tonnes)\"\n  ) +\n  scale_y_continuous(labels = comma) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nPlot 3 Note\n\n\n\nThe bar graph clearly shows the distinct difference and order between the countries and the amount of rice produced.\n\n\n\n\n\n\nCuriously, I want to find out has rice production output always increased every decade.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n#| code-fold: false\n#| code-summary: \"Code\"\n#| eval: false\n\n# 2. Cycle plot: group years into decades and show within-decade patterns\n\n\nrice_cycle &lt;- rice %&gt;%\n  mutate(\n    Decade = paste0(floor((Year - 1) / 10) * 10, \"s\"),\n    YearInDecade = Year - as.numeric(substr(Decade, 1, 4))\n  ) %&gt;%\n  group_by(Decade, Year, YearInDecade) %&gt;%\n  summarize(TotalProd = sum(Production, na.rm = TRUE), .groups = \"drop\")\n\n\nggplot(rice_cycle, aes(\n  x = Year - as.numeric(substr(Decade, 1, 4)),\n  y = TotalProd,\n  color = Decade,\n  group = Decade\n)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Cycle Plot: Rice Production by Decade\",\n    x = \"Year within Decade\",\n    y = \"Total Production (tonnes)\"\n  ) +\n  scale_x_continuous(breaks = 0:10) +\n  scale_y_continuous(labels = comma) +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot 4 Note\n\n\n\nThis trend shows that countries have produced more than 2.5x the total production of rice from 1960s to 2000s.\n\n\n\n\n\n\n\n\n\nLet’s try to visualize the yield of rice production of each country.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(rice, aes(x = Year, y = Yield, color = Country, group = Country)) +\n  geom_line(linewidth = 1.2) +\n  scale_y_continuous(labels = label_comma()) +\n  labs(\n    title = \"Rice Yield by Country (1961–1980)\",\n    subtitle = \"Year: 1960 to 1980\",\n    x = \"Year\", y = \"Yield (tonnes per hectare)\",\n    caption = \"Animated line plot using gganimate\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nPlot 5 Note\n\n\n\nIt’s abit hard to visualise with line graph, a boxplot might be more suitable for this instead.\n\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(rice, aes(x = Country, y = Yield, fill = Country)) +\n  geom_boxplot(outlier.alpha = 0.4) +\n  coord_flip() +\n  labs(\n    title = \"Distribution of Rice Yield by Country\",\n    x = \"\",\n    y = \"Yield (tonnes/ha)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nPlot 6 Note\n\n\n\nThe boxplot accurately shows the spread of yield of each country. Based on the plot, u can find that Korea, Japan & China are the top 3 countries for Yield."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "By the end of this hands-on exercise, I will be creating the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "Installing and launching the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\nPackages:\n\n\nCode\npacman::p_load(scales, viridis, lubridate, ggthemes,\n               gridExtra, readxl, knitr, data.table,\n               CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "In this section, I will be practicing to plot a calender heatmap programmatically by using ggplot2 package.\n\n\n\n\n\nBy the end of this section, I will:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, I will use the code chunk below to import eventlog.csv file into R environment and called the data frame as “attacks”.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\n\nCode\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\n\nCode\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\nnew field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, I required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\n\nCode\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\n\nStep 2: Preparing the tidy data frame\nIn this step, I will extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\n\nCode\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "In this section, I will attempt to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\n\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data = Vietnam,\n            aes(x = year, \n                y = `Vietnam`, \n                group = month), \n            colour = \"black\") +\n  geom_hline(data = hline.data, \n             aes(yintercept = avgvalue), \n             linetype = \"dashed\", \n             colour = \"red\", \n             size = 0.5) + \n  facet_grid(~month) +\n  labs(title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\",\n       x = \"\", \n       y = \"No. of Visitors\") +   \n  theme_minimal(base_family = \"Helvetica\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "In this section I will plot a slopegraph by using R.\nBefore getting start, ensure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Andre Ong Jia Kang\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#extra-plots-using-rice-dataset",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#extra-plots-using-rice-dataset",
    "title": "Hands-on_Ex06",
    "section": "",
    "text": "I will be exploring the below additional plots for the Rice dataset.\n\nHeatmaps, Cycleplots, Barcharts, Boxplots, Linegraphs.\n\nMain purpose will be to visualize the 1) Rice production & 2) Yield over the years or countries.\n\n\n\n\n\n\nSimple and Easy\n\n\n\nFor effective data visualization, simple graphs can tell a story instead of complicated ones.\n\n\n\n\n\n\nCode\npacman::p_load(ggplot2, readr, dplyr, scales) \n\n\n\n\n\n\n\n\nLet’s plot out a heatmap to show the Rice Production values across the countries.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(rice, aes(x = Year, y = Country, fill = Production)) +\n  geom_tile(color = \"white\") +\n  scale_fill_viridis(option = \"C\", labels = comma) +\n  labs(\n    title = \"Heatmap of Rice Production\",\n    x = \"Year\",\n    y = \"\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 7),\n    panel.grid = element_blank()\n  )\n\n\n\n\n\n\n\n\n\n\nPlot 1 Note\n\n\n\nBased on the colour, this shows that China has the highest amount of rice production\n\n\n\n\n\n\nIf china has the highest rice production, let’s see how much China actually produces yearly against the other countries.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(rice, aes(x = Year, y = Production, color = Country, group = Country)) +\n  geom_line(size = 1) +\n  labs(\n    title = \"Rice Production Over Time\",\n    x = \"Year\",\n    y = \"Production (tonnes)\"\n  ) +\n  scale_x_continuous(breaks = pretty_breaks()) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nPlot 2 Note\n\n\n\nThe bottom few countries in the plot are hard to deduce the order. Let’s try to use bargraph to understand it further.\n\n\n\n\n\n\nUsing bargraphs with the axis, we can visualise clearly on the order of countries for total rice production and their respective values.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrice %&gt;%\n  group_by(Country) %&gt;%\n  summarize(TotalProd = sum(Production, na.rm = TRUE)) %&gt;%\n  arrange(desc(TotalProd)) %&gt;%\n  ggplot(aes(x = reorder(Country, TotalProd), y = TotalProd, fill = Country)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Total Rice Production by Country\",\n    x = \"\",\n    y = \"Total Production (tonnes)\"\n  ) +\n  scale_y_continuous(labels = comma) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nPlot 3 Note\n\n\n\nThe bar graph clearly shows the distinct difference and order between the countries and the amount of rice produced.\n\n\n\n\n\n\nCuriously, I want to find out has rice production output always increased every decade.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n#| code-fold: false\n#| code-summary: \"Code\"\n#| eval: false\n\n# 2. Cycle plot: group years into decades and show within-decade patterns\n\n\nrice_cycle &lt;- rice %&gt;%\n  mutate(\n    Decade = paste0(floor((Year - 1) / 10) * 10, \"s\"),\n    YearInDecade = Year - as.numeric(substr(Decade, 1, 4))\n  ) %&gt;%\n  group_by(Decade, Year, YearInDecade) %&gt;%\n  summarize(TotalProd = sum(Production, na.rm = TRUE), .groups = \"drop\")\n\n\nggplot(rice_cycle, aes(\n  x = Year - as.numeric(substr(Decade, 1, 4)),\n  y = TotalProd,\n  color = Decade,\n  group = Decade\n)) +\n  geom_line(size = 1.2) +\n  labs(\n    title = \"Cycle Plot: Rice Production by Decade\",\n    x = \"Year within Decade\",\n    y = \"Total Production (tonnes)\"\n  ) +\n  scale_x_continuous(breaks = 0:10) +\n  scale_y_continuous(labels = comma) +\n  theme_minimal() +\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot 4 Note\n\n\n\nThis trend shows that countries have produced more than 2.5x the total production of rice from 1960s to 2000s.\n\n\n\n\n\n\n\n\n\nLet’s try to visualize the yield of rice production of each country.\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(rice, aes(x = Year, y = Yield, color = Country, group = Country)) +\n  geom_line(linewidth = 1.2) +\n  scale_y_continuous(labels = label_comma()) +\n  labs(\n    title = \"Rice Yield by Country (1961–1980)\",\n    subtitle = \"Year: 1960 to 1980\",\n    x = \"Year\", y = \"Yield (tonnes per hectare)\",\n    caption = \"Animated line plot using gganimate\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nPlot 5 Note\n\n\n\nIt’s abit hard to visualise with line graph, a boxplot might be more suitable for this instead.\n\n\n\n\n\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(rice, aes(x = Country, y = Yield, fill = Country)) +\n  geom_boxplot(outlier.alpha = 0.4) +\n  coord_flip() +\n  labs(\n    title = \"Distribution of Rice Yield by Country\",\n    x = \"\",\n    y = \"Yield (tonnes/ha)\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nPlot 6 Note\n\n\n\nThe boxplot accurately shows the spread of yield of each country. Based on the plot, u can find that Korea, Japan & China are the top 3 countries for Yield."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview",
    "title": "Hands-on_Ex08",
    "section": "21.1 Overview",
    "text": "21.1 Overview\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, I will plot a functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started",
    "title": "Hands-on_Ex08",
    "section": "21.2 Getting Started",
    "text": "21.2 Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\n\nCode\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-data-into-r",
    "title": "Hands-on_Ex08",
    "section": "21.3 Importing Data into R",
    "text": "21.3 Importing Data into R\n\n21.3.1 The Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n21.3.2 Importing Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\n\nCode\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Andreojk\\ISS608-VAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nI can examine the content of mpsz by using the code chunk below.\n\n\nCode\nmpsz\n\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed.\n\n\n21.3.3 Importing Attribute Data into R\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\n\nCode\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\n21.3.4 Data Preparation\nBefore a thematic map can be prepared, I am required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n21.3.4.1 Data wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\n\nCode\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n\n21.3.4.2 Joining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\n\nCode\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate(across(c(PA, SZ), toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\n\nCode\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\n\nCode\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on_Ex08",
    "section": "21.4 Choropleth Mapping Geospatial Data Using tmap",
    "text": "21.4 Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n21.4.1 Plotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\n\nCode\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n21.4.2 Creating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nIn the following sub-section, we will share the tmap functions that used to plot these elements.\n\n21.4.2.1 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\n\nCode\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n21.4.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. I will explore and learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n21.4.2.3 Drawing a choropleth map using tm_fill() and tm_border()\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\") +\n  tm_borders(lwd = 0.01,  \n             fill_alpha = 0.1)\n\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n21.4.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n21.4.3.1 Plotting choropleth maps with built-in classification methods The code chunk below shows a quantile data classification that used 5 classes.\n\n21.4.3.1 Plotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"equal\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\nWarning: Maps Lie!\nDIY: Using what I have learned, I prepared choropleth maps by using different classification methods supported by tmap and compare their differences.\n\nDIY Graph 1DIY Graph 2\n\n\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"kmeans\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"fisher\",\n        n = 5)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy changing the “style”, visually the colour code for the blue “dependency ratios” are slightly different. (darker for Graph 1)\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\nDIY Graph 3DIY Graph 4\n\n\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"kmeans\",\n        n = 12)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"fisher\",\n        n = 18)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy changing the numbers “n”, we can see difference in colour ranges based on the “dependency ratios” with a wider spread of ratio value correlating to the additional colour code details. (Graph 4 has a wider ratio and range of colours compared to Graph 3)\n\n\n\n\n21.4.3.2 Plotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\n\nCode\nsummary(mpsz_pop2020$DEPENDENCY)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7867  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n21.4.4 Colour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n21.4.4.1 Using ColourBrewer palette\nTo change the colour, we assign the preferred colour to values argument of tm_scale_intervals() as shown in the code chunk below.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"quantile\",\n        n = 5,\n        values = \"-brewer.greens\")) +\n  tm_borders(fill_alpha = 0.5)\n\n\n\n\n\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n21.4.5 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n21.4.5.1 Map Legend\nIn tmap, several tm_legend() options are provided to change the placement, format and appearance of the legend.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\",\n      fill.scale = tm_scale_intervals(\n        style = \"jenks\",\n        n = 5,\n        values = \"brewer.greens\"),\n      fill.legend = tm_legend(\n        title = \"Dependency ratio\")) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\")\n\n\n\n\n\n\n\n\n\n\n\n21.4.5.2 Map style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n21.4.5.3 Cartographic Furniture Beside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_polygons(fill = \"DEPENDENCY\", \n              fill.scale = tm_scale_intervals(\n                style = \"quantile\",\n                n = 5,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                title = \"Dependency ratio\")) +\n  tm_title(\"Distribution of Dependency Ratio by planning subzone\") +\n  tm_layout(frame = TRUE) +\n  tm_borders(fill_alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\n\nCode\ntmap_style(\"white\")\n\n\n\n\n\n21.4.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n21.4.6.1 By assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\n\nCode\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\n\nCode\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\n21.4.6.2 By defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\n\nCode\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n21.4.6.3 By creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\n\nCode\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n21.4.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, I can also use selection funtion to map spatial objects meeting the selection criterion.\n\n\nCode\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference",
    "title": "Hands-on_Ex08",
    "section": "21.5 Reference",
    "text": "21.5 Reference\n\n21.5.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n21.5.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n21.5.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-1",
    "title": "Hands-on_Ex08",
    "section": "22.3 Overview",
    "text": "22.3 Overview\nProportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, I can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, I will explore and learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n22.3.1 Learning outcome\nBy the end of this hands-on exercise, we will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-1",
    "title": "Hands-on_Ex08",
    "section": "22.4 Getting Started",
    "text": "22.4 Getting Started\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\n\nCode\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#geospatial-data-wrangling-1",
    "title": "Hands-on_Ex08",
    "section": "22.5 Geospatial Data Wrangling",
    "text": "22.5 Geospatial Data Wrangling\n\n22.5.1 The data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n\n\n\n\n22.5.2 Data Import and Preparation\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\n\nCode\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\n\nCode\nlist(sgpools) \n\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n22.5.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages\n\n\nCode\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required me to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. I can search for other country’s epsg code by referring to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\n\n\n\n\nI can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\n\nCode\nlist(sgpools_sf)\n\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-proportional-symbol-map",
    "title": "Hands-on_Ex08",
    "section": "22.6 Drawing Proportional Symbol Map",
    "text": "22.6 Drawing Proportional Symbol Map\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\n\nCode\ntmap_mode(\"view\")\n\n\n\n22.6.1 It all started with an interactive point symbol map\nThe code chunks below are used to create an interactive point symbol map.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n           size = 1,\n           col = \"black\",\n           lwd = 1)\n\n\n\n\n\n\n\n\n22.6.2 Lets make it proportional\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"red\",\n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)\n\n\n\n\n\n\n\n\n\n22.6.3 Lets give it a different colour\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1)\n\n\n\n\n\n\n\n\n\n\n22.6.4 I have a twin brothers :)\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\n\nCode\ntm_shape(sgpools_sf) + \n  tm_bubbles(fill = \"OUTLET TYPE\", \n             size = \"Gp1Gp2 Winnings\",\n             col = \"black\",\n             lwd = 1) + \n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore we end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\n\nCode\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference-1",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference-1",
    "title": "Hands-on_Ex08",
    "section": "22.7 Reference",
    "text": "22.7 Reference\n\n22.7.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n22.7.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n22.7.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#overview-2",
    "title": "Hands-on_Ex08",
    "section": "23.1 Overview",
    "text": "23.1 Overview\n\n23.1.1 Objectives\nIn this in-class exercise, we will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n23.1.2 Learning outcome\nBy the end of this in-class exercise, we will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#getting-started-2",
    "title": "Hands-on_Ex08",
    "section": "23.2 Getting Started",
    "text": "23.2 Getting Started\n\n23.2.1 Installing and loading packages\n\n\nCode\npacman::p_load(tmap, tidyverse, sf)\n\n\n\n\n23.2.2 Importing data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level.\n\n\nCode\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#basic-choropleth-mapping",
    "title": "Hands-on_Ex08",
    "section": "23.3 Basic Choropleth Mapping",
    "text": "23.3 Basic Choropleth Mapping\n\n23.3.1 Visualising distribution of non-functional water point\n\n\nCode\np1 &lt;- tm_shape(NGA_wp) +\n  tm_polygons(fill = \"wp_functional\",\n             fill.scale = tm_scale_intervals(\n               style = \"equal\",\n               n = 10,\n               values = \"brewer.blues\"),\n             fill.legend = tm_legend(\n               position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Distribution of functional water point by LGAs\")\n\np2 &lt;- tm_shape(NGA_wp) + \n  tm_polygons(fill = \"total_wp\", \n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) +\n  tm_borders(lwd = 0.1, \n             fill_alpha = 1) + \n  tm_title(\"Distribution of total  water point by LGAs\")\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#choropleth-map-for-rates",
    "title": "Hands-on_Ex08",
    "section": "23.4 Choropleth Map for Rates",
    "text": "23.4 Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n23.4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\n\nCode\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n23.4.2 Plotting map of rate\n\n\nCode\ntm_shape(NGA_wp) +\n  tm_polygons(\"pct_functional\",\n              fill.scale = tm_scale_intervals(\n                style = \"equal\",\n                n = 10,\n                values = \"brewer.blues\"),\n              fill.legend = tm_legend(\n                position = c(\"right\", \"bottom\"))) + \n  tm_borders(lwd = 0.1,\n             fill_alpha = 1) +\n  tm_title(\"Rate map of functional water point by LGAs\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extreme-value-maps",
    "title": "Hands-on_Ex08",
    "section": "23.5 Extreme Value Maps",
    "text": "23.5 Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n23.5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n23.5.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\n\nCode\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\n\nStep 2: Creating customised classification and extracting values\n\n\nCode\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geometry field.\n\n\n\n\n23.5.1.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nI can give a function an evocative name that makes your code easier to understand.\nAs requirements change, I only need to update code in one place, instead of many.\nI eliminate the chance of making incidental mistakes when I copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n23.5.1.3 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\nCode\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\n23.5.1.4 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\n\nCode\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_polygons(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\n23.5.1.5 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\n\nCode\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n23.5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\n\nCode\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n23.5.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n\nCode\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\n23.5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\n\nCode\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\n23.5.2.3 Test drive the newly created function\nLet’s test the newly created function\n\n\nCode\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n23.5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\n\nCode\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\n\n\nCode\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html",
    "title": "MC1_In-class_Ex05",
    "section": "",
    "text": "Loading the R packages required.\n\n\nCode\npacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph)\n\n\nIn the code below, ‘fromJSON’ of jsonlite package is used to import MC1_graph.json file ino R.\n\n\nCode\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\n\n\nCode\nstr(kg, max.level = 1)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nData cleaning by splitting the nodes and links.\n\n\n\nCode\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tb1 &lt;- as_tibble(kg$links)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html#getting-started",
    "href": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html#getting-started",
    "title": "MC1_In-class_Ex05",
    "section": "",
    "text": "Loading the R packages required.\n\n\nCode\npacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph)\n\n\nIn the code below, ‘fromJSON’ of jsonlite package is used to import MC1_graph.json file ino R.\n\n\nCode\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\n\n\nCode\nstr(kg, max.level = 1)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nData cleaning by splitting the nodes and links.\n\n\n\nCode\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tb1 &lt;- as_tibble(kg$links)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html#initial-eda",
    "href": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html#initial-eda",
    "title": "MC1_In-class_Ex05",
    "section": "Initial EDA",
    "text": "Initial EDA\n\n\n\n\n\n\nNote\n\n\n\n\nfield names uses `` instead of ’’.\n\n\n\n\n\nCode\nggplot(data = edges_tb1,\n       aes(y = `Edge Type`)) + geom_bar()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html#creating-knowledge-graph",
    "href": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html#creating-knowledge-graph",
    "title": "MC1_In-class_Ex05",
    "section": "Creating Knowledge Graph",
    "text": "Creating Knowledge Graph\n\nStep 1: Mapping from node id to row index\n\n\nCode\nid_map &lt;- tibble(id = nodes_tbl$id,\n                 index = seq_len(\n                   nrow(nodes_tbl)\n                 ))\n\n\nThis ensures each id rom your node list is mapped to the correct row number.\n\n\nStep 2: map source and target IDs to row indices\n\n\nCode\nedges_tb1 &lt;- edges_tb1 %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;%\n  rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;%\n  rename(to = index)\n\n\n\n\nStep 3: Filter out any unmatched\n\n\nCode\nedges_tb1 &lt;- edges_tb1 %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n\n\n\nStep 4: Creating the graph\nLastly, ‘tbl_graph’ is used to create idygraph’s graph object by using the code chuk below.\n\n\nCode\ngraph &lt;- tbl_graph(nodes = nodes_tbl,\n                   edges = edges_tb1,\n                   directed = kg$directed)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html#visualising-the-knowledge-graph",
    "href": "In-class_Ex/In-class_Ex05/MC1_In-class_Ex05.html#visualising-the-knowledge-graph",
    "title": "MC1_In-class_Ex05",
    "section": "Visualising the knowledge graph",
    "text": "Visualising the knowledge graph\n\n\nCode\nset.seed(1234)\n\n\n\nVisualising the whole graph\n\n\nCode\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(alpha = 0.3,\n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`),\n                  size = 4) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE, \n                 size = 2.5) +\n  theme_void()\n\n\n\n\nVisualising the sub-graph\nIn this section, we are interested to create a sub-graph base on “Memberof” value in Edge Type column of he edges data frame.\n\nStep 1: Filter edges to only “Memberof”\n\n\nCode\ngraph_memberof &lt;- graph %&gt;%\n  activate(edges) %&gt;%\n  filter(`Edge Type` == \"MemberOf\")\n\n\n\n\nStep 2: Extract only connected nodes (i.e., used in these edges)\n\n\nCode\nused_node_indices &lt;- graph_memberof %&gt;%\n  activate(edges) %&gt;%\n  as_tibble() %&gt;%\n  select(from, to) %&gt;%\n  unlist() %&gt;%\n  unique()\n\n\n\n\nStep 3: Keep only those nodes\n\n\nCode\ngraph_memberof &lt;- graph_memberof %&gt;%\n  activate(nodes) %&gt;%\n  mutate(row_id = row_number()) %&gt;%\n  filter(row_id %in% used_node_indices) %&gt;%\n  select(-row_id) # optional cleanup\n\n\n\n\nPlot the sub-graph\n\n\nCode\nggraph(graph_memberof,\n       layout = \"fr\") +\n  geom_edge_link(alpha = 0.5,\n                 colour = \"gray\") +\n  geom_node_point(aes(color = `Node Type`),\n                  size = 1) +\n  geom_node_text(aes(label = name),\n                 repel = TRUE,\n                 size = 2.5) +\n  theme_void()"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take-Home_Ex01_Part1",
    "section": "",
    "text": "This study is obtained from a local Singapore dataset to reveal how Singapore’s resident population is distributed by age and sex across its various planning areas and subzones as of June 2024. It helps to map age cohorts geographically, examine sex-ratio, key-demographic locations and population density.\nI will be taking a look at the dataset to provide some key insights of the following stated below:\n\nRegional breakdown for policy makers allocating services such as transport based on geographic distributions.\nTarget professionals providing community healthcare or age-targeted programs for the population."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#overview",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#overview",
    "title": "Take-Home_Ex01_Part1",
    "section": "",
    "text": "This study is obtained from a local Singapore dataset to reveal how Singapore’s resident population is distributed by age and sex across its various planning areas and subzones as of June 2024. It helps to map age cohorts geographically, examine sex-ratio, key-demographic locations and population density.\nI will be taking a look at the dataset to provide some key insights of the following stated below:\n\nRegional breakdown for policy makers allocating services such as transport based on geographic distributions.\nTarget professionals providing community healthcare or age-targeted programs for the population."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-cleaning",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#data-cleaning",
    "title": "Take-Home_Ex01_Part1",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\nLaunching R packages\nLaunching R packages and libraries required.\n\n\nCode\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, ggiraph, plotly, \n               patchwork, DT, dplyr, scales, forcats, dplyr, grid) \n\n\nThe dataset “Singapore Residents by Planning Area / Subzone, Single Year of Age and Sex, June 2024” was obtained from Department of Statistics, Singapore.\n\n\nCode\ndf &lt;- read_csv(\"data/respopagesex2024.csv\")\n\n\nBefore I analyse the data, I will have a preview of the dataset to find out the number of columns ad character type of it.\n\n\nCode\nglimpse(df)\n\n\nRows: 60,424\nColumns: 6\n$ PA   &lt;chr&gt; \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo Kio\", \"Ang Mo K…\n$ SZ   &lt;chr&gt; \"Ang Mo Kio Town Centre\", \"Ang Mo Kio Town Centre\", \"Ang Mo Kio T…\n$ Age  &lt;chr&gt; \"0\", \"0\", \"1\", \"1\", \"2\", \"2\", \"3\", \"3\", \"4\", \"4\", \"5\", \"5\", \"6\", …\n$ Sex  &lt;chr&gt; \"Males\", \"Females\", \"Males\", \"Females\", \"Males\", \"Females\", \"Male…\n$ Pop  &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 30, 10, 20, 10, 20, 30, 30, 10, 3…\n$ Time &lt;dbl&gt; 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024, 2024,…\n\n\nObservations\n\nBased on the variable and data type. The dataset consists of 6 columns and 60,424 rows. 4 Columns are Character class and 2 are Number class.\nFor Age column, it is in Character class. I will keep it in this state first. In the plots that require transforming of the age data points, I will change it to Number class.\nPA - Planning Area, SZ - Subzone, Age - Single Year of Age, Sex - Male/Female, Pop - Resident Count, Time - Time/Period\n\nBefore using the data, I want to check if there is any missing values present.\n\n\nCode\nwhich(is.na(df))\n\n\ninteger(0)\n\n\nCode\nsum(is.na(df))\n\n\n[1] 0\n\n\nBased on the result, there is no missing values or “NA” values. The dataset is ready for analysis.\n\n\nAdding a column called “Region” to group the PA into the 5 Singapore Regions\nI want to further visualise the PA easier into the 5 Regions in Singapore. Using dplyr’s mutate() + case_when(), I will map each Planning Area (PA) into one of the five regions North, South, East, West and North-East using the following source website. (https://www.newlaunchesreview.com/regions-of-singapore/)\n\n\nCode\n# 3. Define the mapping and create the new column\ndf &lt;- df %&gt;%\n  mutate(\n    Region = case_when(\n      # Central Region (Core + Rest)\n      PA %in% c(\n        \"Downtown Core\", \"Outram\", \"Sentosa\", \"Rochor\", \"Orchard\", \"Newton\",\n        \"River Valley\", \"Bukit Timah\", \"Holland Road\", \"Tanglin\", \"Novena\",\n        \"Thomson\", \"Marina East\", \"Marina South\", \"Museum\", \"Singapore River\",\n        \"Bishan\", \"Bukit Merah\", \"Geylang\", \"Kallang\", \"Marine Parade\",\n        \"Queenstown\", \"Southern Islands\", \"Toa Payoh\", \"Straits View\"\n      ) ~ \"Central\",                                                          # :contentReference[oaicite:0]{index=0}\n\n      # North Region\n      PA %in% c(\n        \"Central Water Catchment\", \"Lim Chu Kang\", \"Mandai\", \"Sembawang\",\n        \"Simpang\", \"Sungei Kadut\", \"Woodlands\", \"Yishun\"\n      ) ~ \"North\",                                                            # :contentReference[oaicite:1]{index=1}\n\n      # North-East Region\n      PA %in% c(\n        \"Ang Mo Kio\", \"Hougang\", \"North-Eastern Islands\", \"Punggol\",\n        \"Seletar\", \"Sengkang\", \"Serangoon\"\n      ) ~ \"North-East\",                                                       # :contentReference[oaicite:2]{index=2}\n\n      # East Region\n      PA %in% c(\"Bedok\", \"Changi\", \"Changi Bay\", \"Paya Lebar\", \"Pasir Ris\", \"Tampines\"\n      ) ~ \"East\",                                                             # :contentReference[oaicite:3]{index=3}\n\n      # West Region\n      PA %in% c(\n        \"Bukit Batok\", \"Bukit Panjang\", \"Boon Lay\", \"Pioneer\", \"Choa Chu Kang\",\n        \"Clementi\", \"Jurong East\", \"Jurong West\", \"Tengah\", \"Tuas\",\n        \"Western Islands\", \"Western Water Catchment\", \"Benoi\", \"Ghim Moh\",\n        \"Gul\", \"Pandan Gardens\", \"Jurong Island\", \"Kent Ridge\", \"Nanyang\",\n        \"Teban Gardens\", \"Toh Tuck\", \"Tuas South\", \"West Coast\"\n      ) ~ \"West\",                                                             # :contentReference[oaicite:4]{index=4}\n\n      # Catch-all for any PAs that didn’t match\n      TRUE ~ NA_character_\n    )\n  )\n\n# 4. Inspect\nhead(df)\n\n\n# A tibble: 6 × 7\n  PA         SZ                     Age   Sex       Pop  Time Region    \n  &lt;chr&gt;      &lt;chr&gt;                  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;     \n1 Ang Mo Kio Ang Mo Kio Town Centre 0     Males      10  2024 North-East\n2 Ang Mo Kio Ang Mo Kio Town Centre 0     Females    10  2024 North-East\n3 Ang Mo Kio Ang Mo Kio Town Centre 1     Males      10  2024 North-East\n4 Ang Mo Kio Ang Mo Kio Town Centre 1     Females    10  2024 North-East\n5 Ang Mo Kio Ang Mo Kio Town Centre 2     Males      10  2024 North-East\n6 Ang Mo Kio Ang Mo Kio Town Centre 2     Females    10  2024 North-East\n\n\nI would like to check the if there are any “NA” values in the Region column.\n\n\nCode\ndf %&gt;%\n  summarise(na_count = sum(is.na(Region)))\n\n\n# A tibble: 1 × 1\n  na_count\n     &lt;int&gt;\n1        0\n\n\nWith no “NA” values present, I will proceed with check the Population count on how many “0” values present for the Sum and the respective Planning Areas.\n\n\nCode\nzero_pop_pas &lt;- df %&gt;%\n  group_by(PA) %&gt;%\n  summarise(TotalPop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  filter(TotalPop == 0)\n\n# View the PAs\nprint(zero_pop_pas)\n\n\n# A tibble: 13 × 2\n   PA                      TotalPop\n   &lt;chr&gt;                      &lt;dbl&gt;\n 1 Boon Lay                       0\n 2 Central Water Catchment        0\n 3 Changi Bay                     0\n 4 Lim Chu Kang                   0\n 5 Marina East                    0\n 6 Marina South                   0\n 7 North-Eastern Islands          0\n 8 Paya Lebar                     0\n 9 Pioneer                        0\n10 Simpang                        0\n11 Straits View                   0\n12 Tuas                           0\n13 Western Islands                0\n\n\nCode\n# If you just want a character vector of the names:\nzero_pa_names &lt;- zero_pop_pas %&gt;% pull(PA)\nprint(zero_pa_names)\n\n\n [1] \"Boon Lay\"                \"Central Water Catchment\"\n [3] \"Changi Bay\"              \"Lim Chu Kang\"           \n [5] \"Marina East\"             \"Marina South\"           \n [7] \"North-Eastern Islands\"   \"Paya Lebar\"             \n [9] \"Pioneer\"                 \"Simpang\"                \n[11] \"Straits View\"            \"Tuas\"                   \n[13] \"Western Islands\"        \n\n\n\n\nCleaning of dataset by removing Population Sum = 0\nThere are 13 Planning Areas with Population Sum = 0 is not useful for visualization. I will remove these 13 PA’s from the dataset and call the new dataset as df2.\n\n\nCode\ndf2 &lt;- df %&gt;%\n  group_by(PA) %&gt;%\n  filter(sum(Pop, na.rm = TRUE) &gt; 0) %&gt;%\n  ungroup()\n\n\nWith this, I will start the visualization graphs below."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#top-5-planning-areas-by-total-population",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#top-5-planning-areas-by-total-population",
    "title": "Take-Home_Ex01_Part1",
    "section": "1) Top 5 Planning Areas by Total Population",
    "text": "1) Top 5 Planning Areas by Total Population\nI would want a piechart plot showing the percentage spread of the population in the 5 regions. This will show where majority of the people in the transformed dataset is living at. On top of this, 2 more barchart plots to show the “Top 5” and “Bottom 5” most populated Planning Areas are in Singapore.\n\n\nCode\n# identify top 5 PAs\ntop5_pa &lt;- df2 %&gt;%\n  group_by(PA) %&gt;%\n  summarise(TotalPop = sum(Pop), .groups = \"drop\") %&gt;%\n  arrange(desc(TotalPop)) %&gt;%\n  slice_head(n = 5) %&gt;%\n  pull(PA)\n\n# prepare stacked bars by sex\np1_data &lt;- df2 %&gt;%\n  filter(PA %in% top5_pa) %&gt;%\n  group_by(PA, Sex) %&gt;%\n  summarise(Pop = sum(Pop), .groups = \"drop\")\n\np1 &lt;- ggplot(p1_data, aes(x = fct_reorder(PA, Pop), y = Pop, fill = Sex)) +\n  geom_col() +\n  coord_flip() +\n  scale_y_continuous(labels = comma) +\n  labs(\n    title = \"Top 5 Planning Areas by Population (2024)\",\n    x     = \"Planning Area\",\n    y     = \"Population\",\n    fill  = \"\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  theme(\n    plot.margin     = margin(5, 5, 5, 5),       \n    legend.key.size = unit(0.4, \"cm\"),          \n    legend.text     = element_text(size = 8),    \n    plot.title = element_text(size = 10),\n    axis.title.x = element_text(size = 8),\n    axis.title.y = element_text(size = 8)\n  )\n\n## identify bottom 5 PAs\nbottom10_pa &lt;- df2 %&gt;%\n  group_by(PA) %&gt;%\n  summarise(TotalPop = sum(Pop), .groups = \"drop\") %&gt;%\n  arrange(TotalPop) %&gt;%\n  slice_head(n = 5) %&gt;%\n  pull(PA)\n\n# 2. prepare stacked bars by sex\np2_data &lt;- df2 %&gt;%\n  filter(PA %in% bottom10_pa) %&gt;%\n  group_by(PA, Sex) %&gt;%\n  summarise(Pop = sum(Pop), .groups = \"drop\")\n\n# 3. plot\np2 &lt;- ggplot(p2_data, aes(x = fct_reorder(PA, Pop), y = Pop, fill = Sex)) +\n  geom_col() +\n  coord_flip() +\n  scale_y_continuous(labels = comma) +\n  labs(\n    title = \"Bottom 5 Planning Areas by Population (2024)\",\n    x     = \"Planning Area\",\n    y     = \"Population\",\n    fill  = \"\"\n  ) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\") +\n  theme(\n    plot.margin     = margin(5, 5, 5, 5),\n    legend.key.size = unit(0.4, \"cm\"),\n    legend.text     = element_text(size = 8),\n    plot.title = element_text(size = 10),\n    axis.title.x = element_text(size = 8),\n    axis.title.y = element_text(size = 8)\n  )\n\n# 3a. Pie chart of Region shares\np3_data &lt;- df2 %&gt;% \n  group_by(Region) %&gt;% \n  summarise(TotalPop = sum(Pop, na.rm = TRUE), .groups = \"drop\") %&gt;% \n  mutate(Percent = TotalPop / sum(TotalPop) * 100)\n\n# 2) Draw pie chart\np3 &lt;- ggplot(p3_data, aes(x = \"\", y = TotalPop, fill = Region)) +\n  geom_col(width = 1, color = \"white\") +\n  coord_polar(theta = \"y\") +\n  geom_text(aes(label = paste0(round(Percent, 1), \"%\")),\n            position = position_stack(vjust = 0.5), size = 2) +\n  labs(title = \"Population Percentage by Region\",\n       x = NULL, y = NULL, fill = NULL) +\n  theme_void() +\n  theme(\n      plot.title        = element_text(size = 10, margin = margin(b = 5), vjust = -28),\n      legend.position   = \"right\",\n      legend.key.size   = unit(0.4, \"cm\"),\n      legend.text       = element_text(size = 6),\n      legend.title      = element_blank(),\n      plot.margin       = margin(t = 5, r = 5, b = 5, l = 5)\n    )\n\n\ncombined &lt;- (p1 / p2) | p3 +\n  plot_layout(widths = c(2, 1.5)) +\n  # --- ADJUSTMENT for overall ---\n  plot_annotation(theme = theme(\n    plot.margin = margin(10, 10, 10, 10)\n  ))\n\nprint(combined)\n\n\n\n\n\n\n\n\n\nDiscussion:\n\nHighest population were from Central, West and North-East Regions based on the Pie Chart.\nThe top 5 Planning Areas collectively houses the highest resident counts above 200,000 where Tampines leads the distribution. For the bottom 5, the resident counts are below 1000 with Seletar being the lowest.\nIn each, the male/female split is roughly even with no majority of sex in a particular area. Though the bottom 5 areas has a slight female majority for some, it does not accurate reflect the cluster due to its low resident count.\nThe differences in bar lengths emphasize varying suburban densities. This can be a good insight for Planners and infrastructure teams to prioritize resource allocation (schools, clinics) where populations are largest."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#population-of-malefemale-across-the-ages",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#population-of-malefemale-across-the-ages",
    "title": "Take-Home_Ex01_Part1",
    "section": "2) Population of male/female across the ages",
    "text": "2) Population of male/female across the ages\nBased on the initial view, I would like to check the spread of ages across the population in the dataset. To visualize the distribution for male and female, we will plot a bar chart with Age as the X-axis, Population as the Y-axis and bar graphs representing the sex. For the age, I will bin them in 10-year bands for better aesthetic purposes.\n\n\nCode\ndf3 &lt;- df2 %&gt;%\n  # ensure Age is numeric\n  mutate(Age = as.numeric(Age)) %&gt;%\n  # now bin into 10-year groups\n  mutate(\n    AgeGroup = cut(\n      Age,\n      breaks = seq(0, 100, by = 10),\n      right  = FALSE,\n      labels = paste0(seq(0, 90, by = 10), \"-\", seq(9, 99, by = 10))\n    )\n  ) %&gt;%\n  group_by(AgeGroup, Sex) %&gt;%\n  summarise(Pop = sum(Pop), .groups = \"drop\")\n\ndf3 &lt;- df3 %&gt;%\n  mutate(\n    AgeGroup = fct_explicit_na(AgeGroup, na_level = \"90 and above\")\n  )\n\np4 &lt;- ggplot(df3, aes(x = AgeGroup, y = Pop, fill = Sex)) +\n  geom_col(position = \"dodge\") +\n  scale_y_continuous(labels = comma) +\n  labs(\n    title = \"Population by Age Group and Sex (2024)\",\n    x     = \"Age Group (years)\",\n    y     = \"Population\",\n    fill  = \"\"\n  ) +\n  theme_ipsum() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"top\"\n  )\n\np4\n\n\n\n\n\n\n\n\n\nDiscussion:\n\nThe age distribution has a positive skew with most of the population in the middle age ranges.\nFemales do appear slightly higher than males from 30 years old onwards which might reflect women having longer lifespan.However, the disparity isn’t very obvious and it is well balanced distribution."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#top-4-subzones-with-highest-population-with-boxplots-of-the-age-distribution",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#top-4-subzones-with-highest-population-with-boxplots-of-the-age-distribution",
    "title": "Take-Home_Ex01_Part1",
    "section": "3) Top 4 subzones with highest population with boxplots of the age distribution",
    "text": "3) Top 4 subzones with highest population with boxplots of the age distribution\nI would like to find out the highest 4 subzones in Tampines based on the population graph. To see which subzones contributed to it and what is the age group living there. I will first plot a barchart and also boxplot to visualize these properly.\n\n\nCode\n# 1) Find & alphabetize your top 4 subzones\ntop4_sz &lt;- df2 %&gt;%\n  filter(PA == \"Tampines\") %&gt;%\n  group_by(SZ) %&gt;% \n  summarise(TotalPop = sum(Pop), .groups = \"drop\") %&gt;% \n  slice_max(TotalPop, n = 4) %&gt;% \n  pull(SZ)\n\nalpha_levels &lt;- sort(top4_sz)\n\n# 2) Bar‐chart data (with ordered factor)\nbar_data &lt;- df2 %&gt;% \n  filter(SZ %in% top4_sz) %&gt;% \n  group_by(SZ) %&gt;% \n  summarise(TotalPop = sum(Pop), .groups = \"drop\") %&gt;%\n  mutate(SZ = factor(SZ, levels = alpha_levels))\n\np_bar &lt;- ggplot(bar_data, aes(x = SZ, y = TotalPop)) +\n  geom_col(fill = \"darkorange\") +\n  coord_flip() +\n  scale_y_continuous(labels = comma) +\n  labs(subtitle = \"Total Population – Top 4 Subzones\", x = NULL, y = \"Population\") +\n  theme_ipsum(plot_margin = margin(8, 8, 8, 8))\n\n# 3) Boxplot data (with same ordered factor)\nbox_data &lt;- df2 %&gt;% \n  filter(SZ %in% top4_sz) %&gt;% \n  mutate(\n    Age = as.numeric(Age),\n    SZ  = factor(SZ, levels = alpha_levels)\n  ) %&gt;% \n  select(SZ, Age, Pop) %&gt;% \n  uncount(weights = Pop)\n\np_box &lt;- ggplot(box_data, aes(x = SZ, y = Age, fill = SZ)) +\n  geom_boxplot(alpha = 1.5, show.legend = FALSE) +\n  coord_flip() +\n  labs(subtitle = \"Age Distribution by Subzone\", x = NULL, y = \"Age (years)\") +\n  theme_ipsum(plot_margin = margin(8, 8, 8, 8))\n\n# 4) Combine\n(p_bar / p_box) +\n  plot_annotation(\n    title   = \"Population Size & Age Distributions in Top 4 Subzones (A–Z)\",\n    caption = \"Bars = total pop; Boxes = age spread\"\n  )\n\n\n\n\n\n\n\n\n\nDiscussion: - There is a obvious majority of the population in Tampines staying in Tampines West & East.\n\nBased on the boxplot, the IQR (Lower, Median, Upper Quantile) is between 25 to 60 years old. Only residents at Tampines North is lower between 10 to 35 years old. This could be due to newer house such as BTO at Tampines North areas.\nThis trend can inform on transport services focusing in the busiest areas at Tampines West & East as the population is significantly larger as compared to Tampines North & Simei."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take-Home_Ex02",
    "section": "",
    "text": "For Take-home Exercise 2, my group members (Hendra and Jin Yao) and I have decided to do Mini-Challenge 1.\nThrough our discussion (and the help of a wheel randomizer), we split the challenge’s questions amongst ourselves. Hendra will be doing question 2, Jin Yao will be doing question 1 and I will be doing question 3.\n\n\nMy task in MC1 is to help Silas, a local journalist to create beautiful and informative visualizations of this data and uncover new and interesting information. Below is the question I am tasked to solve.\n3.Use your visualizations to develop a profile of what it means to be a rising star in the music industry.\na. Visualize the careers of three artists. Compare and contrast their rise in popularity and influence.\nb. Using this characterization, give three predictions of who the next Oceanus Folk stars with be over the next five years.\n\n\n\nLoading the R packages required.\n\n\nCode\npacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph, visNetwork, gridExtra, igraph)\n\n\nIn the code below, ‘fromJSON’ of jsonlite package is used to import MC1_graph.json file ino R.\n\n\nCode\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\n\n\nCode\nstr(kg, max.level = 1)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nData cleaning by splitting the nodes and links.\n\n\n\nCode\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tb1 &lt;- as_tibble(kg$links)\n\n\n\n\n\nI will be checking the categories for the Nodes,Edges and their count.\n\n\nCode\nggplot(data = edges_tb1,\n       aes(y = `Edge Type`)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\nI will draw up a simple visNetwork to show the linkages of Edge Type == “MemberOf’ to respective Person and MusicalGroup nodes. This is for the initial step for visualization and checking the affliation of each Person to a Group.\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes)\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% \n  mutate(idx = row_number()) %&gt;% \n  select(id, idx)\n\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# 2. Keep only MemberOf edges and their nodes\nmember_edges    &lt;- edges_idx %&gt;% filter(`Edge Type` == \"MemberOf\")\nmember_node_ids &lt;- unique(c(member_edges$from, member_edges$to))\nmember_nodes    &lt;- nodes_tbl %&gt;% \n  mutate(idx = row_number()) %&gt;% \n  filter(idx %in% member_node_ids)\n\n# 3. Build the visNetwork nodes df using the original idx as id\nnodes_df &lt;- member_nodes %&gt;%\n  transmute(\n    id    = idx,                 # must match edges 'from'/'to'\n    label = name,\n    group = `Node Type`,\n    title = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`)\n  )\n\nnodes_df &lt;- nodes_df %&gt;% arrange(label)\n# 4. Build the edges df using the same idx values\nedges_df &lt;- member_edges %&gt;%\n  transmute(\n    from  = from,                # matches nodes_df$id\n    to    = to,                  # matches nodes_df$id\n    title = `Edge Type`\n  )\n\n# 5. Render the network\nvisNetwork(nodes_df, edges_df, height = \"600px\", width = \"100%\") %&gt;%\n  visNodes(shape = \"dot\", font = list(color = \"black\")) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 1),\n    nodesIdSelection = list(enabled = TRUE, useLabels = TRUE)\n  ) %&gt;%\n  visLegend(useGroups = TRUE, width = 0.1, position = \"right\")\n\n\n\n\n\n\n\n\n\n\nLet’s check for the most popular genres in the music industry. I want to find out which genres have the most released songs and also whether their songs have appeared on a top record chart.\n\n\n\n\n\n\nNodes to be used\n\n\n\n• notable (boolean) – whether or not the song has appeared on a top record chart\n• notoriety_date (string) – if provided, the year in which the song first appeared on a top record chart\n• genre (string) – the song’s genre\n\n\n\nTotal songs in genres (notoriety_date)Total songs in genres (notoble)\n\n\n\nLet’s find out the top genres with the most notoriety_dates.\n\n\n\nCode\nlibrary(gridExtra)\n\n# 1. Load your data\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes)\n\n# 2. Filter to Song nodes and flag notoriety\nsongs &lt;- nodes_tbl %&gt;% \n  filter(`Node Type` == \"Song\") %&gt;%\n  mutate(\n    has_notoriety = !is.na(notoriety_date)\n  )\n\n# 3. Count of songs per genre, broken down by notoriety\ngenre_counts &lt;- songs %&gt;%\n  count(genre, has_notoriety, name = \"Count\") %&gt;%\n  arrange(genre)\n\np1 &lt;- ggplot(genre_counts, aes(x = fct_reorder(genre, Count, .fun = sum), \n                               y = Count, \n                               fill = has_notoriety)) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_manual(\n    name   = \"Has Notoriety Date\",\n    values = c(`TRUE` = \"#1f78b4\", `FALSE` = \"#89aac9\"),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(\n    title = \"Number of Songs by Genre (Notoriety Date Present)\",\n    x     = NULL,\n    y     = \"Song Count\"\n  ) +\n  theme_minimal(base_size = 12)\n\n# 4. Optional: Average popularity per genre (if available)\nhas_pop &lt;- \"popularity\" %in% colnames(songs)\nif (has_pop) {\n  genre_pop &lt;- songs %&gt;%\n    group_by(genre) %&gt;%\n    summarise(AvgPopularity = mean(popularity, na.rm = TRUE),\n              .groups = \"drop\") %&gt;%\n    arrange(desc(AvgPopularity))\n  \n  p2 &lt;- ggplot(genre_pop, aes(x = fct_reorder(genre, AvgPopularity), y = AvgPopularity)) +\n    geom_col(fill = \"tomato\") +\n    coord_flip() +\n    labs(\n      title = \"Average Song Popularity by Genre\",\n      x     = NULL,\n      y     = \"Avg. Popularity\"\n    ) +\n    theme_minimal(base_size = 12)\n  \n  # 5. Display side-by-side\n  grid.arrange(p1, p2, ncol = 2)\n} else {\n  # 5. If no popularity field, just show the stacked count plot\n  print(p1)\n}\n\n\n\n\n\n\n\n\n\n\n\n\nWe get a much better representation of the total songs an whether it appeared on the top charts below.\nDream Pop has the most songs while Celtic Folk has the least amount of songs in the dataset throughout the years.\n\n\n\nCode\nlibrary(gridExtra)\n\n# 1. Load your data\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes)\n\n# 2. Filter to Song nodes and flag notable\nsongs &lt;- nodes_tbl %&gt;% \n  filter(`Node Type` == \"Song\") %&gt;%\n  mutate(\n    has_notable = (notable == TRUE)\n  )\n\n# 3. Count of songs per genre, broken down by notable\ngenre_counts &lt;- songs %&gt;%\n  count(genre, has_notable, name = \"Count\") %&gt;%\n  arrange(genre)\n\np1 &lt;- ggplot(genre_counts, aes(\n         x = fct_reorder(genre, Count, .fun = sum), \n         y = Count, \n         fill = has_notable\n       )) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_manual(\n    name   = \"Has Notable\",\n    values = c(`TRUE`  = \"#1f78b4\", \n               `FALSE` = \"grey80\"),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(\n    title = \"Number of Songs by Genre (Notable Present)\",\n    x     = NULL,\n    y     = \"Song Count\"\n  ) +\n  theme_minimal(base_size = 12)\n\n# 4. Optional: Average popularity per genre (if available)\nhas_pop &lt;- \"popularity\" %in% colnames(songs)\nif (has_pop) {\n  genre_pop &lt;- songs %&gt;%\n    group_by(genre) %&gt;%\n    summarise(AvgPopularity = mean(popularity, na.rm = TRUE),\n              .groups = \"drop\") %&gt;%\n    arrange(desc(AvgPopularity))\n  \n  p2 &lt;- ggplot(genre_pop, aes(\n           x = fct_reorder(genre, AvgPopularity), \n           y = AvgPopularity\n         )) +\n    geom_col(fill = \"tomato\") +\n    coord_flip() +\n    labs(\n      title = \"Average Song Popularity by Genre\",\n      x     = NULL,\n      y     = \"Avg. Popularity\"\n    ) +\n    theme_minimal(base_size = 12)\n  \n  # 5. Display side-by-side\n  grid.arrange(p1, p2, ncol = 2)\n} else {\n  # 5. If no popularity field, just show the stacked count plot\n  print(p1)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAfter analysis, there are songs that never get a notoriety_date chart but are still marked as notable == True. Thus, it would be better to count the notable songs instead of notoriety_date.\n\n\n\n\n\n\nLet’s find out the top 15 artists with the most notable songs in this dataset.\n\n\n\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% \n  mutate(idx = row_number())    # add an index for joining\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\n\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# 2. Identify all Person nodes\nperson_idxs &lt;- which(nodes_tbl$`Node Type` == \"Person\")\n\n# 3. Count songs marked 'notable' per Person\nnotable_tbl &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  # join to get each target song's 'notable' flag\n  left_join(\n    nodes_tbl %&gt;% select(idx, notable),\n    by = c(\"to\" = \"idx\")\n  ) %&gt;%\n  # keep only those with notable == TRUE\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableSongs\") %&gt;%\n  arrange(desc(NotableSongs))\n\n# 4. Plot the top 5 Persons by number of notable songs\ntop_n &lt;- 15\nnotable_tbl %&gt;%\n  slice_head(n = top_n) %&gt;%\n  ggplot(aes(x = fct_reorder(Person, NotableSongs), y = NotableSongs)) +\n    geom_col(fill = \"turquoise\") +\n    coord_flip() +\n    labs(\n      title = \"Top 15 Persons by Number of Notable Songs\",\n      x     = NULL,\n      y     = \"Count of Notable Songs\"\n    ) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot 6 Note\n\n\n\nWith this, I will like to visualize these 15 top performers and their affiliation to each genres just as a preview.\n\n\n\n\n\n\nThe table below shows the notable songs of the artists into the selected top 10 genres.\nTop 10 Genres based on total number of songs:\n“Dream Pop”, “Indie Folk”, “Synthwave”, “Doom Metal”, “Oceanus Folk”, “Alternative Rock”, “Southern Gothic Rock”, “Indie Rock”, “Americana”, “Psychedelic Rock”\n\n\n\nCode\n# 1. Compute total notable songs per Person\nnotable_tbl_edit &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(nodes_tbl %&gt;% select(idx, notable), by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableSongs\") %&gt;%\n  arrange(desc(NotableSongs))\n\n# 2. Define the 10 genres of interest\ngenres &lt;- c(\n  \"Dream Pop\", \"Indie Folk\", \"Synthwave\", \"Doom Metal\", \"Oceanus Folk\",\n  \"Alternative Rock\", \"Southern Gothic Rock\", \"Indie Rock\",\n  \"Americana\", \"Psychedelic Rock\"\n)\n\n# 3. Compute notable‐song counts by Person × Genre\ngenre_counts &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% \n      filter(`Node Type` == \"Song\", genre %in% genres, notable == TRUE) %&gt;%\n      select(idx, genre),\n    by = c(\"to\" = \"idx\")\n  ) %&gt;%\n  filter(!is.na(genre)) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, genre, name = \"Count\")\n\n# 4. Pivot those genres into columns for all persons\ncomparison &lt;- notable_tbl_edit %&gt;%\n  rename(AllGenres = NotableSongs) %&gt;%\n  left_join(\n    genre_counts %&gt;%\n      pivot_wider(\n        id_cols     = Person,\n        names_from  = genre,\n        values_from = Count,\n        values_fill = 0,\n        names_prefix = \"Notable_\"\n      ),\n    by = \"Person\"\n  ) %&gt;%\n  # fill any missing genre columns with zeros\n  mutate(across(where(is.numeric), ~replace_na(.x, 0))) %&gt;%\n  # reorder: Person, AllGenres, then the Notable_* genres\n  select(Person, AllGenres, starts_with(\"Notable_\"))\n\n# 5. Display as a horizontally scrollable DataTable\nlibrary(DT)\nDT::datatable(\n  comparison,\n  options = list(\n    scrollX = TRUE,\n    pageLength = 10\n  )\n)\n\n\n\n\n\n\n\n\n\nI will select the top 6 genres based on the previous plot and filter to the top 5 artists with the most notable songs.\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% \n  mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# 2. Identify all Person nodes\nperson_idxs &lt;- which(nodes_tbl$`Node Type` == \"Person\")\n\n# 3. Define your genres of interest\ngenres &lt;- c(\"Dream Pop\", \"Indie Folk\", \"Synthwave\", \"Doom Metal\", \"Oceanus Folk\", \"Southern Gothic Rock\")\n\n# 4. Build a lookup of song‐idx → genre + notable flag, for these genres\ngenre_songs &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre %in% genres) %&gt;%\n  select(idx, genre, notable)\n\n# 5. Count notable songs per Person per genre\nnotable_genre_tbl &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n    from %in% person_idxs\n  ) %&gt;%\n  inner_join(genre_songs, by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(genre, Person, name = \"NotableSongs\") %&gt;%\n  arrange(genre, desc(NotableSongs))\n\n# 6. Take top 5 Persons in each genre\ntop5_by_genre &lt;- notable_genre_tbl %&gt;%\n  group_by(genre) %&gt;%\n  slice_max(NotableSongs, n = 5, with_ties = FALSE) %&gt;%\n  ungroup()\n\n# 7. Plot small multiples\nggplot(top5_by_genre, \n       aes(x = fct_reorder(Person, NotableSongs), y = NotableSongs)) +\n  geom_col(fill = \"darkgreen\") +\n  coord_flip() +\n  facet_wrap(~ genre, scales = \"free_y\", ncol = 2) +\n  labs(\n    title = \"Top 5 Persons by Number of Notable Songs in select 6 most popular Genres\",\n    x     = NULL,\n    y     = \"Count of Notable Songs\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(strip.text = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelection\n\n\n\nBased on the charts shown, I will choose the following artist based on high number of notable songs and popular genre. I will also explore and derive some findings of the 3 artists and any characteristics on how popular & influential they are as top artist in their field.\n1. Kimberly Snyder\n2. Leyla Graf-Gotthard\n3. Szymon Pyć"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#scenario-question-3",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#scenario-question-3",
    "title": "Take-Home_Ex02",
    "section": "",
    "text": "My task in MC1 is to help Silas, a local journalist to create beautiful and informative visualizations of this data and uncover new and interesting information. Below is the question I am tasked to solve.\n3.Use your visualizations to develop a profile of what it means to be a rising star in the music industry.\na. Visualize the careers of three artists. Compare and contrast their rise in popularity and influence.\nb. Using this characterization, give three predictions of who the next Oceanus Folk stars with be over the next five years."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#getting-started",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#getting-started",
    "title": "Take-Home_Ex02",
    "section": "",
    "text": "Loading the R packages required.\n\n\nCode\npacman::p_load(tidyverse, jsonlite, SmartEDA, tidygraph, ggraph, visNetwork, gridExtra, igraph)\n\n\nIn the code below, ‘fromJSON’ of jsonlite package is used to import MC1_graph.json file ino R.\n\n\nCode\nkg &lt;- fromJSON(\"data/MC1_graph.json\")\n\n\n\n\n\n\nCode\nstr(kg, max.level = 1)\n\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi TRUE\n $ graph     :List of 2\n $ nodes     :'data.frame': 17412 obs. of  10 variables:\n $ links     :'data.frame': 37857 obs. of  4 variables:\n\n\n\n\n\n\nData cleaning by splitting the nodes and links.\n\n\n\nCode\nnodes_tbl &lt;- as_tibble(kg$nodes)\nedges_tb1 &lt;- as_tibble(kg$links)\n\n\n\n\n\nI will be checking the categories for the Nodes,Edges and their count.\n\n\nCode\nggplot(data = edges_tb1,\n       aes(y = `Edge Type`)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = nodes_tbl,\n       aes(y = `Node Type`)) + geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\nI will draw up a simple visNetwork to show the linkages of Edge Type == “MemberOf’ to respective Person and MusicalGroup nodes. This is for the initial step for visualization and checking the affliation of each Person to a Group.\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes)\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% \n  mutate(idx = row_number()) %&gt;% \n  select(id, idx)\n\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# 2. Keep only MemberOf edges and their nodes\nmember_edges    &lt;- edges_idx %&gt;% filter(`Edge Type` == \"MemberOf\")\nmember_node_ids &lt;- unique(c(member_edges$from, member_edges$to))\nmember_nodes    &lt;- nodes_tbl %&gt;% \n  mutate(idx = row_number()) %&gt;% \n  filter(idx %in% member_node_ids)\n\n# 3. Build the visNetwork nodes df using the original idx as id\nnodes_df &lt;- member_nodes %&gt;%\n  transmute(\n    id    = idx,                 # must match edges 'from'/'to'\n    label = name,\n    group = `Node Type`,\n    title = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`)\n  )\n\nnodes_df &lt;- nodes_df %&gt;% arrange(label)\n# 4. Build the edges df using the same idx values\nedges_df &lt;- member_edges %&gt;%\n  transmute(\n    from  = from,                # matches nodes_df$id\n    to    = to,                  # matches nodes_df$id\n    title = `Edge Type`\n  )\n\n# 5. Render the network\nvisNetwork(nodes_df, edges_df, height = \"600px\", width = \"100%\") %&gt;%\n  visNodes(shape = \"dot\", font = list(color = \"black\")) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 1),\n    nodesIdSelection = list(enabled = TRUE, useLabels = TRUE)\n  ) %&gt;%\n  visLegend(useGroups = TRUE, width = 0.1, position = \"right\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-exploring-for-top-artists-across-all-genres",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-exploring-for-top-artists-across-all-genres",
    "title": "Take-Home_Ex02",
    "section": "",
    "text": "Let’s check for the most popular genres in the music industry. I want to find out which genres have the most released songs and also whether their songs have appeared on a top record chart.\n\n\n\n\n\n\nNodes to be used\n\n\n\n• notable (boolean) – whether or not the song has appeared on a top record chart\n• notoriety_date (string) – if provided, the year in which the song first appeared on a top record chart\n• genre (string) – the song’s genre\n\n\n\nTotal songs in genres (notoriety_date)Total songs in genres (notoble)\n\n\n\nLet’s find out the top genres with the most notoriety_dates.\n\n\n\nCode\nlibrary(gridExtra)\n\n# 1. Load your data\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes)\n\n# 2. Filter to Song nodes and flag notoriety\nsongs &lt;- nodes_tbl %&gt;% \n  filter(`Node Type` == \"Song\") %&gt;%\n  mutate(\n    has_notoriety = !is.na(notoriety_date)\n  )\n\n# 3. Count of songs per genre, broken down by notoriety\ngenre_counts &lt;- songs %&gt;%\n  count(genre, has_notoriety, name = \"Count\") %&gt;%\n  arrange(genre)\n\np1 &lt;- ggplot(genre_counts, aes(x = fct_reorder(genre, Count, .fun = sum), \n                               y = Count, \n                               fill = has_notoriety)) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_manual(\n    name   = \"Has Notoriety Date\",\n    values = c(`TRUE` = \"#1f78b4\", `FALSE` = \"#89aac9\"),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(\n    title = \"Number of Songs by Genre (Notoriety Date Present)\",\n    x     = NULL,\n    y     = \"Song Count\"\n  ) +\n  theme_minimal(base_size = 12)\n\n# 4. Optional: Average popularity per genre (if available)\nhas_pop &lt;- \"popularity\" %in% colnames(songs)\nif (has_pop) {\n  genre_pop &lt;- songs %&gt;%\n    group_by(genre) %&gt;%\n    summarise(AvgPopularity = mean(popularity, na.rm = TRUE),\n              .groups = \"drop\") %&gt;%\n    arrange(desc(AvgPopularity))\n  \n  p2 &lt;- ggplot(genre_pop, aes(x = fct_reorder(genre, AvgPopularity), y = AvgPopularity)) +\n    geom_col(fill = \"tomato\") +\n    coord_flip() +\n    labs(\n      title = \"Average Song Popularity by Genre\",\n      x     = NULL,\n      y     = \"Avg. Popularity\"\n    ) +\n    theme_minimal(base_size = 12)\n  \n  # 5. Display side-by-side\n  grid.arrange(p1, p2, ncol = 2)\n} else {\n  # 5. If no popularity field, just show the stacked count plot\n  print(p1)\n}\n\n\n\n\n\n\n\n\n\n\n\n\nWe get a much better representation of the total songs an whether it appeared on the top charts below.\nDream Pop has the most songs while Celtic Folk has the least amount of songs in the dataset throughout the years.\n\n\n\nCode\nlibrary(gridExtra)\n\n# 1. Load your data\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes)\n\n# 2. Filter to Song nodes and flag notable\nsongs &lt;- nodes_tbl %&gt;% \n  filter(`Node Type` == \"Song\") %&gt;%\n  mutate(\n    has_notable = (notable == TRUE)\n  )\n\n# 3. Count of songs per genre, broken down by notable\ngenre_counts &lt;- songs %&gt;%\n  count(genre, has_notable, name = \"Count\") %&gt;%\n  arrange(genre)\n\np1 &lt;- ggplot(genre_counts, aes(\n         x = fct_reorder(genre, Count, .fun = sum), \n         y = Count, \n         fill = has_notable\n       )) +\n  geom_col() +\n  coord_flip() +\n  scale_fill_manual(\n    name   = \"Has Notable\",\n    values = c(`TRUE`  = \"#1f78b4\", \n               `FALSE` = \"grey80\"),\n    labels = c(\"No\", \"Yes\")\n  ) +\n  labs(\n    title = \"Number of Songs by Genre (Notable Present)\",\n    x     = NULL,\n    y     = \"Song Count\"\n  ) +\n  theme_minimal(base_size = 12)\n\n# 4. Optional: Average popularity per genre (if available)\nhas_pop &lt;- \"popularity\" %in% colnames(songs)\nif (has_pop) {\n  genre_pop &lt;- songs %&gt;%\n    group_by(genre) %&gt;%\n    summarise(AvgPopularity = mean(popularity, na.rm = TRUE),\n              .groups = \"drop\") %&gt;%\n    arrange(desc(AvgPopularity))\n  \n  p2 &lt;- ggplot(genre_pop, aes(\n           x = fct_reorder(genre, AvgPopularity), \n           y = AvgPopularity\n         )) +\n    geom_col(fill = \"tomato\") +\n    coord_flip() +\n    labs(\n      title = \"Average Song Popularity by Genre\",\n      x     = NULL,\n      y     = \"Avg. Popularity\"\n    ) +\n    theme_minimal(base_size = 12)\n  \n  # 5. Display side-by-side\n  grid.arrange(p1, p2, ncol = 2)\n} else {\n  # 5. If no popularity field, just show the stacked count plot\n  print(p1)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAfter analysis, there are songs that never get a notoriety_date chart but are still marked as notable == True. Thus, it would be better to count the notable songs instead of notoriety_date."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#top-15-artists-with-the-most-notable-songs-and-if-it-links-to-the-most-popular-genres.",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#top-15-artists-with-the-most-notable-songs-and-if-it-links-to-the-most-popular-genres.",
    "title": "Take-Home_Ex02",
    "section": "",
    "text": "Let’s find out the top 15 artists with the most notable songs in this dataset.\n\n\n\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% \n  mutate(idx = row_number())    # add an index for joining\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\n\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# 2. Identify all Person nodes\nperson_idxs &lt;- which(nodes_tbl$`Node Type` == \"Person\")\n\n# 3. Count songs marked 'notable' per Person\nnotable_tbl &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  # join to get each target song's 'notable' flag\n  left_join(\n    nodes_tbl %&gt;% select(idx, notable),\n    by = c(\"to\" = \"idx\")\n  ) %&gt;%\n  # keep only those with notable == TRUE\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableSongs\") %&gt;%\n  arrange(desc(NotableSongs))\n\n# 4. Plot the top 5 Persons by number of notable songs\ntop_n &lt;- 15\nnotable_tbl %&gt;%\n  slice_head(n = top_n) %&gt;%\n  ggplot(aes(x = fct_reorder(Person, NotableSongs), y = NotableSongs)) +\n    geom_col(fill = \"turquoise\") +\n    coord_flip() +\n    labs(\n      title = \"Top 15 Persons by Number of Notable Songs\",\n      x     = NULL,\n      y     = \"Count of Notable Songs\"\n    ) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlot 6 Note\n\n\n\nWith this, I will like to visualize these 15 top performers and their affiliation to each genres just as a preview.\n\n\n\n\n\n\nThe table below shows the notable songs of the artists into the selected top 10 genres.\nTop 10 Genres based on total number of songs:\n“Dream Pop”, “Indie Folk”, “Synthwave”, “Doom Metal”, “Oceanus Folk”, “Alternative Rock”, “Southern Gothic Rock”, “Indie Rock”, “Americana”, “Psychedelic Rock”\n\n\n\nCode\n# 1. Compute total notable songs per Person\nnotable_tbl_edit &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(nodes_tbl %&gt;% select(idx, notable), by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableSongs\") %&gt;%\n  arrange(desc(NotableSongs))\n\n# 2. Define the 10 genres of interest\ngenres &lt;- c(\n  \"Dream Pop\", \"Indie Folk\", \"Synthwave\", \"Doom Metal\", \"Oceanus Folk\",\n  \"Alternative Rock\", \"Southern Gothic Rock\", \"Indie Rock\",\n  \"Americana\", \"Psychedelic Rock\"\n)\n\n# 3. Compute notable‐song counts by Person × Genre\ngenre_counts &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% \n      filter(`Node Type` == \"Song\", genre %in% genres, notable == TRUE) %&gt;%\n      select(idx, genre),\n    by = c(\"to\" = \"idx\")\n  ) %&gt;%\n  filter(!is.na(genre)) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, genre, name = \"Count\")\n\n# 4. Pivot those genres into columns for all persons\ncomparison &lt;- notable_tbl_edit %&gt;%\n  rename(AllGenres = NotableSongs) %&gt;%\n  left_join(\n    genre_counts %&gt;%\n      pivot_wider(\n        id_cols     = Person,\n        names_from  = genre,\n        values_from = Count,\n        values_fill = 0,\n        names_prefix = \"Notable_\"\n      ),\n    by = \"Person\"\n  ) %&gt;%\n  # fill any missing genre columns with zeros\n  mutate(across(where(is.numeric), ~replace_na(.x, 0))) %&gt;%\n  # reorder: Person, AllGenres, then the Notable_* genres\n  select(Person, AllGenres, starts_with(\"Notable_\"))\n\n# 5. Display as a horizontally scrollable DataTable\nlibrary(DT)\nDT::datatable(\n  comparison,\n  options = list(\n    scrollX = TRUE,\n    pageLength = 10\n  )\n)\n\n\n\n\n\n\n\n\n\nI will select the top 6 genres based on the previous plot and filter to the top 5 artists with the most notable songs.\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% \n  mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# 2. Identify all Person nodes\nperson_idxs &lt;- which(nodes_tbl$`Node Type` == \"Person\")\n\n# 3. Define your genres of interest\ngenres &lt;- c(\"Dream Pop\", \"Indie Folk\", \"Synthwave\", \"Doom Metal\", \"Oceanus Folk\", \"Southern Gothic Rock\")\n\n# 4. Build a lookup of song‐idx → genre + notable flag, for these genres\ngenre_songs &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre %in% genres) %&gt;%\n  select(idx, genre, notable)\n\n# 5. Count notable songs per Person per genre\nnotable_genre_tbl &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n    from %in% person_idxs\n  ) %&gt;%\n  inner_join(genre_songs, by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(genre, Person, name = \"NotableSongs\") %&gt;%\n  arrange(genre, desc(NotableSongs))\n\n# 6. Take top 5 Persons in each genre\ntop5_by_genre &lt;- notable_genre_tbl %&gt;%\n  group_by(genre) %&gt;%\n  slice_max(NotableSongs, n = 5, with_ties = FALSE) %&gt;%\n  ungroup()\n\n# 7. Plot small multiples\nggplot(top5_by_genre, \n       aes(x = fct_reorder(Person, NotableSongs), y = NotableSongs)) +\n  geom_col(fill = \"darkgreen\") +\n  coord_flip() +\n  facet_wrap(~ genre, scales = \"free_y\", ncol = 2) +\n  labs(\n    title = \"Top 5 Persons by Number of Notable Songs in select 6 most popular Genres\",\n    x     = NULL,\n    y     = \"Count of Notable Songs\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(strip.text = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSelection\n\n\n\nBased on the charts shown, I will choose the following artist based on high number of notable songs and popular genre. I will also explore and derive some findings of the 3 artists and any characteristics on how popular & influential they are as top artist in their field.\n1. Kimberly Snyder\n2. Leyla Graf-Gotthard\n3. Szymon Pyć"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#popularity-comparison-overall-vs-in-genre-by-notable-songs",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#popularity-comparison-overall-vs-in-genre-by-notable-songs",
    "title": "Take-Home_Ex02",
    "section": "Popularity: Comparison Overall vs in Genre by Notable Songs",
    "text": "Popularity: Comparison Overall vs in Genre by Notable Songs\nUsing notable songs as a proxy for popularity, let’s compare the total notable songs of the selected 3 artists in their respective genre vs overall.\nThis will show how many notable songs the artist produced were actually their main genre.\n\nKimberly SnyderLeyla Graf-GotthardSzymon Pyć\n\n\n\nBased on the bar graphs, Kimberly Snyder has the most notable songs released but ties with Matthew Hancock in the Dream Pop genre. However, this also shows that Kimberly has influence on other genres.\n\n\n\nCode\nlibrary(gridExtra)\n\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map    &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\nperson_idxs &lt;- which(nodes_tbl$`Node Type` == \"Person\")\n\n# 2. Dream Pop: top 5 Persons by notable Dream Pop songs\ndp_song_idxs &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Dream Pop\") %&gt;%\n  pull(idx)\n\nnotable_dp_tbl &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs, to %in% dp_song_idxs) %&gt;%\n  left_join(nodes_tbl %&gt;% select(idx, notable), by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableDreamPopSongs\") %&gt;%\n  arrange(desc(NotableDreamPopSongs))\n\np1 &lt;- notable_dp_tbl %&gt;%\n  slice_head(n = 5) %&gt;%\n  ggplot(aes(x = fct_reorder(Person, NotableDreamPopSongs), \n             y = NotableDreamPopSongs)) +\n    geom_col(fill = \"lightblue\") +\n    coord_flip() +\n    labs(\n      title = \"Top 5 Persons by Notable Dream Pop Songs\",\n      x     = NULL,\n      y     = \"Count of Notable Dream Pop Songs\"\n    ) +\n    theme_minimal(base_size = 10)+\n    theme(\n      plot.title   = element_text(size = 10),\n      plot.subtitle= element_text(size = 8),\n      axis.title.x = element_text(size = 8),\n      axis.text    = element_text(size = 7)\n    )\n\n# 3. Selected Persons: overall notable songs\nfocus_people &lt;- c(\"Kimberly Snyder\", \"Matthew Hancock\", \n                  \"Catherine Clay\", \"Navya Sastry\", \"Kashvi Dhillon\")\n\nnotable_tbl &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(nodes_tbl %&gt;% select(idx, notable), by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableSongs\") %&gt;%\n  arrange(desc(NotableSongs))\n\nplot_tbl &lt;- tibble(Person = focus_people) %&gt;%\n  left_join(notable_tbl, by = \"Person\") %&gt;%\n  replace_na(list(NotableSongs = 0))\n\np2 &lt;- plot_tbl %&gt;%\n  ggplot(aes(x = fct_reorder(Person, NotableSongs), y = NotableSongs)) +\n    geom_col(fill = \"pink\") +\n    coord_flip() +\n    labs(\n      title    = \"Notable Songs by Selected Persons\",\n      x        = NULL,\n      y        = \"Count of Notable Songs\"\n    ) +\n    theme_minimal(base_size = 10)+\n    theme(\n      plot.title   = element_text(size = 10),\n      plot.subtitle= element_text(size = 8),\n      axis.title.x = element_text(size = 8),\n      axis.text    = element_text(size = 7)\n    )\n\n# 4. Arrange side‐by‐side\ngrid.arrange(p1, p2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nLeyla Graf-Gotthard is the top in her genre with some influence in other genres too based on overall.\n\n\n\nCode\n# 2. Dream Pop: top 5 Persons by notable Doom Metal songs\ndp_song_idxs2 &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Doom Metal\") %&gt;%\n  pull(idx)\n\nnotable_dp_tbl2 &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs, to %in% dp_song_idxs2) %&gt;%\n  left_join(nodes_tbl %&gt;% select(idx, notable), by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableDoomMetalSongs\") %&gt;%\n  arrange(desc(NotableDoomMetalSongs))\n\np3 &lt;- notable_dp_tbl2 %&gt;%\n  slice_head(n = 5) %&gt;%\n  ggplot(aes(x = fct_reorder(Person, NotableDoomMetalSongs), \n             y = NotableDoomMetalSongs)) +\n    geom_col(fill = \"lightblue\") +\n    coord_flip() +\n    labs(\n      title = \"Top 5 Persons by Doom Metal Pop Songs\",\n      x     = NULL,\n      y     = \"Count of Notable Doom Metal Songs\"\n    ) +\n    theme_minimal(base_size = 10)+\n    theme(\n      plot.title   = element_text(size = 10),\n      plot.subtitle= element_text(size = 8),\n      axis.title.x = element_text(size = 8),\n      axis.text    = element_text(size = 7)\n    )\n\n# 3. Selected Persons: overall notable songs\nfocus_people2 &lt;- c(\"Leyla Graf-Gotthard\", \"Sandro Gröttner\", \n                  \"Bernfried Stolze\", \"Belinda Knappe\", \"Alla Lorch\")\n\nnotable_tbl2 &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(nodes_tbl %&gt;% select(idx, notable), by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableSongs\") %&gt;%\n  arrange(desc(NotableSongs))\n\nplot_tbl2 &lt;- tibble(Person = focus_people2) %&gt;%\n  left_join(notable_tbl2, by = \"Person\") %&gt;%\n  replace_na(list(NotableSongs = 0))\n\np4 &lt;- plot_tbl2 %&gt;%\n  ggplot(aes(x = fct_reorder(Person, NotableSongs), y = NotableSongs)) +\n    geom_col(fill = \"pink\") +\n    coord_flip() +\n    labs(\n      title    = \"Notable Songs by Selected Persons\",\n      x        = NULL,\n      y        = \"Count of Notable Songs\"\n    ) +\n    theme_minimal(base_size = 10)+\n    theme(\n      plot.title   = element_text(size = 10),\n      plot.subtitle= element_text(size = 8),\n      axis.title.x = element_text(size = 8),\n      axis.text    = element_text(size = 7)\n    )\n\n# 4. Arrange side‐by‐side\ngrid.arrange(p3, p4, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, Szymon is the top in his genre with some influence in other genres too based on overall. He has the most number of notable songs overall.\n\n\n\nCode\n# 2. Dream Pop: top 5 Persons by notable Dream Pop songs\ndp_song_idxs3 &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Southern Gothic Rock\") %&gt;%\n  pull(idx)\n\nnotable_dp_tbl3 &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs, to %in% dp_song_idxs3) %&gt;%\n  left_join(nodes_tbl %&gt;% select(idx, notable), by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableSouthernGothicRockSongs\") %&gt;%\n  arrange(desc(NotableSouthernGothicRockSongs))\n\np5 &lt;- notable_dp_tbl3 %&gt;%\n  slice_head(n = 5) %&gt;%\n  ggplot(aes(x = fct_reorder(Person, NotableSouthernGothicRockSongs), \n             y = NotableSouthernGothicRockSongs)) +\n    geom_col(fill = \"lightblue\") +\n    coord_flip() +\n    labs(\n      title = \"Top 5 Persons by Southern Gothic Rock Songs\",\n      x     = NULL,\n      y     = \"Count of Notable Southern Gothic Rock Songs\"\n    ) +\n    theme_minimal(base_size = 10)+\n    theme(\n      plot.title   = element_text(size = 10),\n      plot.subtitle= element_text(size = 8),\n      axis.title.x = element_text(size = 8),\n      axis.text    = element_text(size = 7)\n    )\n\n# 3. Selected Persons: overall notable songs\nfocus_people3 &lt;- c(\"Szymon Pyć\", \"Urszula Stochmal\",\"Andrew Williams\",\"Jay Walters\",\"Deborah Lucas\")\n\nnotable_tbl3 &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(nodes_tbl %&gt;% select(idx, notable), by = c(\"to\" = \"idx\")) %&gt;%\n  filter(notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableSongs\") %&gt;%\n  arrange(desc(NotableSongs))\n\nplot_tbl3 &lt;- tibble(Person = focus_people3) %&gt;%\n  left_join(notable_tbl2, by = \"Person\") %&gt;%\n  replace_na(list(NotableSongs = 0))\n\np6 &lt;- plot_tbl3 %&gt;%\n  ggplot(aes(x = fct_reorder(Person, NotableSongs), y = NotableSongs)) +\n    geom_col(fill = \"pink\") +\n    coord_flip() +\n    labs(\n      title    = \"Notable Songs by Selected Persons\",\n      x        = NULL,\n      y        = \"Count of Notable Songs\"\n    ) +\n    theme_minimal(base_size = 10)+\n    theme(\n      plot.title   = element_text(size = 10),\n      plot.subtitle= element_text(size = 8),\n      axis.title.x = element_text(size = 8),\n      axis.text    = element_text(size = 7)\n    )\n\n# 4. Arrange side‐by‐side\ngrid.arrange(p5, p6, ncol = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotable Songs by Top 5 persons in Genre vs Overall\n\n\n\n\nBased on the notable songs, the selected 3 artists are the top for their genre with influences in other genres as well. This shows the popularity based on using “Notable Songs” as a proxy."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#popularity-notable-and-notoriety_date-plotted-against-release_date",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#popularity-notable-and-notoriety_date-plotted-against-release_date",
    "title": "Take-Home_Ex02",
    "section": "Popularity: Notable and Notoriety_Date plotted against release_date",
    "text": "Popularity: Notable and Notoriety_Date plotted against release_date\nLet’s take a look at the timeline of notable songs for the 3 artists. I will be using notable, release_date and notoriety_date for the respective plots.\nThis will give a broad “popularity over time” view of an artist’s impact.\n\n\n\n\n\n\nNote on Nodes used\n\n\n\nBelow is some explanation on the nodes used for the plots.\n\nNotable: “this song was popular/critically acclaimed,” regardless of whether we know its exact chart date.\nNotoriety_date: only exists for the subset of notable tracks that actually landed on the charts. It will just be a marker for precised chart‐entry timing information (not the whole thing) as it will always under-count the popularity signal.\n\n\n\n\nKimberly SnyderLeyla Graf-GotthardSzymon Pyć\n\n\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\n# 2. Build edge index\nid_map    &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# 3. Pull Kimberly Snyder’s song edges\nkim_idx &lt;- which(nodes_tbl$name == \"Kimberly Snyder\")\nkim_songs &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"), from == kim_idx) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% select(idx, notable, release_date, notoriety_date),\n    by = c(\"to\" = \"idx\")\n  )\n\n# 4. Extract years\nkim_songs &lt;- kim_songs %&gt;%\n  mutate(\n    release_year   = str_extract(release_date,    \"\\\\d{4}\") %&gt;% as.integer(),\n    notoriety_year = str_extract(notoriety_date, \"\\\\d{4}\") %&gt;% as.integer()\n  )\n\n# 5. Aggregate counts\nnotable_yearly &lt;- kim_songs %&gt;%\n  filter(notable == TRUE, !is.na(release_year)) %&gt;%\n  count(Year = release_year, name = \"Notable\") \n\ncharted_yearly &lt;- kim_songs %&gt;%\n  filter(!is.na(notoriety_year)) %&gt;%\n  count(Year = notoriety_year, name = \"Charted\")\n\ncombined &lt;- full_join(notable_yearly, charted_yearly, by = \"Year\") %&gt;%\n  replace_na(list(Notable = 0, Charted = 0)) %&gt;%\n  arrange(Year)\n\n# 6. Plot both metrics\nggplot(combined, aes(x = Year)) +\n  geom_col(aes(y = Notable, fill = \"Notable\"), alpha = 0.5, width = 0.8) +\n  geom_line(aes(y = Charted, color = \"Charted\"), size = 1) +\n  geom_point(aes(y = Charted, color = \"Charted\"), size = 2) +\n  scale_fill_manual(\n    name   = NULL,\n    values = c(Notable = \"#1f78b4\")\n  ) +\n  scale_color_manual(\n    name   = NULL,\n    values = c(Charted = \"#e31a1c\")\n  ) +\n  labs(\n    title    = \"Kimberly Snyder: Notable vs. Charted Songs by Year\",\n    subtitle = \"Bars = all Notable; Line = those with a known notoriety_date\",\n    x        = \"Year\",\n    y        = \"Song Count\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title    = element_text(size = 14),\n    plot.subtitle = element_text(size = 10),\n    axis.text     = element_text(size = 9),\n    axis.title    = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 3. Pull Kimberly Snyder’s song edges\nleyla_idx &lt;- which(nodes_tbl$name == \"Leyla Graf-Gotthard\")\nleyla_songs &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"), from == leyla_idx) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% select(idx, notable, release_date, notoriety_date),\n    by = c(\"to\" = \"idx\")\n  )\n\n# 4. Extract years\nleyla_songs &lt;- leyla_songs %&gt;%\n  mutate(\n    release_year   = str_extract(release_date,    \"\\\\d{4}\") %&gt;% as.integer(),\n    notoriety_year = str_extract(notoriety_date, \"\\\\d{4}\") %&gt;% as.integer()\n  )\n\n# 5. Aggregate counts\nnotable_yearly2 &lt;- leyla_songs %&gt;%\n  filter(notable == TRUE, !is.na(release_year)) %&gt;%\n  count(Year = release_year, name = \"Notable\") \n\ncharted_yearly2 &lt;- leyla_songs %&gt;%\n  filter(!is.na(notoriety_year)) %&gt;%\n  count(Year = notoriety_year, name = \"Charted\")\n\ncombined2 &lt;- full_join(notable_yearly2, charted_yearly2, by = \"Year\") %&gt;%\n  replace_na(list(Notable = 0, Charted = 0)) %&gt;%\n  arrange(Year)\n\n# 6. Plot both metrics\nggplot(combined2, aes(x = Year)) +\n  geom_col(aes(y = Notable, fill = \"Notable\"), alpha = 0.5, width = 0.8) +\n  geom_line(aes(y = Charted, color = \"Charted\"), size = 1) +\n  geom_point(aes(y = Charted, color = \"Charted\"), size = 2) +\n  scale_fill_manual(\n    name   = NULL,\n    values = c(Notable = \"#1f78b4\")\n  ) +\n  scale_color_manual(\n    name   = NULL,\n    values = c(Charted = \"#e31a1c\")\n  ) +\n  labs(\n    title    = \"Leyla Graf-Gotthard: Notable vs. Charted Songs by Year\",\n    subtitle = \"Bars = all Notable; Line = those with a known notoriety_date\",\n    x        = \"Year\",\n    y        = \"Song Count\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title    = element_text(size = 14),\n    plot.subtitle = element_text(size = 10),\n    axis.text     = element_text(size = 9),\n    axis.title    = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 3. Pull Kimberly Snyder’s song edges\nszymon_idx &lt;- which(nodes_tbl$name == \"Szymon Pyć\")\nszymon_songs &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"), from == szymon_idx) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% select(idx, notable, release_date, notoriety_date),\n    by = c(\"to\" = \"idx\")\n  )\n\n# 4. Extract years\nszymon_songs &lt;- szymon_songs %&gt;%\n  mutate(\n    release_year   = str_extract(release_date,    \"\\\\d{4}\") %&gt;% as.integer(),\n    notoriety_year = str_extract(notoriety_date, \"\\\\d{4}\") %&gt;% as.integer()\n  )\n\n# 5. Aggregate counts\nnotable_yearly3 &lt;- szymon_songs %&gt;%\n  filter(notable == TRUE, !is.na(release_year)) %&gt;%\n  count(Year = release_year, name = \"Notable\") \n\ncharted_yearly3 &lt;- szymon_songs %&gt;%\n  filter(!is.na(notoriety_year)) %&gt;%\n  count(Year = notoriety_year, name = \"Charted\")\n\ncombined3 &lt;- full_join(notable_yearly3, charted_yearly3, by = \"Year\") %&gt;%\n  replace_na(list(Notable = 0, Charted = 0)) %&gt;%\n  arrange(Year)\n\n# 6. Plot both metrics\nggplot(combined3, aes(x = Year)) +\n  geom_col(aes(y = Notable, fill = \"Notable\"), alpha = 0.5, width = 0.8) +\n  geom_line(aes(y = Charted, color = \"Charted\"), size = 1) +\n  geom_point(aes(y = Charted, color = \"Charted\"), size = 2) +\n  scale_fill_manual(\n    name   = NULL,\n    values = c(Notable = \"#1f78b4\")\n  ) +\n  scale_color_manual(\n    name   = NULL,\n    values = c(Charted = \"#e31a1c\")\n  ) +\n  labs(\n    title    = \"Szymon Pyć: Notable vs. Charted Songs by Year\",\n    subtitle = \"Bars = all Notable; Line = those with a known notoriety_date\",\n    x        = \"Year\",\n    y        = \"Song Count\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title    = element_text(size = 14),\n    plot.subtitle = element_text(size = 10),\n    axis.text     = element_text(size = 9),\n    axis.title    = element_text(size = 10)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotable Songs and Charted Songs across the Years\n\n\n\n\nWe can see how each of the artist is able to “maintain popularity” be due to their consistent release of “notable” songs throughout the years. This is a clear signal on how the artists still maintain their popularity."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#popularity-percentage-of-un-charted-songs-released-by-artist",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#popularity-percentage-of-un-charted-songs-released-by-artist",
    "title": "Take-Home_Ex02",
    "section": "Popularity: Percentage of un-charted songs released by artist",
    "text": "Popularity: Percentage of un-charted songs released by artist\nWe have seen the timeline and number of notable songs. Let’s find out how many songs did not chart for each of the artist.\n\nKimberly’s songsLeyla’s songsSzymon’s songs\n\n\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\n# 2. Build an edge index\nid_map    &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# 3. Find Kimberly Snyder’s index\nkim_idx &lt;- which(nodes_tbl$name == \"Kimberly Snyder\")\n\n# 4. Pull her ComposerOf/PerformerOf song edges, join the Song nodes\nkim_songs &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from == kim_idx) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% \n      filter(`Node Type` == \"Song\") %&gt;% \n      select(idx, notable),\n    by = c(\"to\" = \"idx\")\n  )\n\n# 5. Count notable vs non-notable\nsummary_tbl &lt;- kim_songs %&gt;%\n  mutate(Notable = if_else(notable, \"Yes\", \"No\")) %&gt;%\n  count(Notable) %&gt;%\n  arrange(Notable)\n\n# 6. Plot as a bar chart\n# 6. Plot as a pie chart with labels\nsummary_tbl &lt;- summary_tbl %&gt;%\n  mutate(percentage = round(n / sum(n) * 100, 1),\n         label = paste0(Notable, \"\\n\", n, \" (\", percentage, \"%)\"))\n\nggplot(summary_tbl, aes(x = \"\", y = n, fill = Notable)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  scale_fill_manual(values = c(Yes = \"#33a02c\", No = \"#ff7f00\")) +\n  geom_text(aes(label = label), position = position_stack(vjust = 0.5), size = 3) +\n  labs(\n    title = \"Kimberly Snyder: Notable vs. Non-Notable Songs\",\n    x     = NULL,\n    y     = NULL\n  ) +\n  theme_minimal(base_size = 16) +\n  theme(axis.text.x = element_blank(), \n        axis.ticks = element_blank(), \n        panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 3. Find Kimberly Snyder’s index\nleyla_idx &lt;- which(nodes_tbl$name == \"Leyla Graf-Gotthard\")\n\n# 4. Pull her ComposerOf/PerformerOf song edges, join the Song nodes\nleyla_songs &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from == leyla_idx) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% \n      filter(`Node Type` == \"Song\") %&gt;% \n      select(idx, notable),\n    by = c(\"to\" = \"idx\")\n  )\n\n# 5. Count notable vs non-notable\nsummary_tbl2 &lt;- leyla_songs %&gt;%\n  mutate(Notable = if_else(notable, \"Yes\", \"No\")) %&gt;%\n  count(Notable) %&gt;%\n  arrange(Notable)\n\n# 6. Plot as a bar chart\n# 6. Plot as a pie chart with labels\nsummary_tbl2 &lt;- summary_tbl2 %&gt;%\n  mutate(percentage = round(n / sum(n) * 100, 1),\n         label = paste0(Notable, \"\\n\", n, \" (\", percentage, \"%)\"))\n\nggplot(summary_tbl2, aes(x = \"\", y = n, fill = Notable)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  scale_fill_manual(values = c(Yes = \"#33a02c\", No = \"#ff7f00\")) +\n  geom_text(aes(label = label), position = position_stack(vjust = 0.5), size = 2.6) +\n  labs(\n    title = \"Leyla Graf-Gotthard: Notable vs. Non-Notable Songs\",\n    x     = NULL,\n    y     = NULL\n  ) +\n  theme_minimal(base_size = 16) +\n  theme(axis.text.x = element_blank(), \n        axis.ticks = element_blank(), \n        panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# 3. Find Kimberly Snyder’s index\nszymon_idx &lt;- which(nodes_tbl$name == \"Szymon Pyć\")\n\n# 4. Pull her ComposerOf/PerformerOf song edges, join the Song nodes\nszymon_songs &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\"),\n         from == szymon_idx) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% \n      filter(`Node Type` == \"Song\") %&gt;% \n      select(idx, notable),\n    by = c(\"to\" = \"idx\")\n  )\n\n# 5. Count notable vs non-notable\nsummary_tbl3 &lt;- szymon_songs %&gt;%\n  mutate(Notable = if_else(notable, \"Yes\", \"No\")) %&gt;%\n  count(Notable) %&gt;%\n  arrange(Notable)\n\n# 6. Plot as a bar chart\n# 6. Plot as a pie chart with labels\nsummary_tbl3 &lt;- summary_tbl3 %&gt;%\n  mutate(percentage = round(n / sum(n) * 100, 1),\n         label = paste0(Notable, \"\\n\", n, \" (\", percentage, \"%)\"))\n\nggplot(summary_tbl3, aes(x = \"\", y = n, fill = Notable)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  scale_fill_manual(values = c(Yes = \"#33a02c\", No = \"#ff7f00\")) +\n  geom_text(aes(label = label), position = position_stack(vjust = 0.5), size = 3) +\n  labs(\n    title = \"Szymon Pyć: Notable vs. Non-Notable Songs\",\n    x     = NULL,\n    y     = NULL\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_blank(), \n        axis.ticks = element_blank(), \n        panel.grid = element_blank())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNotable Songs vs Non-Notable Songs\n\n\n\nThese 3 artist have a majority (more than 2/3) of notable songs as compared to non-notable songs they produced. This is another good signal that shows how the artist is able to maintain popularity by releasing top charting songs consistently."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#influence-work-interactions",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#influence-work-interactions",
    "title": "Take-Home_Ex02",
    "section": "Influence: Work Interactions",
    "text": "Influence: Work Interactions\n\nI want to find out the direct influences by the 3 artist. I will visualise using a visNetwork and count number of work-type influence edges each artists has.\n\n\n\n\n\n\n\nWork-type Influences used in plots\n\n\n\nBelow are the definition of the Edge Types being used.\n\n“MemberOf” - Indicates that the source node (Person) is (or was) a member of the destination node (MusicalGroup)\n“ComposerOf” - Indicates that the source node (Person) composed the destination node (Song or Album)\n“PerformerOf” - Indicates a that the source node (Person or MusicalGroup) performed the destination node (Song or Album)\n“LyricistOf” - Indicates that the source node (Person) wrote lyrics for the destination node (Song or Album)\n“RecordedBy” - Indicates that the destination node (RecordLabel) aided in the recording process for the source node (Song or Album)\n“ProducerOf” - Indicates that the source node (Person or RecordLabel) participated in the production of the destination node’s work (Song, Album, Person, or MusicalGroup)\n“DistributedBy” - Indicates that the destination node (RecordLabel) aided in the distribution process for the source node (Song or Album)\n\n\n\n\nKimberly Snyder\n\nWork Influence Edge TypesSummary of the Edge interactions\n\n\n\n\nCode\n# 1.\nid_map &lt;- nodes_tbl %&gt;% \n  mutate(index = row_number()) %&gt;% \n  select(id, index)\n\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = index) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# 2. Filter for your chosen edge types & artist\nartists    &lt;- c(\"Kimberly Snyder\")\nedge_types &lt;- c(\"MemberOf\", \"ComposerOf\", \"PerformerOf\",\"LyricistOf\", \"RecordedBy\",\"ProducerOf\",\"DistributedBy\")\ncareer_edges &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% edge_types,\n         (from %in% which(nodes_tbl$name %in% artists)) |\n         (to   %in% which(nodes_tbl$name %in% artists)))\n\n# 3. Prune to only the nodes in those edges\ncareer_node_ids &lt;- unique(c(career_edges$from, career_edges$to))\ncareer_nodes    &lt;- nodes_tbl %&gt;% slice(career_node_ids)\n\n# 4. Build visNetwork node DF\nvn_nodes &lt;- career_nodes %&gt;%\n  mutate(\n    id    = row_number(),\n    label = name,\n    group = `Node Type`,\n    title = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`)\n  )\n\n# 5. Build visNetwork edge DF with both label & title\nid_lu &lt;- tibble(old = career_node_ids, new = vn_nodes$id)\nvn_edges &lt;- career_edges %&gt;%\n  inner_join(id_lu, by = c(\"from\" = \"old\")) %&gt;% select(-from)  %&gt;% rename(from = new) %&gt;%\n  inner_join(id_lu, by = c(\"to\"   = \"old\")) %&gt;% select(-to)    %&gt;% rename(to   = new) %&gt;%\n  transmute(\n    from,\n    to,\n    label = `Edge Type`,   # drawn on the arrow\n    title = `Edge Type`,    # hover‐tooltip\n    color = case_when(\n      label == \"MemberOf\"   ~ \"#e31a1c\",\n      label == \"ComposerOf\" ~ \"#33a02c\",\n      label == \"PerformerOf\"~ \"#1f78b4\",\n      label == \"LyricistOf\" ~ \"#ff7f00\",\n      label == \"RecordedBy\" ~ \"#6a329f\",\n      label == \"ProducerOf\" ~ \"#fce80a\",\n      label == \"DistributedBy\" ~ \"#04f3f0\",\n      TRUE                  ~ \"#888888\"\n    )\n  )\n\n# 6. Plot with edge‐labels\nvisNetwork(vn_nodes, vn_edges, height = \"600px\", width = \"100%\") %&gt;%\n  visNodes(shape = \"dot\", size =14, font = list(color = \"black\", size = 10)) %&gt;%\n  visEdges(\n    arrows = \"to\",\n    labelHighlightBold = TRUE,\n    font = list(color = \"blue\", size = 8)\n  ) %&gt;%\n  visLegend(useGroups = TRUE, width = 0.1, position = \"right\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\", randomSeed = 1234) %&gt;%\n  visPhysics(enabled = FALSE)\n\n\n\n\n\n\n\n\n\n\nCode\n# Assuming `career_edges` is already in your environment:\n# Count interactions per edge type\nedge_summary &lt;- career_edges %&gt;%\n  count(`Edge Type`, name = \"Interactions\") %&gt;%\n  arrange(Interactions)\n\n# Bar‐chart of interactions by edge type\nggplot(edge_summary, aes(\n         x = fct_reorder(`Edge Type`, Interactions),\n         y = Interactions,\n         fill = `Edge Type`\n       )) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Total Interactions by Edge Type\",\n    x     = NULL,\n    y     = \"Number of Links\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeyla Graf-Gotthard\n\nWork Influence Edge TypesSummary of the interactions\n\n\n\n\nCode\n# 2. Filter for your chosen edge types & artist\nartists2    &lt;- c(\"Leyla Graf-Gotthard\")\nedge_types &lt;- c(\"MemberOf\", \"ComposerOf\", \"PerformerOf\",\"LyricistOf\", \"RecordedBy\",\"ProducerOf\",\"DistributedBy\")\ncareer_edges2 &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% edge_types,\n         (from %in% which(nodes_tbl$name %in% artists2)) |\n         (to   %in% which(nodes_tbl$name %in% artists2)))\n\n# 3. Prune to only the nodes in those edges\ncareer_node_ids2 &lt;- unique(c(career_edges2$from, career_edges2$to))\ncareer_nodes2    &lt;- nodes_tbl %&gt;% slice(career_node_ids2)\n\n# 4. Build visNetwork node DF\nvn_nodes2 &lt;- career_nodes2 %&gt;%\n  mutate(\n    id    = row_number(),\n    label = name,\n    group = `Node Type`,\n    title = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`)\n  )\n\n# 5. Build visNetwork edge DF with both label & title\nid_lu2 &lt;- tibble(old = career_node_ids2, new = vn_nodes2$id)\nvn_edges2 &lt;- career_edges2 %&gt;%\n  inner_join(id_lu2, by = c(\"from\" = \"old\")) %&gt;% select(-from)  %&gt;% rename(from = new) %&gt;%\n  inner_join(id_lu2, by = c(\"to\"   = \"old\")) %&gt;% select(-to)    %&gt;% rename(to   = new) %&gt;%\n  transmute(\n    from,\n    to,\n    label = `Edge Type`,   # drawn on the arrow\n    title = `Edge Type`,    # hover‐tooltip\n    color = case_when(\n      label == \"MemberOf\"   ~ \"#e31a1c\",\n      label == \"ComposerOf\" ~ \"#33a02c\",\n      label == \"PerformerOf\"~ \"#1f78b4\",\n      label == \"LyricistOf\" ~ \"#ff7f00\",\n      label == \"RecordedBy\" ~ \"#6a329f\",\n      label == \"ProducerOf\" ~ \"#fce80a\",\n      label == \"DistributedBy\" ~ \"#04f3f0\",\n      TRUE                  ~ \"#888888\"\n    )\n  )\n\n# 6. Plot with edge‐labels\nvisNetwork(vn_nodes2, vn_edges2, height = \"600px\", width = \"100%\") %&gt;%\n  visNodes(shape = \"dot\", size =14, font = list(color = \"black\", size = 10)) %&gt;%\n  visEdges(\n    arrows = \"to\",\n    labelHighlightBold = TRUE,\n    font = list(color = \"blue\", size = 8)\n  ) %&gt;%\n  visLegend(useGroups = TRUE, width = 0.1, position = \"right\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\", randomSeed = 1234) %&gt;%\n  visPhysics(enabled = FALSE)\n\n\n\n\n\n\n\n\n\n\nCode\n# Assuming `career_edges` is already in your environment:\n# Count interactions per edge type\nedge_summary2 &lt;- career_edges2 %&gt;%\n  count(`Edge Type`, name = \"Interactions\") %&gt;%\n  arrange(Interactions)\n\n# Bar‐chart of interactions by edge type\nggplot(edge_summary2, aes(\n         x = fct_reorder(`Edge Type`, Interactions),\n         y = Interactions,\n         fill = `Edge Type`\n       )) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Total Interactions by Edge Type\",\n    x     = NULL,\n    y     = \"Number of Links\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSzymon Pyć\n\nWork Influence Edge TypesSummary of the interactions\n\n\n\n\nCode\n# 2. Filter for your chosen edge types & artist\nartists3    &lt;- c(\"Szymon Pyć\")\nedge_types &lt;- c(\"MemberOf\", \"ComposerOf\", \"PerformerOf\",\"LyricistOf\", \"RecordedBy\",\"ProducerOf\",\"DistributedBy\")\ncareer_edges3 &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% edge_types,\n         (from %in% which(nodes_tbl$name %in% artists3)) |\n         (to   %in% which(nodes_tbl$name %in% artists3)))\n\n# 3. Prune to only the nodes in those edges\ncareer_node_ids3 &lt;- unique(c(career_edges3$from, career_edges3$to))\ncareer_nodes3    &lt;- nodes_tbl %&gt;% slice(career_node_ids3)\n\n# 4. Build visNetwork node DF\nvn_nodes3 &lt;- career_nodes3 %&gt;%\n  mutate(\n    id    = row_number(),\n    label = name,\n    group = `Node Type`,\n    title = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`)\n  )\n\n# 5. Build visNetwork edge DF with both label & title\nid_lu3 &lt;- tibble(old = career_node_ids3, new = vn_nodes3$id)\nvn_edges3 &lt;- career_edges3 %&gt;%\n  inner_join(id_lu3, by = c(\"from\" = \"old\")) %&gt;% select(-from)  %&gt;% rename(from = new) %&gt;%\n  inner_join(id_lu3, by = c(\"to\"   = \"old\")) %&gt;% select(-to)    %&gt;% rename(to   = new) %&gt;%\n  transmute(\n    from,\n    to,\n    label = `Edge Type`,   # drawn on the arrow\n    title = `Edge Type`,    # hover‐tooltip\n    color = case_when(\n      label == \"MemberOf\"   ~ \"#e31a1c\",\n      label == \"ComposerOf\" ~ \"#33a02c\",\n      label == \"PerformerOf\"~ \"#1f78b4\",\n      label == \"LyricistOf\" ~ \"#ff7f00\",\n      label == \"RecordedBy\" ~ \"#6a329f\",\n      label == \"ProducerOf\" ~ \"#fce80a\",\n      label == \"DistributedBy\" ~ \"#04f3f0\",\n      TRUE                  ~ \"#888888\"\n    )\n  )\n\n# 6. Plot with edge‐labels\nvisNetwork(vn_nodes3, vn_edges3, height = \"600px\", width = \"100%\") %&gt;%\n  visNodes(shape = \"dot\", size =14, font = list(color = \"black\", size = 10)) %&gt;%\n  visEdges(\n    arrows = \"to\",\n    labelHighlightBold = TRUE,\n    font = list(color = \"blue\", size = 8)\n  ) %&gt;%\n  visLegend(useGroups = TRUE, width = 0.1, position = \"right\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\", randomSeed = 1234) %&gt;%\n  visPhysics(enabled = FALSE)\n\n\n\n\n\n\n\n\n\n\nCode\n# Assuming `career_edges` is already in your environment:\n# Count interactions per edge type\nedge_summary3 &lt;- career_edges3 %&gt;%\n  count(`Edge Type`, name = \"Interactions\") %&gt;%\n  arrange(Interactions)\n\n# Bar‐chart of interactions by edge type\nggplot(edge_summary3, aes(\n         x = fct_reorder(`Edge Type`, Interactions),\n         y = Interactions,\n         fill = `Edge Type`\n       )) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Total Interactions by Edge Type\",\n    x     = NULL,\n    y     = \"Number of Links\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWork-type Influences\n\n\n\nThese plots show the number of work influences by the artist within their scope."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#influence-people-interactions",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#influence-people-interactions",
    "title": "Take-Home_Ex02",
    "section": "Influence: People Interactions",
    "text": "Influence: People Interactions\nThis portion will cover how people are directly/indirectly influenced by the selected artists and their work. I will be plotting a visNetwork and barcharts for Betweenness Centrality value to show their influences.\n\n\n\n\n\n\nPeople Influences\n\n\n\n\n“InterpolatesFrom” - Indicates that the source node (Song or Album) interpolated a melody from the destination node (Song or Album).\n“DirectlySamples” - Indicates that the source node (Song or Album) consists of (an) audio recording(s) that directly reuse a portion of the audio recording of the destination node (Song or Album) via sampling.\n“InStyleOf” - Indicates that the source node (Song or Album) consists of (an) audio recording(s) that directly reuse a portion of the audio recording of the destination node (Song or Album) via sampling.\n“LyricalReferenceTo” - Indicates that the source node (Song or Album) consists of (an) audio recording(s) that directly reuse a portion of the audio recording of the destination node (Song or Album) via sampling.\n“CoverOf” - Indicates that the source node (Song or Album) is a cover of the destination node (Song or Album).\n\n\n\nVisNetwork\n\nThe visNetwork will be limited to a maximum hop of 2 to reduce messiness.\nDropdown select will be created to see the individual artists and their influences.\n\nBetweenness Centrality Value\n\nThis measures a node’s influence in a network by quantifying how often it lies on the shortest paths between other nodes.\nI will solely using this as information on what are the most relevant “bridges” controlling the flow of in the network using maximum hop of 3.\n\n\nKimberly Snyder\n\nPeople Influence EdgesBetweenness centrality in network\n\n\n\n\nCode\n# ─── 0. How many hops? ────────────────────────────────────────────────────────\nmax_hops &lt;- 2   # Change this number to 1, 2, 3… then re‐run the chunk\n\n# ─── 1. Load & index all nodes and edges ────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\n# Build numeric “from/to” index for every edge\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# ─── 2. Build an undirected igraph of the full graph ────────────────────────\ng_all &lt;- graph_from_data_frame(\n  d        = edges_idx %&gt;% select(from, to),\n  directed = FALSE,\n  vertices = nodes_tbl %&gt;% transmute(name = as.character(idx))\n)\n\n# ─── 3. Prepare list of all Person names for dropdown ───────────────────────\nall_persons &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  arrange(name) %&gt;%                # sort ascending by name\n  pull(name)\n\n# ─── 4. Create a named vector mapping Person ➔ idx (character) ─────────────\nperson_idx_map &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  transmute(Person = name, idx_char = as.character(idx)) %&gt;%\n  deframe()\n\n# ─── 5. Function to build and render a Kim‐style ego network given a name ───\nrender_ego_network &lt;- function(center_name) {\n  center_idx &lt;- person_idx_map[[center_name]]\n  if (is.null(center_idx)) {\n    stop(\"Person '\", center_name, \"' not found.\")\n  }\n  # Compute ego‐set of all vertices within max_hops of chosen person\n  ego_list   &lt;- ego(g_all, order = max_hops, nodes = center_idx, mode = \"all\")[[1]]\n  ego_indices &lt;- as.integer(V(g_all)$name[ego_list])\n  # Filter edges so both endpoints are in that ego set\n  career_edges &lt;- edges_idx %&gt;%\n    filter(from %in% ego_indices, to %in% ego_indices)\n  if (nrow(career_edges) == 0) {\n    showNotification(paste0(\n      \"No edges remain when limiting to \", max_hops,\n      \" hops out from \", center_name, \".\"\n    ), type = \"warning\")\n    return(NULL)\n  }\n  # Build list of all involved nodes\n  career_node_ids &lt;- unique(c(career_edges$from, career_edges$to))\n  career_nodes    &lt;- nodes_tbl %&gt;% slice(career_node_ids) %&gt;%\n    mutate(\n      vis_id = row_number(),\n      label  = name,\n      group  = `Node Type`,\n      title  = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`,\n                      if_else(`Node Type` == \"Song\" & !is.na(release_date),\n                              paste0(\"&lt;br&gt;Released: \", release_date), \"\"))\n    )\n  # Remap edges to vis_ids\n  career_edges &lt;- career_edges %&gt;%\n    mutate(\n      from_vis = match(from, career_node_ids),\n      to_vis   = match(to,   career_node_ids)\n    )\n  # Construct visNetwork nodes & edges\n  vn_nodes &lt;- career_nodes %&gt;%\n    transmute(id = vis_id, label = label, group = group, title = title)\n  vn_edges &lt;- career_edges %&gt;%\n    transmute(from = from_vis, to = to_vis, label = `Edge Type`, title = `Edge Type`,\n              color = case_when(\n                label == \"InterpolatesFrom\"   ~ \"#1f78b4\",\n                label == \"DirectlySamples\"    ~ \"#33a02c\",\n                label == \"InStyleOf\"          ~ \"#e31a1c\",\n                label == \"LyricalReferenceTo\" ~ \"#6a3d9a\",\n                label == \"CoverOf\"            ~ \"#fb9a99\",\n                label == \"ComposerOf\"         ~ \"#33a02c\",\n                label == \"PerformerOf\"        ~ \"#1f78b4\",\n                label == \"RecordedBy\"         ~ \"#6a329f\",\n                label == \"ProducerOf\"         ~ \"#fce80a\",\n                label == \"LyricistOf\"         ~ \"#ff7f00\",\n                TRUE                          ~ \"#888888\"\n              ))\n  # Determine vis_id for all Person‐type nodes (to allow dropdown focus)\n  person_vis_ids &lt;- vn_nodes %&gt;%\n    filter(group == \"Person\") %&gt;%\n    arrange(label) %&gt;%  # ensure sorted ascending\n    pull(id)\n  # Render visNetwork\n  visNetwork(vn_nodes, vn_edges, height = \"600px\", width = \"100%\") %&gt;%\n    visNodes(shape = \"dot\", size = 14, font = list(color = \"black\", size = 10)) %&gt;%\n    visEdges(arrows = \"to\", labelHighlightBold = TRUE, font = list(color = \"blue\", size = 7)) %&gt;%\n    visOptions(\n      highlightNearest   = list(enabled = TRUE, degree = 1),\n      nodesIdSelection   = list(\n        enabled   = TRUE,\n        useLabels = TRUE,\n        values    = person_vis_ids\n      )\n    ) %&gt;%\n    visLegend(useGroups = TRUE, width = 0.1, position = \"right\") %&gt;%\n    visIgraphLayout(layout = \"layout_with_fr\", randomSeed = 1234) %&gt;%\n    visPhysics(enabled = FALSE)\n}\n\n# ─── 6. Initial rendering for “Kimberly Snyder” ─────────────────────────────\nrender_ego_network(\"Kimberly Snyder\")\n\n\n\n\n\n\n\n\n\nKimberly had more song influences in her network.\n\n\n\nCode\n# ─── PARAMETERS ───────────────────────────────────────────────────────────────\ncenter_person &lt;- \"Kimberly Snyder\"\nmax_hops      &lt;- 3\nkeep_edge_types &lt;- c(\n  \"InterpolatesFrom\", \"InStyleOf\", \"LyricalReferenceTo\",\n  \"CoverOf\", \"DirectlySamples\",\n  \"ComposerOf\", \"PerformerOf\", \"MemberOf\", \"Released\"\n)\n\n# ─── 1. Load & index all nodes and edges ────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# ─── 2. Build an undirected igraph of the full graph (topology only) ────────\ng_all &lt;- graph_from_data_frame(\n  d        = edges_idx %&gt;% select(from, to),\n  directed = FALSE,\n  vertices = nodes_tbl %&gt;% transmute(name = as.character(idx))\n)\n\n# ─── 3. Find the chosen person’s idx (character) ────────────────────────────\ncenter_idx_char &lt;- nodes_tbl %&gt;%\n  filter(name == center_person, `Node Type` == \"Person\") %&gt;%\n  pull(idx) %&gt;%\n  as.character()\nif (length(center_idx_char) != 1) {\n  stop(\"Person '\", center_person, \"' not found or not unique.\")\n}\n\n# ─── 4. Compute the ego‐set of vertices within max_hops of the center ────────\nego_list   &lt;- ego(g_all, order = max_hops, nodes = center_idx_char, mode = \"all\")[[1]]\nego_indices &lt;- as.integer(V(g_all)$name[ego_list])  # numeric idx of all nodes in ego‐set\n\n# ─── 5. Filter edges so that both endpoints lie in that ego‐set AND edge‐type is in keep_edge_types ─\nego_edges &lt;- edges_idx %&gt;%\n  filter(\n    from %in% ego_indices,\n    to   %in% ego_indices,\n    `Edge Type` %in% keep_edge_types\n  )\n\nif (nrow(ego_edges) == 0) {\n  message(\"No edges remain when limiting to \", max_hops, \" hop(s) around \", center_person, \".\")\n} else {\n  # ─── 6. Build the list of involved nodes in this ego‐set ─────────────────────\n  ego_node_ids &lt;- unique(c(ego_edges$from, ego_edges$to))\n  ego_nodes    &lt;- nodes_tbl %&gt;% slice(ego_node_ids)\n  \n  # ─── 7. Construct an igraph for this ego network ───────────────────────────\n  vertices_df &lt;- ego_nodes %&gt;%\n    transmute(name = as.character(idx), label = name, type = `Node Type`)\n  edges_df &lt;- ego_edges %&gt;%\n    transmute(from = as.character(from), to = as.character(to), etype = `Edge Type`)\n  \n  g_ego &lt;- graph_from_data_frame(\n    d        = edges_df %&gt;% select(from, to),\n    directed = FALSE,\n    vertices = vertices_df\n  )\n  \n  # ─── 8. Compute betweenness centrality for every vertex ────────────────────\n  bc_vals &lt;- betweenness(g_ego, directed = FALSE, normalized = TRUE)\n  centrality_tbl &lt;- tibble(\n    idx         = as.integer(names(bc_vals)),\n    betweenness = unname(bc_vals)\n  ) %&gt;%\n    left_join(\n      ego_nodes %&gt;% select(idx, NodeName = name, NodeType = `Node Type`),\n      by = \"idx\"\n    ) %&gt;%\n    arrange(desc(betweenness))\n  \n  \n  # ─── 9. Bar‐chart of top 10 nodes by betweenness ──────────────────────────\n  centrality_tbl %&gt;%\n    slice_head(n = 10) %&gt;%\n    ggplot(aes(x = fct_reorder(NodeName, betweenness), y = betweenness, fill = NodeType)) +\n    geom_col(show.legend = TRUE) +\n    coord_flip() +\n    labs(\n      title = paste0(\"Top 10 Nodes by Betweenness (\", max_hops, \"-hop around \", center_person, \")\"),\n      x     = NULL,\n      y     = \"Betweenness (normalized)\"\n    ) +\n    theme_minimal(base_size = 9) +\n    theme(\n      plot.title    = element_text(size = 10, face = \"bold\"),\n      axis.title.y  = element_text(size = 5),\n      axis.title.x  = element_text(size = 10)\n    )\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeyla Graf-Gotthard\n\nPeople Influence EdgesBetweenness centrality in network\n\n\n\n\nCode\n# ─── 0. How many hops? ────────────────────────────────────────────────────────\nmax_hops &lt;- 2   # Change this number to 1, 2, 3… then re‐run the chunk\n\n# ─── 1. Load & index all nodes and edges ────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\n# Build numeric “from/to” index for every edge\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# ─── 2. Build an undirected igraph of the full graph ────────────────────────\ng_all &lt;- graph_from_data_frame(\n  d        = edges_idx %&gt;% select(from, to),\n  directed = FALSE,\n  vertices = nodes_tbl %&gt;% transmute(name = as.character(idx))\n)\n\n# ─── 3. Prepare list of all Person names for dropdown ───────────────────────\nall_persons &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  arrange(name) %&gt;%                # sort ascending by name\n  pull(name)\n\n# ─── 4. Create a named vector mapping Person ➔ idx (character) ─────────────\nperson_idx_map &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  transmute(Person = name, idx_char = as.character(idx)) %&gt;%\n  deframe()\n\n# ─── 5. Function to build and render a Leyla‐style ego network given a name ───\nrender_ego_network &lt;- function(center_name) {\n  center_idx &lt;- person_idx_map[[center_name]]\n  if (is.null(center_idx)) {\n    stop(\"Person '\", center_name, \"' not found.\")\n  }\n  # Compute ego‐set of all vertices within max_hops of chosen person\n  ego_list   &lt;- ego(g_all, order = max_hops, nodes = center_idx, mode = \"all\")[[1]]\n  ego_indices &lt;- as.integer(V(g_all)$name[ego_list])\n  # Filter edges so both endpoints are in that ego set\n  career_edges &lt;- edges_idx %&gt;%\n    filter(from %in% ego_indices, to %in% ego_indices)\n  if (nrow(career_edges) == 0) {\n    showNotification(paste0(\n      \"No edges remain when limiting to \", max_hops,\n      \" hops out from \", center_name, \".\"\n    ), type = \"warning\")\n    return(NULL)\n  }\n  # Build list of all involved nodes\n  career_node_ids &lt;- unique(c(career_edges$from, career_edges$to))\n  career_nodes    &lt;- nodes_tbl %&gt;% slice(career_node_ids) %&gt;%\n    mutate(\n      vis_id = row_number(),\n      label  = name,\n      group  = `Node Type`,\n      title  = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`,\n                      if_else(`Node Type` == \"Song\" & !is.na(release_date),\n                              paste0(\"&lt;br&gt;Released: \", release_date), \"\"))\n    )\n  # Remap edges to vis_ids\n  career_edges &lt;- career_edges %&gt;%\n    mutate(\n      from_vis = match(from, career_node_ids),\n      to_vis   = match(to,   career_node_ids)\n    )\n  # Construct visNetwork nodes & edges\n  vn_nodes &lt;- career_nodes %&gt;%\n    transmute(id = vis_id, label = label, group = group, title = title)\n  vn_edges &lt;- career_edges %&gt;%\n    transmute(from = from_vis, to = to_vis, label = `Edge Type`, title = `Edge Type`,\n              color = case_when(\n                label == \"InterpolatesFrom\"   ~ \"#1f78b4\",\n                label == \"DirectlySamples\"    ~ \"#33a02c\",\n                label == \"InStyleOf\"          ~ \"#e31a1c\",\n                label == \"LyricalReferenceTo\" ~ \"#6a3d9a\",\n                label == \"CoverOf\"            ~ \"#fb9a99\",\n                label == \"ComposerOf\"         ~ \"#33a02c\",\n                label == \"PerformerOf\"        ~ \"#1f78b4\",\n                label == \"RecordedBy\"         ~ \"#6a329f\",\n                label == \"ProducerOf\"         ~ \"#fce80a\",\n                label == \"LyricistOf\"         ~ \"#ff7f00\",\n                TRUE                          ~ \"#888888\"\n              ))\n  # Determine vis_id for all Person‐type nodes (to allow dropdown focus)\n  person_vis_ids &lt;- vn_nodes %&gt;%\n    filter(group == \"Person\") %&gt;%\n    arrange(label) %&gt;%  # ensure sorted ascending\n    pull(id)\n  # Render visNetwork\n  visNetwork(vn_nodes, vn_edges, height = \"600px\", width = \"100%\") %&gt;%\n    visNodes(shape = \"dot\", size = 14, font = list(color = \"black\", size = 10)) %&gt;%\n    visEdges(arrows = \"to\", labelHighlightBold = TRUE, font = list(color = \"blue\", size = 7)) %&gt;%\n    visOptions(\n      highlightNearest   = list(enabled = TRUE, degree = 1),\n      nodesIdSelection   = list(\n        enabled   = TRUE,\n        useLabels = TRUE,\n        values    = person_vis_ids\n      )\n    ) %&gt;%\n    visLegend(useGroups = TRUE, width = 0.1, position = \"right\") %&gt;%\n    visIgraphLayout(layout = \"layout_with_fr\", randomSeed = 1234) %&gt;%\n    visPhysics(enabled = FALSE)\n}\n\n# ─── 6. Initial rendering for “Kimberly Snyder” ─────────────────────────────\nrender_ego_network(\"Leyla Graf-Gotthard\")\n\n\n\n\n\n\n\n\n\nSimilarly, Leyla had more song influences in her network.\n\n\n\nCode\n# ─── PARAMETERS ───────────────────────────────────────────────────────────────\ncenter_person &lt;- \"Leyla Graf-Gotthard\"\nmax_hops      &lt;- 3\nkeep_edge_types &lt;- c(\n  \"InterpolatesFrom\", \"InStyleOf\", \"LyricalReferenceTo\",\n  \"CoverOf\", \"DirectlySamples\",\n  \"ComposerOf\", \"PerformerOf\", \"MemberOf\", \"Released\"\n)\n\n# ─── 1. Load & index all nodes and edges ────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# ─── 2. Build an undirected igraph of the full graph (topology only) ────────\ng_all &lt;- graph_from_data_frame(\n  d        = edges_idx %&gt;% select(from, to),\n  directed = FALSE,\n  vertices = nodes_tbl %&gt;% transmute(name = as.character(idx))\n)\n\n# ─── 3. Find the chosen person’s idx (character) ────────────────────────────\ncenter_idx_char &lt;- nodes_tbl %&gt;%\n  filter(name == center_person, `Node Type` == \"Person\") %&gt;%\n  pull(idx) %&gt;%\n  as.character()\nif (length(center_idx_char) != 1) {\n  stop(\"Person '\", center_person, \"' not found or not unique.\")\n}\n\n# ─── 4. Compute the ego‐set of vertices within max_hops of the center ────────\nego_list   &lt;- ego(g_all, order = max_hops, nodes = center_idx_char, mode = \"all\")[[1]]\nego_indices &lt;- as.integer(V(g_all)$name[ego_list])  # numeric idx of all nodes in ego‐set\n\n# ─── 5. Filter edges so that both endpoints lie in that ego‐set AND edge‐type is in keep_edge_types ─\nego_edges &lt;- edges_idx %&gt;%\n  filter(\n    from %in% ego_indices,\n    to   %in% ego_indices,\n    `Edge Type` %in% keep_edge_types\n  )\n\nif (nrow(ego_edges) == 0) {\n  message(\"No edges remain when limiting to \", max_hops, \" hop(s) around \", center_person, \".\")\n} else {\n  # ─── 6. Build the list of involved nodes in this ego‐set ─────────────────────\n  ego_node_ids &lt;- unique(c(ego_edges$from, ego_edges$to))\n  ego_nodes    &lt;- nodes_tbl %&gt;% slice(ego_node_ids)\n  \n  # ─── 7. Construct an igraph for this ego network ───────────────────────────\n  vertices_df &lt;- ego_nodes %&gt;%\n    transmute(name = as.character(idx), label = name, type = `Node Type`)\n  edges_df &lt;- ego_edges %&gt;%\n    transmute(from = as.character(from), to = as.character(to), etype = `Edge Type`)\n  \n  g_ego &lt;- graph_from_data_frame(\n    d        = edges_df %&gt;% select(from, to),\n    directed = FALSE,\n    vertices = vertices_df\n  )\n  \n  # ─── 8. Compute betweenness centrality for every vertex ────────────────────\n  bc_vals &lt;- betweenness(g_ego, directed = FALSE, normalized = TRUE)\n  centrality_tbl &lt;- tibble(\n    idx         = as.integer(names(bc_vals)),\n    betweenness = unname(bc_vals)\n  ) %&gt;%\n    left_join(\n      ego_nodes %&gt;% select(idx, NodeName = name, NodeType = `Node Type`),\n      by = \"idx\"\n    ) %&gt;%\n    arrange(desc(betweenness))\n  \n  # ─── 9. Bar‐chart of top 10 nodes by betweenness ──────────────────────────\n  centrality_tbl %&gt;%\n    slice_head(n = 10) %&gt;%\n    ggplot(aes(x = fct_reorder(NodeName, betweenness), y = betweenness, fill = NodeType)) +\n    geom_col(show.legend = TRUE) +\n    coord_flip() +\n    labs(\n      title = paste0(\"Top 10 Nodes by Betweenness (\", max_hops, \"-hop around \", center_person, \")\"),\n      x     = NULL,\n      y     = \"Betweenness (normalized)\"\n    ) +\n        theme_minimal(base_size = 9) +\n    theme(\n      plot.title    = element_text(size = 10, face = \"bold\"),\n      axis.title.y  = element_text(size = 5),\n      axis.title.x  = element_text(size = 10)\n    )\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSzymon Pyć\n\nPeople Influence EdgesBetweenness centrality in network\n\n\n\n\nCode\n# ─── 0. How many hops? ────────────────────────────────────────────────────────\nmax_hops &lt;- 2   # Change this number to 1, 2, 3… then re‐run the chunk\n\n# ─── 1. Load & index all nodes and edges ────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\n# Build numeric “from/to” index for every edge\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# ─── 2. Build an undirected igraph of the full graph ────────────────────────\ng_all &lt;- graph_from_data_frame(\n  d        = edges_idx %&gt;% select(from, to),\n  directed = FALSE,\n  vertices = nodes_tbl %&gt;% transmute(name = as.character(idx))\n)\n\n# ─── 3. Prepare list of all Person names for dropdown ───────────────────────\nall_persons &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  arrange(name) %&gt;%                # sort ascending by name\n  pull(name)\n\n# ─── 4. Create a named vector mapping Person ➔ idx (character) ─────────────\nperson_idx_map &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  transmute(Person = name, idx_char = as.character(idx)) %&gt;%\n  deframe()\n\n# ─── 5. Function to build and render a Leyla‐style ego network given a name ───\nrender_ego_network &lt;- function(center_name) {\n  center_idx &lt;- person_idx_map[[center_name]]\n  if (is.null(center_idx)) {\n    stop(\"Person '\", center_name, \"' not found.\")\n  }\n  # Compute ego‐set of all vertices within max_hops of chosen person\n  ego_list   &lt;- ego(g_all, order = max_hops, nodes = center_idx, mode = \"all\")[[1]]\n  ego_indices &lt;- as.integer(V(g_all)$name[ego_list])\n  # Filter edges so both endpoints are in that ego set\n  career_edges &lt;- edges_idx %&gt;%\n    filter(from %in% ego_indices, to %in% ego_indices)\n  if (nrow(career_edges) == 0) {\n    showNotification(paste0(\n      \"No edges remain when limiting to \", max_hops,\n      \" hops out from \", center_name, \".\"\n    ), type = \"warning\")\n    return(NULL)\n  }\n  # Build list of all involved nodes\n  career_node_ids &lt;- unique(c(career_edges$from, career_edges$to))\n  career_nodes    &lt;- nodes_tbl %&gt;% slice(career_node_ids) %&gt;%\n    mutate(\n      vis_id = row_number(),\n      label  = name,\n      group  = `Node Type`,\n      title  = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`,\n                      if_else(`Node Type` == \"Song\" & !is.na(release_date),\n                              paste0(\"&lt;br&gt;Released: \", release_date), \"\"))\n    )\n  # Remap edges to vis_ids\n  career_edges &lt;- career_edges %&gt;%\n    mutate(\n      from_vis = match(from, career_node_ids),\n      to_vis   = match(to,   career_node_ids)\n    )\n  # Construct visNetwork nodes & edges\n  vn_nodes &lt;- career_nodes %&gt;%\n    transmute(id = vis_id, label = label, group = group, title = title)\n  vn_edges &lt;- career_edges %&gt;%\n    transmute(from = from_vis, to = to_vis, label = `Edge Type`, title = `Edge Type`,\n              color = case_when(\n                label == \"InterpolatesFrom\"   ~ \"#1f78b4\",\n                label == \"DirectlySamples\"    ~ \"#33a02c\",\n                label == \"InStyleOf\"          ~ \"#e31a1c\",\n                label == \"LyricalReferenceTo\" ~ \"#6a3d9a\",\n                label == \"CoverOf\"            ~ \"#fb9a99\",\n                label == \"ComposerOf\"         ~ \"#33a02c\",\n                label == \"PerformerOf\"        ~ \"#1f78b4\",\n                label == \"RecordedBy\"         ~ \"#6a329f\",\n                label == \"ProducerOf\"         ~ \"#fce80a\",\n                label == \"LyricistOf\"         ~ \"#ff7f00\",\n                TRUE                          ~ \"#888888\"\n              ))\n  # Determine vis_id for all Person‐type nodes (to allow dropdown focus)\n  person_vis_ids &lt;- vn_nodes %&gt;%\n    filter(group == \"Person\") %&gt;%\n    arrange(label) %&gt;%  # ensure sorted ascending\n    pull(id)\n  # Render visNetwork\n  visNetwork(vn_nodes, vn_edges, height = \"600px\", width = \"100%\") %&gt;%\n    visNodes(shape = \"dot\", size = 14, font = list(color = \"black\", size = 10)) %&gt;%\n    visEdges(arrows = \"to\", labelHighlightBold = TRUE, font = list(color = \"blue\", size = 7)) %&gt;%\n    visOptions(\n      highlightNearest   = list(enabled = TRUE, degree = 1),\n      nodesIdSelection   = list(\n        enabled   = TRUE,\n        useLabels = TRUE,\n        values    = person_vis_ids\n      )\n    ) %&gt;%\n    visLegend(useGroups = TRUE, width = 0.1, position = \"right\") %&gt;%\n    visIgraphLayout(layout = \"layout_with_fr\", randomSeed = 1234) %&gt;%\n    visPhysics(enabled = FALSE)\n}\n\n# ─── 6. Initial rendering for “Kimberly Snyder” ─────────────────────────────\nrender_ego_network(\"Szymon Pyć\")\n\n\n\n\n\n\n\n\n\nInterestingly, there were more albums and people influence in Szymon’s network.\n\n\n\nCode\n# ─── PARAMETERS ───────────────────────────────────────────────────────────────\ncenter_person &lt;- \"Szymon Pyć\"\nmax_hops      &lt;- 3\nkeep_edge_types &lt;- c(\n  \"InterpolatesFrom\", \"InStyleOf\", \"LyricalReferenceTo\",\n  \"CoverOf\", \"DirectlySamples\",\n  \"ComposerOf\", \"PerformerOf\", \"MemberOf\", \"Released\"\n)\n\n# ─── 1. Load & index all nodes and edges ────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# ─── 2. Build an undirected igraph of the full graph (topology only) ────────\ng_all &lt;- graph_from_data_frame(\n  d        = edges_idx %&gt;% select(from, to),\n  directed = FALSE,\n  vertices = nodes_tbl %&gt;% transmute(name = as.character(idx))\n)\n\n# ─── 3. Find the chosen person’s idx (character) ────────────────────────────\ncenter_idx_char &lt;- nodes_tbl %&gt;%\n  filter(name == center_person, `Node Type` == \"Person\") %&gt;%\n  pull(idx) %&gt;%\n  as.character()\nif (length(center_idx_char) != 1) {\n  stop(\"Person '\", center_person, \"' not found or not unique.\")\n}\n\n# ─── 4. Compute the ego‐set of vertices within max_hops of the center ────────\nego_list   &lt;- ego(g_all, order = max_hops, nodes = center_idx_char, mode = \"all\")[[1]]\nego_indices &lt;- as.integer(V(g_all)$name[ego_list])  # numeric idx of all nodes in ego‐set\n\n# ─── 5. Filter edges so that both endpoints lie in that ego‐set AND edge‐type is in keep_edge_types ─\nego_edges &lt;- edges_idx %&gt;%\n  filter(\n    from %in% ego_indices,\n    to   %in% ego_indices,\n    `Edge Type` %in% keep_edge_types\n  )\n\nif (nrow(ego_edges) == 0) {\n  message(\"No edges remain when limiting to \", max_hops, \" hop(s) around \", center_person, \".\")\n} else {\n  # ─── 6. Build the list of involved nodes in this ego‐set ─────────────────────\n  ego_node_ids &lt;- unique(c(ego_edges$from, ego_edges$to))\n  ego_nodes    &lt;- nodes_tbl %&gt;% slice(ego_node_ids)\n  \n  # ─── 7. Construct an igraph for this ego network ───────────────────────────\n  vertices_df &lt;- ego_nodes %&gt;%\n    transmute(name = as.character(idx), label = name, type = `Node Type`)\n  edges_df &lt;- ego_edges %&gt;%\n    transmute(from = as.character(from), to = as.character(to), etype = `Edge Type`)\n  \n  g_ego &lt;- graph_from_data_frame(\n    d        = edges_df %&gt;% select(from, to),\n    directed = FALSE,\n    vertices = vertices_df\n  )\n  \n  # ─── 8. Compute betweenness centrality for every vertex ────────────────────\n  bc_vals &lt;- betweenness(g_ego, directed = FALSE, normalized = TRUE)\n  centrality_tbl &lt;- tibble(\n    idx         = as.integer(names(bc_vals)),\n    betweenness = unname(bc_vals)\n  ) %&gt;%\n    left_join(\n      ego_nodes %&gt;% select(idx, NodeName = name, NodeType = `Node Type`),\n      by = \"idx\"\n    ) %&gt;%\n    arrange(desc(betweenness))\n  \n  # ─── 9. Bar‐chart of top 10 nodes by betweenness ──────────────────────────\n  centrality_tbl %&gt;%\n    slice_head(n = 10) %&gt;%\n    ggplot(aes(x = fct_reorder(NodeName, betweenness), y = betweenness, fill = NodeType)) +\n    geom_col(show.legend = TRUE) +\n    coord_flip() +\n    labs(\n      title = paste0(\"Top 10 Nodes by Betweenness (\", max_hops, \"-hop around \", center_person, \")\"),\n      x     = NULL,\n      y     = \"Betweenness (normalized)\"\n    ) +\n        theme_minimal(base_size = 9) +\n    theme(\n      plot.title    = element_text(size = 10, face = \"bold\"),\n      axis.title.y  = element_text(size = 5),\n      axis.title.x  = element_text(size = 10)\n    )\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPeople Influence\n\n\n\nThese plots depict that each artist has a difference in which external node (song/album/person) had the most influence and control."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#additional-affliation-works-with-musical-groups",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#additional-affliation-works-with-musical-groups",
    "title": "Take-Home_Ex02",
    "section": "Additional: Affliation works with Musical Groups",
    "text": "Additional: Affliation works with Musical Groups\n\nI want to visualise the categories for Kimberly Snyder’s Sonic Renegades and their members.\nOnly Kimberly Snyder has an affliated musicalgroup as Leyla Graf-Gotthard and Szymon Pyć are supposedly solo artists as there isnt any nodes linking them to a group.\n\n\nKimberly Snyder and Sonic Renegade members\nFollowing factors are used to visualize Kimberly and her members.\n\n“MemberOf”, “ComposerOf”, “PerformerOf”,“LyricistOf”, “RecordedBy”,“ProducerOf”,“DistributedBy”\n\n\nMusicalGroup Linkages\n\n\nCode\n#── Ingest your graph data ────────────────────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes)\nedges_tbl &lt;- as_tibble(kg_raw$links)\n\n#── Map source/target to row indices ──────────────────────────────────────────\nid_map &lt;- nodes_tbl %&gt;% \n  mutate(index = row_number()) %&gt;% \n  select(id, index)\n\nedges_idx &lt;- edges_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = index) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = index) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n#── Define your five Sonic Renegade members ────────────────────────────────────────\nartists &lt;- c(\n  \"Kimberly Snyder\",\n  \"Gerald Mullins\",\n  \"Kelly Stewart\",\n  \"Joshua Herring\"\n)\n\n#── Pull only the relevant edges for those artists ────────────────────────────\ncareer_edges &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"MemberOf\", \"ComposerOf\", \"PerformerOf\",\"LyricistOf\", \"RecordedBy\",\"ProducerOf\",\"DistributedBy\")) %&gt;%\n  filter(\n    from %in% which(nodes_tbl$name %in% artists) |\n    to   %in% which(nodes_tbl$name %in% artists)\n  )\n\n#── Slice out all involved nodes ──────────────────────────────────────────────\ncareer_node_ids &lt;- unique(c(career_edges$from, career_edges$to))\ncareer_nodes    &lt;- nodes_tbl %&gt;% slice(career_node_ids)\n\n#── Build visNetwork nodes df (uniform sizing) ───────────────────────────────\nvn_nodes &lt;- career_nodes %&gt;%\n  mutate(\n    id    = row_number(),\n    label = name,\n    group = `Node Type`,\n    value = 1\n  )\n\n#── Remap edges to the new vn_node ids ────────────────────────────────────────\nid_lookup &lt;- tibble(old = career_node_ids, new = vn_nodes$id)\n\nvn_edges &lt;- career_edges %&gt;%\n  inner_join(id_lookup, by = c(\"from\" = \"old\")) %&gt;%\n    select(-from) %&gt;% rename(from = new) %&gt;%\n  inner_join(id_lookup, by = c(\"to\" = \"old\")) %&gt;%\n    select(-to)   %&gt;% rename(to   = new) %&gt;%\n  select(from, to, title = `Edge Type`)\n\n#── Plot ─────────────────────────────────────────────────────────────────────\nvisNetwork(vn_nodes, vn_edges, height = \"600px\", width = \"100%\") %&gt;%\n  visNodes(shape = \"dot\", scaling = list(min = 5, max = 30)) %&gt;%\n  visEdges(arrows = \"to\") %&gt;%\n  visLegend(width = 0.1, position = \"right\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\", randomSeed = 1234) %&gt;%\n  visPhysics(enabled = FALSE)\n\n\n\n\n\n\n\n\nTimeline of Sonic Renegade’ members works\n\nI would like to view the timeline of the works by each of the members to see who has been having consistent work throughout the years.\n\n\n\nCode\nlibrary(lubridate)\nlibrary(tidyr)       # for unnest_wider()\n\n# 1. Load & index graph (as before) -----------------------------\nkg_raw      &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl   &lt;- as_tibble(kg_raw$nodes)\nlinks_tbl   &lt;- as_tibble(kg_raw$links)\n\nivy_id_map  &lt;- nodes_tbl %&gt;% \n  mutate(ivy_row = row_number()) %&gt;% \n  select(id, ivy_row)\n\nivy_edges   &lt;- links_tbl %&gt;%\n  left_join(ivy_id_map, by = c(\"source\" = \"id\")) %&gt;% rename(from = ivy_row) %&gt;%\n  left_join(ivy_id_map, by = c(\"target\" = \"id\")) %&gt;% rename(to   = ivy_row) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# 2. Get Ivy Echos members ---------------------------------------\nband_idx     &lt;- which(nodes_tbl$name == \"Sonic Renegade\")\nmember_idxs  &lt;- ivy_edges %&gt;%\n  filter(`Edge Type` == \"MemberOf\", to == band_idx) %&gt;%\n  pull(from)\nmember_names &lt;- nodes_tbl$name[member_idxs]\n\n# 3. Filter to their ComposerOf/PerformerOf and extract years ----\nrelease_edges &lt;- ivy_edges %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\",\"PerformerOf\",\"LyricistOf\", \"RecordedBy\",\"ProducerOf\",\"DistributedBy\"),\n         from %in% member_idxs)\n\nrelease_data  &lt;- release_edges %&gt;%\n  mutate(\n    Artist = nodes_tbl$name[from],\n    Year   = as.integer(nodes_tbl$release_date[to])\n  ) %&gt;%\n  filter(!is.na(Year))\n\n# 4. Summarize & “complete” zero years ---------------------------\nraw_counts &lt;- release_data %&gt;%\n  count(Artist, Year)\n\n# determine full span of years in your dataset\nyear_span &lt;- seq(min(raw_counts$Year), max(raw_counts$Year))\n\ntimeline_tbl &lt;- raw_counts %&gt;%\n  complete(\n    Artist = member_names,\n    Year   = year_span,\n    fill   = list(n = 0)\n  )\n\n# 5. Plot with zeros shown ----------------------------------------\nggplot(timeline_tbl %&gt;% mutate(Year_f = factor(Year)), \n       aes(x = Year_f, y = n, color = Artist, group = Artist)) +\n  geom_line(position = position_dodge(width = 0.5), size = 1) +\n  geom_point(position = position_dodge(width = 0.5), size = 3) +\n  scale_x_discrete(drop = FALSE) +\n  labs(\n    title = \"Annual Output by Sonic Renegade Members (Dodged)\",\n    x     = \"Year\",\n    y     = \"Number of Works\",\n    color = \"Artist\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdditional\n\n\n\nBased on the above plot, the trend of how many songs released by each member is similar. However, Kimberly Snyder has more songs each year as compared to the other group members.\nThis could also show how Kimberly had more notable songs due to more effort in producing songs each year which lead to her immense popularity and influence."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#summary-of-part-a",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#summary-of-part-a",
    "title": "Take-Home_Ex02",
    "section": "Summary of part (a)",
    "text": "Summary of part (a)\n\nNotable songs and release across the years are important factors for artist’s popularity.\nExternal factors such as influences factors show how much control and spread of the artist’s information is spread across to people."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#popularity",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#popularity",
    "title": "Take-Home_Ex02",
    "section": "Popularity",
    "text": "Popularity\n\nNumber of Notable songs of Oceanus Folk\n\nLet’s take a look at all the songs + notable songs released by Oceanus Folk throughout their careers.\nI will do a global count of every Oceanus Folk song marked “notable == True” to have an overview without any restrictions.\nI will plot the total songs released beside the notable songs barchart as comparison.\n\n\n\nCode\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% \n  mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\n\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# 2. Identify all Person nodes\nperson_idxs &lt;- which(nodes_tbl$`Node Type` == \"Person\")\n\n# 3a. Count all Oceanus Folk songs per Person\ntotal_oceanus_tbl &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% select(idx, genre, `Node Type`),\n    by = c(\"to\" = \"idx\")\n  ) %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Oceanus Folk\") %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"TotalOceanusSongs\")\n\n# 3b. Count only notable Oceanus Folk songs per Person\nnotable_oceanus_tbl &lt;- edges_idx %&gt;%\n  filter(`Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n         from %in% person_idxs) %&gt;%\n  left_join(\n    nodes_tbl %&gt;% select(idx, notable, genre, `Node Type`),\n    by = c(\"to\" = \"idx\")\n  ) %&gt;%\n  filter(`Node Type` == \"Song\",\n         genre == \"Oceanus Folk\",\n         notable == TRUE) %&gt;%\n  mutate(Person = nodes_tbl$name[from]) %&gt;%\n  count(Person, name = \"NotableOceanusSongs\")\n\n# 4. Join total & notable counts, replace missing with 0\ncombined_tbl &lt;- full_join(total_oceanus_tbl, notable_oceanus_tbl, by = \"Person\") %&gt;%\n  replace_na(list(TotalOceanusSongs = 0, NotableOceanusSongs = 0)) %&gt;%\n  arrange(desc(NotableOceanusSongs))\n\n# 5. Take top 15 by Notable count, then reorder factor by Notable\ntop_n &lt;- 15\nplot_tbl &lt;- combined_tbl %&gt;%\n  slice_head(n = top_n) %&gt;%\n  mutate(Person = fct_reorder(Person, NotableOceanusSongs))\n\n# 6. Pivot to long form for grouped/stacked bar plotting\nplot_long &lt;- plot_tbl %&gt;%\n  pivot_longer(cols = c(TotalOceanusSongs, NotableOceanusSongs),\n               names_to = \"Metric\", values_to = \"Count\")\n\n# 7. Plot side-by-side columns: Total vs Notable\nggplot(plot_long, aes(x = Person, y = Count, fill = Metric)) +\n  geom_col(position = position_dodge(width = 0.7), width = 0.6) +\n  coord_flip() +\n  scale_fill_manual(\n    values = c(\n      TotalOceanusSongs   = \"#a6cee3\",\n      NotableOceanusSongs = \"#1f78b4\"\n    ),\n    labels = c(\"Total Songs\", \"Notable Songs\")\n  ) +\n  labs(\n    title = \"Top Persons by Oceanus Folk Output (Total vs. Notable)\",\n    x     = NULL,\n    y     = \"Number of Songs\",\n    fill  = \"Metric\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = \"top\",\n    axis.text.y     = element_text(size = 10),\n    plot.title      = element_text(size = 14, face = \"bold\")\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverall Artists in Oceanus Folk\n\n\n\nYou can see the spread of artists with notable songs but we have yet to limit the years as we are not interested in long-careered artists but rising artists.\n\n\n\n\nSongs timeline\nI will plot these songs across the years to visualize which years we should set as our limit.\n\n\nCode\nlibrary(lubridate)\n\n# 1. Load & index the graph\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;%\n  mutate(idx = row_number())\n\n# 2. Filter to Oceanus Folk Song nodes and extract their year + notable flag\noceanus_songs &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Oceanus Folk\") %&gt;%\n  mutate(\n    # Parse release_date and written_date to integers (YYYY)\n    release_year = suppressWarnings(as.integer(str_extract(release_date, \"\\\\d{4}\"))),\n    written_year = suppressWarnings(as.integer(str_extract(written_date, \"\\\\d{4}\"))),\n    # Choose the earliest non-NA year as the official song_year\n    song_year    = pmin(release_year, written_year, na.rm = TRUE),\n    # Flag whether this song is “notable” (has a notoriety_date)\n    is_notable   = !is.na(notoriety_date)\n  ) %&gt;%\n  # Only keep those with a valid song_year ≤ 2040\n  filter(!is.na(song_year), song_year &lt;= 2040) %&gt;%\n  select(idx, song_year, is_notable)\n\n# 3. Determine the earliest Oceanus Folk “debut” year\ndebut_year &lt;- min(oceanus_songs$song_year, na.rm = TRUE)\n\n# 4. Build a data frame of year-by-year counts from debut_year through 2040\nyear_seq &lt;- tibble(year = seq(debut_year, 2040))\n\nyearly_counts &lt;- oceanus_songs %&gt;%\n  group_by(song_year) %&gt;%\n  summarize(\n    total_releases   = n(),\n    total_notable    = sum(is_notable),\n    .groups = \"drop\"\n  ) %&gt;%\n  rename(year = song_year)\n\n# 5. Left-join to ensure we include years with zero releases/notable\nyearly_trends &lt;- year_seq %&gt;%\n  left_join(yearly_counts, by = \"year\") %&gt;%\n  replace_na(list(total_releases = 0, total_notable = 0))\n\n# 6. Plot both series on the same plot\nggplot(yearly_trends, aes(x = year)) +\n  geom_col(aes(y = total_releases), fill = \"steelblue\", alpha = 0.6) +\n  geom_line(aes(y = total_notable), color = \"darkred\", size = 1) +\n  geom_point(aes(y = total_notable), color = \"darkred\", size = 2) +\n  scale_x_continuous(breaks = seq(debut_year, 2040, by = 2)) +\n  labs(\n    title = \"Oceanus Folk: Annual Song Releases and Notable Songs (to 2040)\",\n    subtitle = paste0(\"Data from first Oceanus Folk release (\", debut_year, \") through 2040\"),\n    x = \"Year\",\n    y = \"Count\",\n    caption = \"Blue bars = total Oceanus Folk songs released; Red line = notable songs\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title    = element_text(size = 8, face = \"bold\"),\n    plot.subtitle = element_text(size = 10),\n    axis.text.x   = element_text(angle = 45, hjust = 1)\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTimeline Note\n\n\n\n\nThere weren’t any notable songs released by the Oceanus Folk artists from 2036 to 2040.\nBased on this, I will want to limit the spread to around 10 years since the last notable song in 2035.\nThe range I will select to determine my 3 rising stars will be from 2025 to 2035."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#direct-prediction-based-on-notable-songs",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#direct-prediction-based-on-notable-songs",
    "title": "Take-Home_Ex02",
    "section": "Direct Prediction based on notable songs",
    "text": "Direct Prediction based on notable songs\n\nBelow is a direct prediction on the top 3 “next Oceanus Folk stars” based on limiting the notable songs and release years from 2025 to 2035.\n\n\n\nCode\nlibrary(DT)\nlibrary(lubridate)\n\n# ─── 0. PARAMETERS ─────────────────────────────────────────────────────────────\nwindow_start       &lt;- 2025\nwindow_end         &lt;- 2035\nearly_window_years &lt;- 5\ninfluence_edge_types &lt;- c(\n  \"InterpolatesFrom\",\n  \"CoverOf\",\n  \"LyricalReferenceTo\",\n  \"DirectlySamples\",\n  \"InStyleOf\"\n)\n\n# ─── 1. LOAD & PREPARE NODES + EDGES ───────────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;%\n  mutate(idx = row_number())  # numeric index for joining\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# ─── 2. EXTRACT “OCEANUS FOLK” SONGS & THEIR FIRST‐RELEASE YEARS ─────────────\nsongs_oceanus &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Oceanus Folk\") %&gt;%\n  mutate(\n    release_year = suppressWarnings(as.integer(str_extract(release_date, \"\\\\d{4}\"))),\n    written_year = suppressWarnings(as.integer(str_extract(written_date, \"\\\\d{4}\"))),\n    first_year   = pmin(release_year, written_year, na.rm = TRUE)\n  ) %&gt;%\n  filter(!is.na(first_year)) %&gt;%\n  filter(first_year &gt;= window_start, first_year &lt;= window_end) %&gt;%\n  select(song_idx = idx, first_year)\n\nperson_idxs &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  pull(idx)\n\nperson_song_edges &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n    from %in% person_idxs,\n    to   %in% songs_oceanus$song_idx\n  ) %&gt;%\n  select(person_idx = from, song_idx = to)\n\nperson_first_oceanus &lt;- person_song_edges %&gt;%\n  left_join(songs_oceanus, by = \"song_idx\") %&gt;%\n  group_by(person_idx) %&gt;%\n  summarise(first_oceanus_year = min(first_year, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  filter(first_oceanus_year &gt;= window_start, first_oceanus_year &lt;= window_end)\n\nif (nrow(person_first_oceanus) == 0) {\n  stop(\"No emerging Oceanus Folk artists found between \", window_start, \" and \", window_end, \".\")\n}\n\n# ─── 3. COMPUTE EARLY‐CAREER “POPULARITY” ─────────────────────────────────────\nsongs_oceanus_full &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Oceanus Folk\") %&gt;%\n  mutate(\n    release_year     = suppressWarnings(as.integer(str_extract(release_date, \"\\\\d{4}\"))),\n    written_year     = suppressWarnings(as.integer(str_extract(written_date, \"\\\\d{4}\"))),\n    first_year_song  = pmin(release_year, written_year, na.rm = TRUE),\n    is_notable       = !is.na(notoriety_date)\n  ) %&gt;%\n  select(song_idx = idx, first_year_song, is_notable)\n\nartist_songs &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n    from %in% person_first_oceanus$person_idx,\n    to   %in% songs_oceanus_full$song_idx\n  ) %&gt;%\n  select(person_idx = from, song_idx = to) %&gt;%\n  left_join(songs_oceanus_full, by = \"song_idx\") %&gt;%\n  left_join(person_first_oceanus, by = \"person_idx\")\n\nartist_songs_early &lt;- artist_songs %&gt;%\n  filter(\n    first_year_song &gt;= first_oceanus_year,\n    first_year_song &lt;= first_oceanus_year + early_window_years\n  )\n\npopularity_tbl &lt;- artist_songs_early %&gt;%\n  filter(is_notable) %&gt;%\n  count(person_idx, name = \"early_notable_songs\")\n\npopularity_tbl &lt;- person_first_oceanus %&gt;%\n  select(person_idx) %&gt;%\n  left_join(popularity_tbl, by = \"person_idx\") %&gt;%\n  mutate(early_notable_songs = replace_na(early_notable_songs, 0))\n\n# ─── 4. COMPUTE EARLY‐CAREER “INFLUENCE” ─────────────────────────────────────\nnodes_years &lt;- nodes_tbl %&gt;%\n  mutate(\n    release_year   = suppressWarnings(as.integer(str_extract(release_date, \"\\\\d{4}\"))),\n    written_year   = suppressWarnings(as.integer(str_extract(written_date, \"\\\\d{4}\"))),\n    notoriety_year = suppressWarnings(as.integer(str_extract(notoriety_date, \"\\\\d{4}\"))),\n    node_year      = pmin(release_year, written_year, notoriety_year, na.rm = TRUE)\n  ) %&gt;%\n  select(idx, node_year)\n\nartist_infl_edges &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% influence_edge_types,\n    (from %in% person_first_oceanus$person_idx) |\n    (to   %in% person_first_oceanus$person_idx)\n  ) %&gt;%\n  left_join(nodes_years, by = c(\"from\" = \"idx\")) %&gt;% rename(year_from = node_year) %&gt;%\n  left_join(nodes_years, by = c(\"to\"   = \"idx\")) %&gt;% rename(year_to   = node_year) %&gt;%\n  mutate(edge_year = pmax(year_from, year_to, na.rm = TRUE))\n\nartist_infl_early &lt;- artist_infl_edges %&gt;%\n  mutate(person_idx = if_else(from %in% person_first_oceanus$person_idx, from, to)) %&gt;%\n  left_join(person_first_oceanus, by = \"person_idx\") %&gt;%\n  filter(\n    edge_year &gt;= first_oceanus_year,\n    edge_year &lt;= first_oceanus_year + early_window_years\n  ) %&gt;%\n  count(person_idx, name = \"early_influence_edges\")\n\ninfluence_tbl &lt;- person_first_oceanus %&gt;%\n  select(person_idx) %&gt;%\n  left_join(artist_infl_early, by = \"person_idx\") %&gt;%\n  mutate(early_influence_edges = replace_na(early_influence_edges, 0))\n\n# ─── 5. COMBINE & RANK EMERGING ARTISTS ───────────────────────────────────────\nemerging_metrics &lt;- person_first_oceanus %&gt;%\n  left_join(popularity_tbl, by = \"person_idx\") %&gt;%\n  left_join(influence_tbl,  by = \"person_idx\") %&gt;%\n  left_join(nodes_tbl %&gt;% select(person_idx = idx, name), by = \"person_idx\") %&gt;%\n  mutate(total_score = early_notable_songs + early_influence_edges) %&gt;%\n  select(person_idx, name, first_oceanus_year,\n         early_notable_songs, early_influence_edges, total_score) %&gt;%\n  arrange(desc(total_score), desc(early_notable_songs))\n\ntop3_emerging &lt;- emerging_metrics %&gt;% slice_head(n = 3)\n\n# ─── 6. RENDER AS DATA TABLE WITH SCROLLING ──────────────────────────────────\nDT::datatable(\n  top3_emerging,\n  extensions = \"Buttons\",\n  options = list(\n    scrollX    = TRUE,\n    pageLength = 5\n  )\n)\n\n\n\n\n\n\n\n\n\n\n\n\nMost notable songs from emerging artists in Oceanus Folk genre\n\n\n\n\nOrla Seabloom, Beatrice Albright & Daniel O’Connell have the most notable songs (4&lt;=) and their debut was between 2025 to 2035.\nLet’s visualise them against the rest of the artist to have a clearer view on this take."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-notable-oceanus-folk-songs-based-on-debut-of-artist-from-2025-to-2035",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#visualising-notable-oceanus-folk-songs-based-on-debut-of-artist-from-2025-to-2035",
    "title": "Take-Home_Ex02",
    "section": "Visualising Notable Oceanus Folk songs based on debut of Artist from 2025 to 2035",
    "text": "Visualising Notable Oceanus Folk songs based on debut of Artist from 2025 to 2035\n\nI will be restricting the artists whose first Oceanus Folk release fell in 2025–2035 and count that as notable songs for more relevance for recent years.\n\n\n\nCode\nlibrary(lubridate)\nlibrary(plotly)\n\n# 1. Load & index nodes and edges\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% \n  mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\n# Build numeric from/to indices for each edge\nid_map    &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from), !is.na(to))\n\n# 2. Extract Oceanus Folk songs and compute 'song_year' + notable flag\noceanus_songs_full &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Oceanus Folk\") %&gt;%\n  mutate(\n    release_year   = suppressWarnings(as.integer(str_extract(release_date, \"\\\\d{4}\"))),\n    written_year   = suppressWarnings(as.integer(str_extract(written_date, \"\\\\d{4}\"))),\n    song_year      = pmin(release_year, written_year, na.rm = TRUE),\n    is_notable     = !is.na(notoriety_date)\n  ) %&gt;%\n  filter(!is.na(song_year)) %&gt;%\n  select(song_idx = idx, song_year, is_notable)\n\n# 3. Identify all Person indices\nperson_idxs &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  pull(idx)\n\n# 4. Find ComposerOf / PerformerOf edges linking persons → Oceanus Folk songs\nperson_song_edges &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n    from %in% person_idxs,\n    to   %in% oceanus_songs_full$song_idx\n  ) %&gt;%\n  select(person_idx = from, song_idx = to)\n\n# 5. Compute each person’s first Oceanus Folk year, then filter to 2028–2040\nperson_first_oceanus &lt;- person_song_edges %&gt;%\n  left_join(oceanus_songs_full, by = \"song_idx\") %&gt;%\n  group_by(person_idx) %&gt;%\n  summarize(\n    first_oceanus_year = min(song_year, na.rm = TRUE),\n    .groups = \"drop\"\n  ) %&gt;%\n  filter(first_oceanus_year &gt;= 2025, first_oceanus_year &lt;= 2035) %&gt;%\n  # Attach PersonName\n  left_join(\n    nodes_tbl %&gt;% select(person_idx = idx, PersonName = name),\n    by = \"person_idx\"\n  )\n\nif (nrow(person_first_oceanus) == 0) {\n  stop(\"No Oceanus Folk persons with first release between 2028 and 2040.\")\n}\n\n# 6. For those emerging persons, find their notable Oceanus Folk songs between 2028–2040\nartist_notable_songs &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n    from %in% person_first_oceanus$person_idx,\n    to   %in% oceanus_songs_full$song_idx\n  ) %&gt;%\n  left_join(oceanus_songs_full, by = c(\"to\" = \"song_idx\")) %&gt;%\n  left_join(person_first_oceanus, by = c(\"from\" = \"person_idx\")) %&gt;%\n  # keep only songs that are notable and within 2028–2040\n  filter(\n    is_notable,\n    song_year &gt;= 2025,\n    song_year &lt;= 2035\n  ) %&gt;%\n  select(PersonName, song_year)\n\n# 7. Count notable songs per PersonName per year\nnotable_counts &lt;- artist_notable_songs %&gt;%\n  count(PersonName, year = song_year, name = \"NotableCount\")\n\n# 8. Create a year grid from 2028 to 2040 and person list\nyear_seq    &lt;- tibble(year = 2025:2035)\nperson_list &lt;- person_first_oceanus %&gt;% pull(PersonName) %&gt;% unique()\n\n# Expand to all combinations and fill missing with zero\nall_combos &lt;- expand_grid(PersonName = person_list, year = 2025:2035)\n\nnotable_trends &lt;- all_combos %&gt;%\n  left_join(notable_counts, by = c(\"PersonName\", \"year\")) %&gt;%\n  replace_na(list(NotableCount = 0))\n\n# 9. Static ggplot (for sizing/legend adjustments)\nstatic_plot &lt;- ggplot(notable_trends, aes(x = year, y = NotableCount, color = PersonName, group = PersonName)) +\n  geom_line(position = position_dodge(width = 1.5), size = 1) +\n  geom_point(position = position_dodge(width = 1.5), size = 2) +\n  scale_x_continuous(breaks = seq(2025, 2035, by = 2)) +\n  labs(\n    title    = \"Notable Oceanus Folk Songs by Emerging Artists (2025–2035)\",\n    subtitle = \"Click a legend item to isolate that artist\",\n    x        = \"Year\",\n    y        = \"Number of Notable Songs\",\n    color    = \"Artist\"\n  ) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.text   = element_text(size = 8),\n    legend.title  = element_text(size = 9),\n    plot.title    = element_text(size = 12, face = \"bold\"),\n    plot.subtitle = element_text(size = 10),\n    axis.text.x   = element_text(angle = 45, hjust = 1)\n  )\n\n# 10. Convert to interactive Plotly, adjust legend for “toggle others” on click\ninteractive_plot &lt;- ggplotly(static_plot, tooltip = c(\"x\", \"y\", \"colour\")) %&gt;%\n  layout(\n    legend = list(\n      font = list(size = 8),\n      itemclick = \"toggleothers\",    # clicking a legend item isolates that trace\n      itemdoubleclick = \"toggle\"     # double-click brings back all traces\n    )\n  )\n\n# 11. Print the interactive plot\ninteractive_plot\n\n\n\n\n\n\n\n\n\n\n\n\nFindings based on Notable Songs\n\n\n\n\nThis plot shows that Orla, Beatrice and Daniel indeed have the most notable songs in the “recent” time period.\n\n\n\n\n\n\n\n\n\nSailor Shift outlier\n\n\n\n\nIt’s worth to note that Sailor Shift has alot more notable songs overall. But only 1 of it falls under the 2025 - 2035 period.\nThe reason why Sailor Shift isn’t considered an “rising star” is due to the combination of 2 filters.\n\nEmerging-artist filter (2025 - 2035) - 1st Oceanus Folk song_year must fall in this window.\n“Notable” + Year - The song must have a non-NA notoriety_date in the period.\n\n\n\n\nOrla Seabloom, Beatrice Albright and Daniel O’Connell are the most promising upcoming Oceanus Folk artists based on popularity in recent years."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#influences",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#influences",
    "title": "Take-Home_Ex02",
    "section": "Influences",
    "text": "Influences\n\nI will plot the influence diagram without splitting the work and influence related edges. This will show a good overview of Orla Seabloom, Beatrice Albright and Daniel O’Connell’s connection.\n\n\nOceanus Folk visNetwork from 2025 - 2035Betweenness Centrality\n\n\n\nLimiting the hop to 1.\n\n\n\nCode\n# ─── 0. How many hops? ────────────────────────────────────────────────────────\nmax_hops &lt;- 1\n\n# ─── 1. Load & index all nodes and edges ────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# ─── 2. Extract Oceanus Folk songs with their earliest year ────────────────\noceanus_songs_full &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Oceanus Folk\") %&gt;%\n  mutate(\n    release_year = suppressWarnings(as.integer(str_extract(release_date, \"\\\\d{4}\"))),\n    written_year = suppressWarnings(as.integer(str_extract(written_date, \"\\\\d{4}\"))),\n    song_year    = pmin(release_year, written_year, na.rm = TRUE)\n  ) %&gt;%\n  filter(!is.na(song_year)) %&gt;%\n  select(song_idx = idx, song_year)\n\n# ─── 3. Identify Person→Oceanus Folk edges ─────────────────────────────────\nperson_idxs &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  pull(idx)\n\nperson_song_edges &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n    from %in% person_idxs,\n    to   %in% oceanus_songs_full$song_idx\n  )\n\n# ─── 4. Compute each person’s first Oceanus Folk year, then filter to 2025–2035 ─\nperson_first_oceanus &lt;- person_song_edges %&gt;%\n  left_join(oceanus_songs_full, by = c(\"to\" = \"song_idx\")) %&gt;%\n  group_by(from) %&gt;%\n  summarize(first_oceanus_year = min(song_year, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  filter(first_oceanus_year &gt;= 2025, first_oceanus_year &lt;= 2035) %&gt;%\n  rename(person_idx = from)\n\nif (nrow(person_first_oceanus) == 0) {\n  stop(\"No Oceanus Folk artists with first release between 2025 and 2035.\")\n}\n\nfocus_artists &lt;- nodes_tbl %&gt;%\n  filter(idx %in% person_first_oceanus$person_idx, `Node Type` == \"Person\") %&gt;%\n  pull(name)\n\n# ─── 5. Build an undirected igraph of the full graph ────────────────────────\ng_all &lt;- graph_from_data_frame(\n  d        = edges_idx %&gt;% select(from, to),\n  directed = FALSE,\n  vertices = nodes_tbl %&gt;% transmute(name = as.character(idx))\n)\n\n# ─── 6. Compute each focus artist’s 1-hop ego set; then union ─────────────\nego_indices_list &lt;- lapply(person_first_oceanus$person_idx, function(a_idx) {\n  ego(g_all, order = max_hops, nodes = as.character(a_idx), mode = \"all\")[[1]]\n})\nall_ego_numeric &lt;- unique(as.integer(unlist(ego_indices_list)))\n\n# ─── 7. Filter edges to include both influence and work edges among that union ─\nkeep_edge_types &lt;- c(\n  \"InterpolatesFrom\", \"InStyleOf\", \"LyricalReferenceTo\",\n  \"CoverOf\", \"DirectlySamples\",\n  \"ComposerOf\", \"PerformerOf\", \"MemberOf\", \"Released\"\n)\n\ncareer_edges &lt;- edges_idx %&gt;%\n  filter(\n    from %in% all_ego_numeric,\n    to   %in% all_ego_numeric,\n    `Edge Type` %in% keep_edge_types\n  )\n\nif (nrow(career_edges) == 0) {\n  stop(\"No matching edges found within the 1-hop neighborhoods of selected Oceanus Folk artists.\")\n}\n\n# ─── 8. Build the list of all involved nodes ────────────────────────────────\ncareer_node_ids &lt;- unique(c(career_edges$from, career_edges$to))\ncareer_nodes    &lt;- nodes_tbl %&gt;% slice(career_node_ids) %&gt;%\n  mutate(\n    vis_id = row_number(),\n    label  = name,\n    group  = `Node Type`,\n    title  = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`)\n  )\n\n# ─── 9. Remap each career_edge → (from_vis, to_vis) by matching against career_node_ids ─\ncareer_edges &lt;- career_edges %&gt;%\n  mutate(\n    from_vis = match(from, career_node_ids),\n    to_vis   = match(to,   career_node_ids)\n  )\n\n# ─── 10. Construct visNetwork data frames for nodes & edges ─────────────────\nvn_nodes &lt;- career_nodes %&gt;%\n  transmute(\n    id    = vis_id,\n    label = label,\n    group = group,\n    title = title\n  )\n\nvn_edges &lt;- career_edges %&gt;%\n  transmute(\n    from  = from_vis,\n    to    = to_vis,\n    label = `Edge Type`,\n    title = `Edge Type`,\n    color = case_when(\n      label == \"InterpolatesFrom\"   ~ \"#1f78b4\",\n      label == \"InStyleOf\"          ~ \"#e31a1c\",\n      label == \"LyricalReferenceTo\" ~ \"#6a3d9a\",\n      label == \"CoverOf\"            ~ \"#fb9a99\",\n      label == \"DirectlySamples\"    ~ \"#33a02c\",\n      label == \"ComposerOf\"         ~ \"#666666\",\n      label == \"PerformerOf\"        ~ \"#444444\",\n      label == \"MemberOf\"           ~ \"#888888\",\n      label == \"Released\"           ~ \"#AAAAAA\",\n      TRUE                          ~ \"#999999\"\n    )\n  )\n\n# ─── 11. Determine which vis_id correspond to the focus artists (sorted alphabetically) ──\nfocus_vis_ids &lt;- vn_nodes %&gt;%\n  filter(label %in% focus_artists) %&gt;%\n  arrange(label) %&gt;%        # sort by artist name ascending\n  pull(id)\n\n# ─── 12. Render interactive visNetwork with alphabetically sorted dropdown ───\nvisNetwork(vn_nodes, vn_edges, height = \"600px\", width = \"100%\") %&gt;%\n  visNodes(\n    shape = \"dot\",\n    size  = 14,\n    font  = list(color = \"black\", size = 10)\n  ) %&gt;%\n  visEdges(\n    arrows             = \"to\",\n    labelHighlightBold = TRUE,\n    font               = list(color = \"white\", size = 7)\n  ) %&gt;%\n  visOptions(\n    highlightNearest = list(enabled = TRUE, degree = 1),\n    nodesIdSelection = list(\n      enabled   = TRUE,\n      useLabels = TRUE,\n      values    = focus_vis_ids\n    )\n  ) %&gt;%\n  visLegend(useGroups = TRUE, width = 0.1, position = \"right\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\", randomSeed = 1234) %&gt;%\n  visPhysics(enabled = FALSE)\n\n\n\n\n\n\n\n\n\n\nCode\n# ─── PARAMETERS ───────────────────────────────────────────────────────────────\nmax_hops &lt;- 1\nstart_year &lt;- 2025\nend_year   &lt;- 2035\n\n# ─── 1. Load & index all nodes and edges ────────────────────────────────────\nkg_raw    &lt;- fromJSON(\"data/MC1_graph.json\")\nnodes_tbl &lt;- as_tibble(kg_raw$nodes) %&gt;% mutate(idx = row_number())\nlinks_tbl &lt;- as_tibble(kg_raw$links)\n\nid_map &lt;- nodes_tbl %&gt;% select(id, idx)\nedges_idx &lt;- links_tbl %&gt;%\n  left_join(id_map, by = c(\"source\" = \"id\"))  %&gt;% rename(from = idx) %&gt;%\n  left_join(id_map, by = c(\"target\" = \"id\"))  %&gt;% rename(to   = idx) %&gt;%\n  filter(!is.na(from) & !is.na(to))\n\n# ─── 2. Identify all Oceanus Folk songs with computed year ─────────────────\noceanus_songs_full &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Song\", genre == \"Oceanus Folk\") %&gt;%\n  mutate(\n    release_year = suppressWarnings(as.integer(str_extract(release_date, \"\\\\d{4}\"))),\n    written_year = suppressWarnings(as.integer(str_extract(written_date, \"\\\\d{4}\"))),\n    song_year    = pmin(release_year, written_year, na.rm = TRUE)\n  ) %&gt;%\n  filter(!is.na(song_year)) %&gt;%\n  select(song_idx = idx, song_year)\n\n# ─── 3. Find Person→Oceanus Folk edges and determine first-release year ────\nperson_idxs &lt;- nodes_tbl %&gt;%\n  filter(`Node Type` == \"Person\") %&gt;%\n  pull(idx)\n\nperson_song_edges &lt;- edges_idx %&gt;%\n  filter(\n    `Edge Type` %in% c(\"ComposerOf\", \"PerformerOf\"),\n    from %in% person_idxs,\n    to   %in% oceanus_songs_full$song_idx\n  )\n\nperson_first_oceanus &lt;- person_song_edges %&gt;%\n  left_join(oceanus_songs_full, by = c(\"to\" = \"song_idx\")) %&gt;%\n  group_by(from) %&gt;%\n  summarize(first_oceanus_year = min(song_year, na.rm = TRUE), .groups = \"drop\") %&gt;%\n  filter(first_oceanus_year &gt;= start_year, first_oceanus_year &lt;= end_year) %&gt;%\n  rename(person_idx = from)\n\nif (nrow(person_first_oceanus) == 0) {\n  stop(\"No Oceanus Folk artists with first release between \", start_year, \" and \", end_year, \".\")\n}\n\n# ─── 4. Compute each focus artist’s 1-hop ego set; then take the union ─────\ng_all &lt;- graph_from_data_frame(\n  d        = edges_idx %&gt;% select(from, to),\n  directed = FALSE,\n  vertices = nodes_tbl %&gt;% transmute(name = as.character(idx))\n)\n\nego_indices_list &lt;- lapply(person_first_oceanus$person_idx, function(a_idx) {\n  ego(g_all, order = max_hops, nodes = as.character(a_idx), mode = \"all\")[[1]]\n})\nall_ego_numeric &lt;- unique(as.integer(unlist(ego_indices_list)))\n\n# ─── 5. Filter edges to include both influence and work edges among that union ─\nkeep_edge_types &lt;- c(\n  \"InterpolatesFrom\", \"InStyleOf\", \"LyricalReferenceTo\",\n  \"CoverOf\", \"DirectlySamples\",\n  \"ComposerOf\", \"PerformerOf\", \"MemberOf\", \"Released\"\n)\n\ncareer_edges &lt;- edges_idx %&gt;%\n  filter(\n    from %in% all_ego_numeric,\n    to   %in% all_ego_numeric,\n    `Edge Type` %in% keep_edge_types\n  )\n\nif (nrow(career_edges) == 0) {\n  stop(\"No matching edges found within the 1-hop neighborhoods of selected Oceanus Folk artists.\")\n}\n\n# ─── 6. Build the list of all involved nodes ────────────────────────────────\ncareer_node_ids &lt;- unique(c(career_edges$from, career_edges$to))\ncareer_nodes    &lt;- nodes_tbl %&gt;% slice(career_node_ids) %&gt;%\n  mutate(\n    vis_id = row_number(),\n    label  = name,\n    group  = `Node Type`,\n    title  = paste0(\"&lt;b&gt;\", name, \"&lt;/b&gt;&lt;br&gt;Type: \", `Node Type`)\n  )\n\n# ─── 7. Build an igraph object for this subnetwork ──────────────────────────\n#    We use original idx as the igraph 'name' attribute\nvertices_df &lt;- career_nodes %&gt;%\n  transmute(name = as.character(idx), label = label, group = `Node Type`, title = title)\n\nedges_df &lt;- career_edges %&gt;%\n  transmute(\n    from_name = as.character(from),\n    to_name   = as.character(to),\n    etype     = `Edge Type`\n  )\n\ng_sub &lt;- graph_from_data_frame(\n  d = edges_df %&gt;% select(from = from_name, to = to_name),\n  directed = FALSE,\n  vertices = vertices_df\n)\n\n# ─── 8. Compute betweenness centrality for every vertex ─────────────────────\nbetw_vals &lt;- betweenness(g_sub, v = V(g_sub), directed = FALSE, normalized = TRUE)\n\n# Create a tidy tibble of (label, group, betweenness)\nbetw_tbl &lt;- tibble(\n  node_id      = V(g_sub)$name,\n  label        = V(g_sub)$label,\n  group        = V(g_sub)$group,\n  betweenness  = betw_vals\n) %&gt;%\n  arrange(desc(betweenness))\n\n# ─── 9. Plot top 10 nodes by betweenness ────────────────────────────────────\ntop_n &lt;- 10\nbetw_tbl %&gt;%\n  slice_head(n = top_n) %&gt;%\n  ggplot(aes(x = fct_reorder(label, betweenness), y = betweenness, fill = group)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Nodes by Betweenness Centrality\",\n    x     = \"Node\",\n    y     = \"Betweenness (normalized)\"\n  ) +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInfluence Notes\n\n\n\nBased on the plots and betweenness centrality values:\n\nOrla Seabloom, Beatrice Albright & Daniel O’Connell appear in the top 10 most critical nodes under Oceanus Folk in the later years (2025 - 2035)\nWe have to count out Sailor Shift and Yang Wan as they might have already been very popular + influential artists in the earlier years before 2025, which led them to having high scores"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#summary-of-part-b",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#summary-of-part-b",
    "title": "Take-Home_Ex02",
    "section": "Summary of part (b)",
    "text": "Summary of part (b)\nBased on the Popularity and Influence plots we can predict based on Oceanus Folks who might be the upcoming rising stars in the next few years.\nLooking at the plots, there is significant evidence that show that 1) Orla Seabloom, 2) Beatrice Albright & 3) Daniel O’Connell are the next upcoming Oceanus Folk stars that debut recently that will likely continue to chart over the next 5 years."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-2",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-2",
    "title": "Hands-on_Ex09",
    "section": "14.1 Overview",
    "text": "14.1 Overview\nHeatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, we will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-2",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-2",
    "title": "Hands-on_Ex09",
    "section": "14.2 Installing and Launching R Packages",
    "text": "14.2 Installing and Launching R Packages\nBefore getting started, we are required to open a new Quarto document. Keep the default html as the authoring format.\nNext, we will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\n\nCode\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-and-preparing-the-data-set-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#importing-and-preparing-the-data-set-1",
    "title": "Hands-on_Ex09",
    "section": "14.3 Importing and Preparing The Data Set",
    "text": "14.3 Importing and Preparing The Data Set\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n14.3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\n\nCode\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\nThe output tibbled data frame is called wh.\n\n\n14.3.2 Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\n\nCode\nrow.names(wh) &lt;- wh$Country\n\n\nNotice that the row number has been replaced into the country name.\n\n\n14.3.3 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\n\nCode\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#static-heatmap",
    "title": "Hands-on_Ex09",
    "section": "14.4 Static Heatmap",
    "text": "14.4 Static Heatmap\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap() of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, we will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n14.4.1 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\n\nCode\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\n\nNote:\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\n\nCode\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\n\nCode\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#creating-interactive-heatmap",
    "title": "Hands-on_Ex09",
    "section": "14.5 Creating Interactive Heatmap",
    "text": "14.5 Creating Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, we should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. we are also required to have the user manual of the package handy with us for reference purposes.\nIn this section, we will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n14.5.1 Working with heatmaply\n\n\nCode\nheatmaply(mtcars)\n\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\n\nCode\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n14.5.2 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n14.5.2.1 Scaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\n\nCode\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n14.5.2.2 Normalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n14.5.2.3 Percentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\n\nCode\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\n14.5.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n14.5.4 Manual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\n14.5.5 Statistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\n\nCode\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\n\nCode\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n14.5.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If we ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives us ((A+B)+C) as a tree, we know that C can’t end up between A and B, but it doesn’t tell us which way to flip the A+B cluster. It doesn’t tell us if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\n14.5.7 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\n14.5.8 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-3",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-3",
    "title": "Hands-on_Ex09",
    "section": "15.1 Overview",
    "text": "15.1 Overview\nParallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few (2006), “This certainly isn’t a chart that we would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, we will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-3",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-3",
    "title": "Hands-on_Ex09",
    "section": "15.2 Installing and Launching R Packages",
    "text": "15.2 Installing and Launching R Packages\nFor this exercise, the GGally, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\n\nCode\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-preparation-1",
    "title": "Hands-on_Ex09",
    "section": "15.3 Data Preparation",
    "text": "15.3 Data Preparation\nIn this hands-on exercise, the World Happinees 2018 data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\n\nCode\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on_Ex09",
    "section": "15.4 Plotting Static Parallel Coordinates Plot",
    "text": "15.4 Plotting Static Parallel Coordinates Plot\nIn this section, we will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n15.4.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n15.4.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, we will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n15.4.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n15.4.4 Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n15.4.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on_Ex09",
    "section": "15.5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "15.5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, we will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n15.5.1 The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\n\nCode\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\nNotice that some of the axis labels are too long. We will learn how to overcome this problem in the next step.\n\n\n15.5.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\n\nCode\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n15.5.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\n\nCode\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\n15.5.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\n\nCode\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#references",
    "title": "Hands-on_Ex09",
    "section": "15.6 References",
    "text": "15.6 References\n\nggparcoord() of GGally package\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-4",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#overview-4",
    "title": "Hands-on_Ex09",
    "section": "16.1 Overview",
    "text": "16.1 Overview\nIn this hands-on exercise, we will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, we will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, we will learn how to plot static treemap by using treemap package. In the third section, we will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-4",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#installing-and-launching-r-packages-4",
    "title": "Hands-on_Ex09",
    "section": "16.2 Installing and Launching R Packages",
    "text": "16.2 Installing and Launching R Packages\nBefore we get started, we are required to check if treemap and tidyverse pacakges have been installed in you R.\n\n\nCode\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#data-wrangling",
    "title": "Hands-on_Ex09",
    "section": "16.3 Data Wrangling",
    "text": "16.3 Data Wrangling\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal of Urban Redevelopment Authority (URA).\n\n16.3.1 Importing the data set\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\n\nCode\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\n\nThe output tibble data.frame is called realis2018.\n\n\n16.3.2 Data Wrangling and Manipulation\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When we then apply the verbs above on the resulting object, they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\n\n\nRecommendation\n\n\n\nThose who are new to dplyr methods should consult Introduction to dplyr before moving on to the next section.\n\n\n\n\n16.3.3 Grouped summaries without the Pipe\nThe code chank below shows a typical two lines code approach to perform the steps.\n\n\nCode\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nAggregation functions such as sum() and meadian() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\n\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n16.3.4 Grouped summaries with the pipe\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\n\n\n\n\n\nRecommendation\n\n\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\n\n\nCode\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#designing-treemap-with-treemap-package",
    "title": "Hands-on_Ex09",
    "section": "16.4 Designing Treemap with treemap Package",
    "text": "16.4 Designing Treemap with treemap Package\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n16.4.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\n\nCode\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\n16.4.2 Using the basic arguments\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n16.4.3 Working with vColor and type arguments\nIn the code chunk below, type argument is define as value.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n16.4.4 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n16.4.5 The “value” type treemap\nThe code chunk below shows a value type treemap.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n16.4.6 The “manual” type treemap\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n16.4.7 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n16.4.8 Working with algorithm argument\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n16.4.9 Using sortID\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on_Ex09",
    "section": "16.5 Designing Treemap using treemapify Package",
    "text": "16.5 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, we will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before getting started, we should read Introduction to “treemapify” its user guide.\n\n16.5.1 Designing a basic treemap\n\n\nCode\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\n16.5.2 Defining hierarchy\nGroup by Planning Region\n\n\nCode\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\n\nCode\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\n\nAdding boundary line\n\n\nCode\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on_Ex09",
    "section": "16.6 Designing Interactive Treemap using d3treeR",
    "text": "16.6 Designing Interactive Treemap using d3treeR\n\n16.6.1 Installing d3treeR package\nThis slide shows us how to install a R package which is not available in cran.\n1. If this is the first time we are installing a package from github, install devtools package by using the code below or else we can skip this step.\n\nUn-comment the code chunk required.\n\n\n\nCode\n#install.packages(\"devtools\")\n\n\n\nNext, we will load the devtools library and install the package found in github by using the codes below.\n\n\n\nCode\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\", force = TRUE)\n\n\ncli        (3.6.4  -&gt; 3.6.5 ) [CRAN]\npromises   (1.3.2  -&gt; 1.3.3 ) [CRAN]\ndata.table (1.17.0 -&gt; 1.17.6) [CRAN]\n\n\npackage 'cli' successfully unpacked and MD5 sums checked\n\n\npackage 'promises' successfully unpacked and MD5 sums checked\n\n\npackage 'data.table' successfully unpacked and MD5 sums checked\n\n\n\nThe downloaded binary packages are in\n    C:\\Users\\andre\\AppData\\Local\\Temp\\RtmpwtHGlW\\downloaded_packages\n── R CMD build ─────────────────────────────────────────────────────────────────\n* checking for file 'C:\\Users\\andre\\AppData\\Local\\Temp\\RtmpwtHGlW\\remotese6460bd49be\\d3treeR-d3treeR-ebb833d/DESCRIPTION' ... OK\n* preparing 'd3treeR':\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\nOmitted 'LazyData' from DESCRIPTION\n* building 'd3treeR_0.1.tar.gz'\n\n\n\n\nNow we are ready to launch d3treeR package\n\n\n\nCode\nlibrary(d3treeR)\n\n\n\n\n16.6.2 Designing An Interactive Treemap\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\n\nCode\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\n\nCode\nd3tree(tm,rootname = \"Singapore\" )"
  }
]